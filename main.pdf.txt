Behaviour Classi002cation forTemporal Databy Polla A FattahThesis submitted to The University ofNottinghamfor the degree of Doctor of Philosophy ,2017
Dedicated to the Moonshine of My Life.AbstractClassifying items using temporal data, i.e. several readings of the sameattribute in different time points, has many applications in the real world.The pivotal question which motivates this study is: 224Is it possible toquantify behavioural change in temporal data? And what is the best ref-erence point to compare the behaviour change with?224. The focus of thisstudy will be in applications in economics such as playing many roundsof public goods games and share price moves in the stock market.There are many methods for classifying temporal data and many meth-ods for measuring the change of items' behaviour in temporal data. How-ever, the available methods for classifying temporal data produce compli-cated rules, and their models are buried in deep decision trees or complexneural networks that are hard for human experts to read and understand.Moreover, methods of measuring cluster changes do not focus on the in-dividual item's behaviour rather; they concentrate on the clusters andtheir changes over time.This research presents methods for classifying temporal data items andmeasuring their behavioural changes between time points. As case ofstudies, public goods game and stock market price data are used to testnovel methods of classi002cation and behaviour change measure.To represent the magnitude of the behaviour change, we use cluster va-lidity measures in a novel way by measuring the difference between itemlabels produced by the same clustering algorithm at each time point anda behaviour reference point. Such a reference point might be the 002rsttime point, the previous time point or a point representing the generaloverall behaviour of the items in the temporal data. This method usesexternal cluster validity indices to measure the difference between labelsprovided by the same clustering method in different time points ratherthan using different clustering methods for the same data set as it is thecase for relative clustering indices.iiiTo create a general behavioural reference point in temporal data, we presenta novel temporal rule-based classi002cation method that consists of twostages. In the 002rst stage, initial rules are generated based on experts' def-inition for the classes in the form of aggregated attributes of the temporalreadings. These initial rules are not crisp and may overlap in their repre-sentation for the classes. This provides 003exibility for the rules so that theycan create a pool of classi002ers that can be selected from. Then this poolof classi002ers will be optimised in the second stage so that an optimisedclassi002er will be selected among them. The optimised classi002er is a setof discrete classi002cation rules, which generates the most compact classesover all time points. Class compactness is measured by using statisticaldispersion measures or Euclidean distance within class items.The classi002cation results of the public goods game show that the pro-posed method for classi002cation can produce better results for represent-ing players than the available methods by economists and general tem-poral classi002cation methods. Moreover, measuring players' behavioursupports economists' view of the players' behaviour change during gamerounds. For the stock market data, we present a viable method for clas-sifying stocks according to their stability which might help to provideinsights for stock market predictability .ivContentsTitle	iDedication	iiAbstract	iiiContents	vList of Figures	xList of T ables	xviAcknowledgements	xxiDissemination	xxii1 Introduction	11.1	Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . .	11.2	Research Questions and Hypotheses . . . . . . . . . . . . .	31.3	Research Contribution . . . . . . . . . . . . . . . . . . . . .	51.4	Thesis Structure . . . . . . . . . . . . . . . . . . . . . . . . .	62 Background and Literature Review	92.1	Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . .	92.2	Machine Learning and Pattern Recognition . . . . . . . . .	102.3	Classi002cation . . . . . . . . . . . . . . . . . . . . . . . . . . .	112.3.1	Decision Trees . . . . . . . . . . . . . . . . . . . . . .	112.3.2	Support V ector Machine . . . . . . . . . . . . . . . .	182.3.3	K-Nearest Neighbours . . . . . . . . . . . . . . . . .	202.3.4	Classi002cation Performance Measures . . . . . . . .	21v2.4	Clustering . . . . . . . . . . . . . . . . . . . . . . . . . . . .	232.4.1	Centroid-Based Clustering . . . . . . . . . . . . . .	252.4.2	Fuzzy Clustering . . . . . . . . . . . . . . . . . . . .	272.4.3	Hierarchical Clustering . . . . . . . . . . . . . . . .	272.4.4	Clustering Validation . . . . . . . . . . . . . . . . . .	302.5	Temporal Data Analysis . . . . . . . . . . . . . . . . . . . .	362.5.1	Measuring Changes in Temporal Data . . . . . . . .	372.5.2	Temporal Classi002cation . . . . . . . . . . . . . . . .	402.5.3	Temporal Clustering . . . . . . . . . . . . . . . . . .	432.6	Applications . . . . . . . . . . . . . . . . . . . . . . . . . . .	442.6.1	Player Types and Behaviour Public Goods Game . .	442.6.2	Stock Market Classi002cation . . . . . . . . . . . . . .	462.7	Conclusion . . . . . . . . . . . . . . . . . . . . . . . . . . . .	473 Methodology	493.1	Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . .	493.2	Formalising the Problem . . . . . . . . . . . . . . . . . . . .	503.3	Measuring Changes Over Time . . . . . . . . . . . . . . . .	523.4	Temporal Rule-Based Classi002cation . . . . . . . . . . . . . .	553.4.1	Generating Initial Rules . . . . . . . . . . . . . . . .	563.4.2	Optimising Initial Rules . . . . . . . . . . . . . . . .	593.5	Evolutionary Algorithms . . . . . . . . . . . . . . . . . . . .	623.5.1	Differential Evolution . . . . . . . . . . . . . . . . .	643.6	Statistical Measures and Tests . . . . . . . . . . . . . . . . .	663.6.1	Variance and Standard Deviation . . . . . . . . . . .	663.6.2	Interquartile Range . . . . . . . . . . . . . . . . . . .	663.6.3	Wilcoxon Test . . . . . . . . . . . . . . . . . . . . . .	673.6.4	Friedman Test . . . . . . . . . . . . . . . . . . . . . .	683.7	Used Data Sets in This Study . . . . . . . . . . . . . . . . .	683.7.1	Creating a Synthetic Data . . . . . . . . . . . . . . .	693.7.2	Public Goods Games Data . . . . . . . . . . . . . . .	70vi3.7.3	Stock Market Data . . . . . . . . . . . . . . . . . . .	763.8	Testing Environment . . . . . . . . . . . . . . . . . . . . . .	824 Measuring Items' Behavioural Change	854.1	Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . .	854.2	Background . . . . . . . . . . . . . . . . . . . . . . . . . . .	874.3	Approach . . . . . . . . . . . . . . . . . . . . . . . . . . . . .	884.3.1	Preparing Datasets for Clustering . . . . . . . . . .	884.3.2	Choosing Clustering Algorithms . . . . . . . . . . .	894.3.3	Choosing Number of Clusters . . . . . . . . . . . .	904.3.4	Choosing External Cluster Validity Indices . . . . .	934.3.5	Using Internal Cluster Validity Indices . . . . . . .	944.3.6	Using Area Under the Curve . . . . . . . . . . . . .	954.3.7	Different Reference of Behaviours for Items . . . . .	954.4	Testing the Proposed Method . . . . . . . . . . . . . . . . .	964.5	Measuring Players' Strategy Change over Time . . . . . . . 1054.5.1	Using Proposed Method . . . . . . . . . . . . . . . . 1064.5.2	Using MONIC . . . . . . . . . . . . . . . . . . . . . . 1094.6	Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1145 Optimizing T emporal Rule-Based Classi002cation	1175.1	Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . 1175.2	Background . . . . . . . . . . . . . . . . . . . . . . . . . . . 1195.3	Approach . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1215.3.1	Choosing Initial Limits for Classes . . . . . . . . . . 1225.3.2	Selecting Best Classi002er . . . . . . . . . . . . . . . . 1295.4	Performance of the Proposed Classi002cation . . . . . . . . . 1335.4.1	Optimizing Classi002cation Rules . . . . . . . . . . . 1345.4.2	Comparing Contribution Behaviour of the Players . 1365.4.3	Using a Third Classi002er for Comparison . . . . . . . 1415.5	Analysing the Behaviour of PGG Players . . . . . . . . . . 1445.5.1	Players' Strategy in Different Lengths of the Game . 145vii5.5.2	New Players Classes' as Reference of Behaviour . . 1465.6	Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1496 T esting the Stability of the Stock Market	1536.1	Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . 1536.2	Background . . . . . . . . . . . . . . . . . . . . . . . . . . . 1546.2.1	Stock Market Predictability . . . . . . . . . . . . . . 1546.2.2	Temporal Data Mining . . . . . . . . . . . . . . . . . 1556.3	Approach . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1566.3.1	Producing Initial Rules for Classes . . . . . . . . . . 1576.3.2	Optimising Rules Using Heuristic . . . . . . . . . . 1616.4	Testing With Public Goods Game Data Sets . . . . . . . . . 1626.4.1	Comparing Brute Force and Heuristic Results . . . 1626.4.2	Comparing Results with Other Classi002cation Meth-ods . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1666.5	Testing Stock Market Stability . . . . . . . . . . . . . . . . . 1706.5.1	Analysing Stocks' Behaviour . . . . . . . . . . . . . 1716.5.2	Comparing Stocks' Class Memberships . . . . . . . 1766.6	Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1797 Conclusion and Future Work	1837.1	Thesis Summary . . . . . . . . . . . . . . . . . . . . . . . . . 1837.2	Main Results . . . . . . . . . . . . . . . . . . . . . . . . . . . 1857.3	Contributions . . . . . . . . . . . . . . . . . . . . . . . . . . 1907.4	Limitations . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1917.5	Future Work . . . . . . . . . . . . . . . . . . . . . . . . . . . 192Bibliography	195Appendices	215A P-V alues for Public Goods Game	217A.1 Public Goods Game 10 . . . . . . . . . . . . . . . . . . . . . 217A.2 Public Goods Game 27 . . . . . . . . . . . . . . . . . . . . . 219viiiB Pro002les of PGG Players	223C Pro002les of S&P 500 Stocks	229ixxList of Figures2.1	General process of classi002cation methods. From [1] . . . .	122.2	Decision trees representation for splitting items of the databy creating hyper-plains which are parallel to one of theaxes. From [2] . . . . . . . . . . . . . . . . . . . . . . . . . .	132.3	Classifying same data set using both rules and a decisiontree. From [3] . . . . . . . . . . . . . . . . . . . . . . . . . .	162.4	Hyperplane of support vector machine between items oftwo classes showing vectorwand points on the dottedlines are support vectors. From [4] . . . . . . . . . . . . . .	192.5	K-Nearest Neighbour Classi002cation with K = 5 . . . . . . .	202.6	Receiver operating characteristic 050ROC051 curves for variousclassi002ers. From [5] . . . . . . . . . . . . . . . . . . . . . . .	232.7	General steps of clustering methods. From [6] . . . . . . .	242.8	A simple data set with a possible dendrogram for hierar-chical clustering algorithm. From [6] . . . . . . . . . . . . .	282.9	An example of uniform data which can not be clustered.From [2] . . . . . . . . . . . . . . . . . . . . . . . . . . . . .	312.10 Difference between time alignment and Euclidean distanceof two time series. Aligned points are indicated by arrows.From [7] . . . . . . . . . . . . . . . . . . . . . . . . . . . . .	412.11 Calculating the distance between two time series using wrap-ping matrix. From [7] . . . . . . . . . . . . . . . . . . . . . .	41xi2.12 K-Nearest Neighbour with dynamic time wrapping. From[8] . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .	423.1	Two different models focussing on temporal data. The 002rstone focuses on the individual time series items while thesecond focuses on the time points and evaluates items ac-cording to their value in that time point.	. . . . . . . . . .	513.2	Three 002gures illustrating the small changes and the entirecluster move between two time points . . . . . . . . . . . .	543.3	The 003owchart of the proposed rule based temporal classi-002cation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .	563.4	An illustration of the ranges which splits between neigh-boring classes. These ranges will be changed into crisplines after optimisation process . . . . . . . . . . . . . . . .	583.5	An illustration for the boundaries of classes and how theranges are converted into line separators. . . . . . . . . . .	603.6	General operations of evolutionary algorithms . 050from [9].051	633.7	An illustration of different parts of a boxplot showing quar-tiles and their interquartile range. 050from [10]051 . . . . . . . .	673.8	Three time points 050002rst, middle and last051 from the overallcreated 20 time points. The 002rst time point which contains500 items separated into four clusters is the original dataset other time points are created by mutating 050jumping051items of four clusters from one cluster into another. . . . .	703.9	P-experiment's unconditional contributions user interface.which the user can enter their amount of contribution. From[11] . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .	723.10 C-experiment Contribution table user interface in whichthe user can enter their contribution for all possible condi-tions. From [11] . . . . . . . . . . . . . . . . . . . . . . . . .	72xii3.11 C-experiment user interface has two 002elds. One for theamount of players own contribution and the other for guess-ing other players rounded average contribution. From [11]	733.12 Four type of players average own contribution accordingto co-players average contribution . . . . . . . . . . . . . .	763.13 Heat map for players contribution according to their beliefin round 1 . . . . . . . . . . . . . . . . . . . . . . . . . . . .	773.14 Heat map for players contribution according to their beliefin round 5 . . . . . . . . . . . . . . . . . . . . . . . . . . . .	773.15 Heat map for players contribution according to their beliefin round 10 . . . . . . . . . . . . . . . . . . . . . . . . . . . .	783.16 Selected heat maps for players contribution according totheir belief in rounds 1, 5, 10, 15, 20 and 25 in the 27 roundsdata set . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .	794.1	Using elbow method and calculating the sum of squarederrors within groups to 002nd appropriate number of clus-ters for the public goods game data in each time point. . .	914.2	Using rand index to 002nd the best member ship matchesbetween clusters and classes. . . . . . . . . . . . . . . . . .	924.3	Three time points 050002rst, middle and last051 from the 20 timepoints created overall. The 002rst time point, contains 500items and separated into four clusters, is the original datasetother time points are created by mutating 050jumping051 itemsof four clusters from one cluster into another. . . . . . . . .	974.4	Results of various clustering methods using the 002rst timepoint as reference of rehavior to calculate the amount ofchanges which happen to the groups of items in conse-quent time points in the test dataset. The amount of changeis measured by using different external cluster validity in-dices and AUC of ROC. . . . . . . . . . . . . . . . . . . . .	99xiii4.5	Results of various clustering methods using the previoustime point as reference of rehavior to calculate the amountof changes which happen to the groups of items in conse-quent time points in the test dataset. . . . . . . . . . . . . . 1004.6	Results of various clustering methods using the 002rst timepoint as reference of rehavior to calculate the amount ofchanges which happen to the groups of items in conse-quent time points in the 10 rounds PGG dataset. . . . . . . 1084.7	Results of various clustering methods using the previoustime point as reference of rehavior to calculate the amountof changes which happen to the groups of items in conse-quent time points in the 10 rounds PGG dataset. . . . . . . 1094.8	Results of various clustering methods using the 002rst timepoint as reference of rehavior to calculate the amount ofchanges which happen to the groups of items in conse-quent time points in the 27 rounds PGG dataset. . . . . . . 1104.9	Results of various clustering methods using the previoustime point as reference of rehavior to calculate the amountof changes which happen to the groups of items in conse-quent time points in the 27 rounds PGG dataset. . . . . . . 1114.10 Number of survival, appearance and disappearance of clus-ters between every tow consequent time points for ten roundspublic goods game as measured by MONIC. . . . . . . . . 1124.11 Number of survival, appearance and disappearance of clus-ters between every tow consequent time points for 27 roundspublic goods game as measured by MONIC. . . . . . . . . 1125.1	An illustration of the proposed classi002cation algorithm andits relation with temporal data and their aggregates. . . . . 1215.2	Three samples of player's pro002les of the public goods game10 rounds data set. . . . . . . . . . . . . . . . . . . . . . . . 126xiv5.3	Boxplots of the players' contribution behaviour of differ-ent player labels in the 10 rounds data set of the publicgoods game. The labels are generated using economists'de002nitions for various strategy types. . . . . . . . . . . . . 1385.4	Boxplots of the players' contribution behaviour in differentclasses which are generated using proposed classi002cationmethod with IQR as a CM for the cost function. . . . . . . . 1395.5	Boxplots of the players' contribution behaviour in differentclasses which are generated using proposed classi002cationmethod with Euclidean complete Dist. as a CM for the costfunction. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1395.6	Boxplots of the players' contribution behaviour in differentclasses which are generated using proposed classi002cationmethod with SD as a CM for the cost function. . . . . . . . 1405.7	Results of various clustering methods using proposed classesas reference of rehavior to calculate the amount of changeswhich happen to the groups of items in consequent timepoints in the test dataset. The amount of change is mea-sured by using different external cluster validity indicesand AUC of ROC. . . . . . . . . . . . . . . . . . . . . . . . . 1485.8	Results of various clustering methods using proposed classesas reference of rehavior to calculate the amount of changeswhich happen to the groups of items in consequent timepoints in the test dataset. The amount of change is mea-sured by using different external cluster validity indicesand AUC of ROC. . . . . . . . . . . . . . . . . . . . . . . . . 1496.1	Three samples of stocks's pro002les of S&P 500 data set. . . . 1606.2	Using the 002rst time point as reference of behaviour. . . . . 1736.3	Using the previous time point as the reference of behaviour. 1746.4	Using the proposed classes as reference of behaviour. . . . 175xvxviList of T ables2.1	Confusion Matrix . . . . . . . . . . . . . . . . . . . . . . . .	223.1	A sample of the S&P 500 data set after cleaning and ma-nipulation. . . . . . . . . . . . . . . . . . . . . . . . . . . . .	813.2	The R packages which are used in this study . . . . . . . .	834.1	P-values of Wilcoxon-test for each pair of clusters. . . . . . 1014.2	P-values of Wilcoxon-test for each pair of external clustervalidity indices and AUC. . . . . . . . . . . . . . . . . . . . 1034.3	P-values of Wilcoxon-test for each pair of external clustervalidity indices or AUC. . . . . . . . . . . . . . . . . . . . . 1045.1	Sample of the public goods game data with three aggre-gated attributes which are derived from temporal attributes.The aggregated attribute headers are denoted by their re-spective mathematical notation. . . . . . . . . . . . . . . . . 1245.2	The attributes' [min, max] values for classi002cation rules . . 1285.3	The attributes' best values for the ranges of the initial clas-si002cation rules of 10 rounds the public goods game dataset using different cost functions. . . . . . . . . . . . . . . . 1365.4	Number of players in each class 050Cardinality number ofclasses051 in 10 rounds of the public goods game data set us-ing different cost functions. . . . . . . . . . . . . . . . . . . 137xvii5.5	The ten rounds' average of standard deviation for play-ers' contribution of each class using various cost functionsto produce players' classes which are compared with theeconomist labels. . . . . . . . . . . . . . . . . . . . . . . . . 1415.6	Correlation value among created attributes . . . . . . . . . 1435.7	Accuracy of SVM using different attribute sets to compareproposed classi002cation and existing labels . . . . . . . . . . 1445.8	The attributes' best values for the ranges of the initial clas-si002cation rules of 27 rounds of the public goods game dataset using selected cost functions. . . . . . . . . . . . . . . . 1465.9	Number of players in each class 050Cardinality number ofclasses051 in 10 rounds of the public goods game data set us-ing different cost functions. . . . . . . . . . . . . . . . . . . 1476.1	Initial classi002cation rules of stock market data set . . . . . 1616.2	Comparing of brute force and differential evolution resultsfor optimising attributes' values for the ranges of the initialclassi002cation rules of 10 rounds public goods games dataset for different cost functions. . . . . . . . . . . . . . . . . . 1646.3	Comparing class membership results of the brute force anddifferential evolution in 10 rounds of public goods gamedata set using different cost functions. . . . . . . . . . . . . 1656.4	AUC of ROC analysis for different classes and the pro-posed classi002cation method of 10 rounds of public goodsgames. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1686.5	AUC of ROC analysis for different classes and the pro-posed classi002cation method of 27 rounds of public goodsgames. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1696.6	Optimised classi002cation rules of stock market data set, us-ing IQR as cost function for optimisation process. . . . . . 172xviii6.7	Number of stocks in each class and percentage of compat-ible results between two quarters of the 002scal year usingdifferent cost functions . . . . . . . . . . . . . . . . . . . . . 1776.8	Number of stocks in each cluster and the percentage ofcompatible results between two quarters using differentclustering methods. . . . . . . . . . . . . . . . . . . . . . . . 178A.1 P-value results for testing the effect of using different clus-tering methods for grouping each time point as prepara-tion for measuring their behaviour using 002rst and previous050consecutive051 time point as reference of behaviour on 10rounds PGG data set. P-values for Wilcoxon-test are pre-sented for each pair of clusters for one to one comparisonand the p-value for Friedman-test is presented as compar-ison for entire samples. . . . . . . . . . . . . . . . . . . . . . 217A.2 P-value results for testing the effect of using different ECVIand AUC methods for measuring changes over time us-ing 002rst and previous 050consecutive051 time point as refer-ence of behaviour on 10 rounds PGG data set. P-valuesfor Wilcoxon-test are presented for each pair of ECVI andAUC for one to one comparison and the p-value for Friedman-test is presented as comparison for entire samples. . . . . . 218A.3 P-value results for testing the effect of using different clus-tering methods for grouping each time point as prepara-tion for measuring their behaviour using 002rst and previous050consecutive051 time point as reference of behaviour on 27rounds PGG data set. P-values for Wilcoxon-test are pre-sented for each pair of clusters for one to one comparisonand the p-value for Friedman-test is presented as compar-ison for entire samples. . . . . . . . . . . . . . . . . . . . . . 219xixA.4 P-value results for testing the effect of using different ECVIand AUC methods for measuring changes over time us-ing 002rst and previous 050consecutive051 time point as refer-ence of behaviour on 27 rounds PGG data set. P-valuesfor Wilcoxon-test are presented for each pair of ECVI andAUC for one to one comparison and the p-value for Friedman-test is presented as comparison for entire samples. . . . . . 221xxAcknowledgementsThanks are due to my supervisors Prof. Uwe Aickelin and Dr. Chris-tian Wagner for their continued guidance and advice. They have indeedchanged my perspective on the methods of conducting researches andpublishing, showing most patience with me to gain the required level ofcompetence in the domain of study .I would also like to thank Prof. Simon Gaechter and Dr Felix Kolle fromthe School of Economics as they provide me with the required data setsof public goods game and spend the time to discuss players' behaviourand their classes.Other members of the School of Computer Science have provided mewith the required advice especially Amir Pourabdollah and Peer-OlafSiebers. I would like also to thank all members of IMA group for provid-ing me with motivation and friendly advice especially Shabbar Naqvi,Ian Dent, Jabran Aladi and Tuong Vu.My thanks with respect to my father Abdulhamid Fattah and my motherSamira Bilal for their continued support and their prayers for me. Thisthesis would not happen if they did not culture in me the dream of per-suading science and truth. I would not forget the support which I havereceived from my father and mother in laws 050Fawzi Abduljabbar andAdiba Bilal051 and their words of motivation. I would love to thank mykids Elaf, Sidra and Mustafa for their understanding and their patienceas being distant from them if not physically but certainly emotionally .Last but not the least I have reserved the warmest thanks to my lovelywife Sanar Fawzi for standing with me during this journey 050As she callsit 'A chapter of life'051.xxiDisseminationJournals017Fattah, P ., Aickelin, U., Wagner, C., 2016. Optimising Rule-BasedClassi002cation in Temporal Data. Zanco J. Pure Appl. Sci. 28, 135226146.Conferences017Fattah, P ., Aickelin, U., Wagner, C., 2016. Optimising Rule-BasedClassi002cation in Temporal Data. In: 1st International Conferenceon Engineering and Innovative Technology . Salahaddin University-Erbil, Erbil, Kurdistan.017Fattah, P ., Aickelin, U., Wagner, C., 2016. Measuring Player ' s Be-haviour Change over Time in Public Goods Game. In: SAI Intelli-gent Systems. London, UK, pp. 637226643.017Fatah, P ., Hamarash, I., 2015. Optimization of association rule min-ing A two step breakdown variation of Appriori algorithm. In: In-ternet Technologies and Applications 050ITA051, 2015. IEEE, pp. 275226280.Presentations017Fattah, P ., Aickelin, U., Wagner, C., 2014. Measuring players' be-havioural change in public goods game using clustering. NetworkIntegrated Behavioural Science.017Fattah, P ., Aickelin, U., Wagner, C., 2014. Measuring Micro Changesover Time in Clustering. In: IMA Seminars. Nottingham.Posters017Fattah, P ., Aickelin, U., Wagner, C., 2014. Measuring Change of Hu-man Behaviour in Public Good Experiment. In: Kurdistan StudentsConference - 2014. Nottingham.xxii017Fattah, P ., Aickelin, U., Wagner, C., 2013. Clustering Human Be-haviour in Public Good Experiments. In: IMA 2013. Nottingham.xxiiiBlank PagexxivChapter 1Introduction1.1 IntroductionThis research can be considered as a study in the 002eld of data mining aswe propose a classi002er for the overall behaviour of items in temporal dataand a method to measure changes of items' behaviour over the length ofthe temporal data. Classi002cation is one technique involved in the datamining. Its task is to predict the class of items in a data set using a certainmodel of a classi002er. The model is constructed using already-labelleditems of similar data sets. This step allows classi002cation techniques tobe considered as a supervised machine learning method. Data Mining isthe process of 002nding patterns in a large scale of data which are interest-ing, new, useful and meaningful [2]. Data mining can be considered asan interdisciplinary 002eld of study consisting of areas such as databases,statistics, machine learning and arti002cial intelligence [12].The initial goal of this research is to measure the behavioural changesfor groups of subjects, especially for public goods games players over aperiod of time. The behaviour of players in public goods game is understudy by economists [11, 13]. Public goods game is a simple experimentin the form of a game. The game consists of multiple players imitat-11.1. INTRODUCTIONing real life situations of public good by contributing to a project whichrepresents the public good [14]. This goal is accomplished by clusteringall available time points separately without a time dimension by using aselected clustering method. Then, the change between these clusters ismeasured using external cluster validity indices [15] to compare betweenthe 002rst time point clusters of the data set and the clusters of the remain-ing time points. However, assigning the 002rst time point as a referenceto measure the change in the subjects' behaviour for the rest of the timepoints raised a concern about the limitations of the method, as the 002rsttime point may not be representative of the rest of the data.The aforementioned limitation leads us to consider the concept of 224Refer-ence of behaviour224 for items in temporal data. The reference of behaviourcan be de002ned as the assumed metric behaviour 'standard' for the itemsin the data set. This reference of behaviour can be the 002rst time point,the previous time point for the current time point, and the general over-all behaviour of the items in the temporal data 050detailed explanation inchapter 4051.The 002rst two references of behaviour are generated straightforward fromdata sets. However, the last reference of behaviour does not directly ex-ist in the data set, and it had to be created so that we tried to use theprovided classes of players by the economists. However, the economists'classes are based on static data 002lled as a questioner by the players in-stead of the actual players' behaviour during the game. Therefore a novelmethod for temporal rule-based classi002cation is introduced, to classifyplayers according to the temporal data. This method is based on the ex-perts' classi002cation and knowledge, and produces clear rules which canbe dealt with by experts in the 002eld in contrast to the available methodsin which the classi002er model lies deep in decision trees or neural net-work layers. The proposed method consists of two stages. The 002rst stagegenerates a pool of classi002ers with the help of human experts and the sec-2CHAPTER 1. INTRODUCTIONond stage uses optimisation techniques to select the best classi002er amongthem 050detailed explanation in chapter 5051.To use the introduced classi002er, and then to measure the behaviour changeof the items in a more generalised context, we tested them with a stockmarket data set. Stock market data has the same properties as a pub-lic goods game because both are temporal, and the recorded behaviourof the items exist at all time points. However, the stock market data islarger than players data in terms of the number of time points and thenumber of items in each time point. Given that a heuristic method isused to optimise provided rules for classi002cation. The used heuristic isDifferential Evolution, which is developed by Storn and 050detailed expla-nation in chapter 6051.1.2 Research Questions and HypothesesThe main question which this study attempts to answer is: 224Is it possibleto quantify the behavioural change of items in temporal data? Also, whatis the best reference point to compare the behaviour change with?224 Thisquestion lead us to introduce methods for quantifying changes and iden-tifying the general behaviour of items using rule-based temporal classi002-cation. A series of smaller questions also arose concerning the details ofthe proposed methods and the case studies. The questions are:017How to identify patterns of behaviour in a single time point? To002nd patterns of behaviour in each time point, we propose that themeasurements of behaviour 050attributes051 in that particular time pointshould be clustered separately without the effect of time on the clus-tering. For example, if we need to examine stock price behaviourin a single time point, it can be clustered into two clusters , decreas-ing and rising. As we have different clustering algorithms, we canhypothesise that:31.2. RESEARCH QUESTIONS AND HYPOTHESESHypothesis 1Using different clustering algorithms will not produce asigni002cant difference in the 002nal result of quantifying the changes overtime as long as same clustering algorithm is used in both time points.017How to measure the difference between the produced clusters inthese time points? To quantify the difference between clusters atany two time points in a temporal data, we propose using existencemethods in cluster validity indices and classi002cation performancemeasures such as AUC, as these methods already measure the mag-nitude of the difference between true classes and clustering/classi-002cation guesses of subjects. According to this proposition, we canhypothesise that:Hypothesis 2The results of different external clustering indices and AUCfor the same data set and clustering algorithm are consistent.017What should be the reference point of behaviour to measure thechanges between time points of the temporal data? To 002nd a refer-ence for items' behaviour, we propose using temporal classi002cationor clustering to determine the overall behaviour of a subject andthen comparing the difference of each time point to the general be-haviour of the item. We can hypothesise that:Hypothesis 3Using overall behaviour of a subject in a temporal dataproduces more stable results than comparing each time point with the 002rsttime point.017How to classify public goods game players according to their con-tribution behaviour? To classify this temporal data and relate theirclasses to the rules created by economists, we propose a temporalrule-based classi002cation method which optimises rules provided byexperts. We can hypothesise that:Hypothesis 4The results of different external clustering indices and AUCfor the same data set and using the same clustering algorithm to determinethe patterns of items' behaviour are consistent.4CHAPTER 1. INTRODUCTION017Does the length of the public goods game affect player strategy? Todetermine the effect of the length of the game on player strategy , wepropose to classify players according to their behaviour using datasets of two different lengths of the game, and then check the num-ber of players in each class. If the number of players is signi002cantlydifferent, then the game length may in003uence player strategy . Oth-erwise it does not:Hypothesis 5The length of the public goods game does not affect overallplayer strategy.017Can the proposed temporal classi002cation method for players of apublic goods game be generalised and used in different areas? Totest the proposed classi002cation method in areas other than a publicgoods game, we classify the stock market data according to theirstability and then check whether they stay in the same class or not.To be able to predict their future values, the majority of stock mar-kets should follow the same stability class in at least two consecu-tive time periods:Hypothesis 6At least 50% of the stocks follow the same stability classfor two consecutive quarters, so that their future behaviour can be pre-dictable.1.3 Research ContributionThis research presents two types of contribution for the knowledge. The002rst type is directly related to data mining and data analysis. The contri-butions of this type are:017Using external cluster validity indices in a new way for measuringthe amount of change which happens to items in the clusters be-tween two time points in a temporal data.51.4. THESIS STRUCTURE017Presenting a novel way for classifying items in temporal data bycombining rule-based algorithms and optimisation. The rules areprovided by experts for the non-temporal attributes of data whichmay have been aggregated from the temporal attributes. Then, us-ing optimisation to 002nd the best classi002er based on the agglomera-tion of the classes measured by the temporal attributes of the datafrom the provided pool of classi002ers.The second type of contribution is related to the application areas of the002rst type, namely a public goods game and stock market prices. Thecontributions of this type are:017Creating a new method for classifying public goods game playersbased on economists' methods of classifying them. However, thenew classi002cation uses players' actual contribution behaviour toclassify them instead of relying on a static questionnaire completedby them prior to the game.017Present additional evidence that the players' change in behaviourover time is smooth and subtle using external cluster validity in-dices to measure the differences in players' membership in clustersover two time points.017By classifying the stability of shares and comparing these classesover two 002scal quarters, we will have contributed to the debateabout the predictability of the stock market and presented yet addi-tional evidence for the random walk theory .1.4 Thesis StructureA detailed literature review is presented in Chapter 2. This covers vari-ous methods and techniques which have been developed to detect andmeasure changes in data streams and spatiotemporal data, as we de-6CHAPTER 1. INTRODUCTIONscribe their uses and limitations. A review of classi002cation and cluster-ing methods are presented highlighting the methods which are used inthis research. This is followed by a comprehensive review of the mostimportant available methods for temporal classi002cation and clusteringalgorithms. In this piece of research, many performance measures havebeen used such as cluster validity indices for clustering and 'Area underthe Curve of ROC' analysis for classi002cation. A detailed description ofthese methods is, therefore, presented. In this research, the data of publicgoods games and economists' classi002cation methods are used for com-parison purposes with our results. Accordingly , a brief review of theseclassi002cations is presented. As one of the tests, we are using stock marketdata to measure its stability , so a brief review on economists' 002ndings onstock market stability is presented.Chapter 3 starts to fully formalise the issue by providing detailed require-ments and concerns about measuring changes over time for items in tem-poral data. The method used for measuring and quantifying changes initems in temporal data between two time points are explained as wellas the rationales behind the decisions made. Then, a step-by-step expla-nation behind the proposed temporal rule-based classi002cation method isoffered with a list of compactness measures used for optimising the pro-vided rules. In this piece of research, three data sets are used, all of whichare listed in this chapter. The 002rst data set is the synthetic data which areused to measure the change between time points. A detailed explanationis provided on how it is created and the property of its attributes. Thesecond data comes with two variations in two different data sets with 10and 27 rounds of the game completed by players. A detailed descriptionof its attributes as well as how the experimental game is constructed andthe data gathered is presented. The last data set of stock market pricesfor the method of gathering, cleaning and reprocessing data is explained.Chapter 4 tests measuring changes between two time points by clustering71.4. THESIS STRUCTUREdata using different clustering algorithms, and tests various methods foraligning clusters in the two time points for the AUC of ROC and a oneto one comparison. Also, a number of external cluster validities are usedto quantify changes of measure for items in the data set. The data usedfor this test is the synthetic data, and two data sets from a public goodsgame.In Chapter 5 the detailed algorithm for the temporal rule-based classi002-cation is presented. Then, the two data sets from the public goods gameare used to classify them using the proposed classi002cation. A compari-son between the results of the classi002cation and provided classes usingexperts' methods for classi002cation is presented, as well as a comparisonbetween classes of two different data sets. In this chapter, a simple ver-sion of the classi002er is used. This is relatively slow as it uses brute forceto 002nd the best classi002er.In Chapter 6 a new version of the proposed classi002er is presented usingDifferential Evolution to 002nd the optimum classi002cation rules from thepool of provided rules for classi002cation. This new version is signi002cantlyfaster than the version of Chapter 5 which uses brute force for optimisa-tion. Proper tests are presented using data sets from public goods gamesto ensure that the results of the heuristic method are not signi002cantly dif-ferent from the results of the brute force optimisation. Then, the newversion of the classi002er is used to address the questions regarding stockmarket data set and the hypotheses.The last chapter presents a conclusion for the use of the presented meth-ods, and their possible limitations are discussed along with the areas thatcould be enhanced in the future. This chapter also reiterates the researchquestions, their related hypotheses as well as providing answers for thesequestions as they arise through this study .8Chapter 2Background and LiteratureReview2.1 IntroductionThis chapter critically analyses literature related to the background of theresearch area and the data mining and analysis methods subsequentlydeployed with the proposed temporal rule-based classi002cation method.This chapter thus covers the topics of traditional and temporal classi002ca-tion and assessment measures.As this thesis also proposes a method for calculating changes over timeusing clustering and cluster validity indices, So that the used clusteringmethods and their features are discussed in this chapter along with dif-ferent types of internal and external cluster validity indices.Multiple real-world data sets are used in this thesis as case studies de-rived from a public goods game and stock market data, thus these topicsare also brie003y covered in this chapter.The literature and topics in this chapter are ordered according to theirimportance and closeness to the proposed methods.92.2. MACHINE LEARNING AND PATTERN RECOGNITION2.2 Machine Learning and Pattern RecognitionPattern recognition is a branch of computer science concerned with themethods of 002nding patterns in raw data automatically using computeralgorithms. Due to the complexity of the patterns and irregularities thatcan be found among the same group of patterns, it is not trivial to hardcode a machine to 002nd all patterns with acceptable accuracy; it is moreef002cient to use machine learning algorithms to recognise patterns in theraw data [16].As de002ned by Samuel [17], computer programs manifest machine learn-ing by behaving in a way that comprises a learning process similar to thatinherent in human or animal cognition. Examples of learning processesinclude learning how to play checkers, identify handwriting and group-ing similar trends and behaviours in raw data. The data of individualpatterns are called features, which might be stored in the form of a vec-tor. Machine learning algorithms can be divided into two main categoriesaccording to the type of input they receive: supervised and unsupervisedlearning [16].Supervised learning is a machine learning algorithm which receives fea-ture vector and the target pattern as an input to build a model. The modelcan be used to recognise new patterns and assign a target to them. Ap-plications of supervised learning include classi002cation 050e.g. classifyingplayers according to their behaviour during a game051 and regression 050e.g.predicting household prices according to features051 [16].Unsupervised learning is a machine learning algorithm which only re-ceives the feature vector as an input, and its task is to 002nd similar groupsof items with comparable features. The essential application of unsuper-vised learning is clustering, such as determining the distribution of dataitems within a multidimensional space [16].This thesis consists of both methods of machine learning, as measuring10CHAPTER 2. BACKGROUND AND LITERATURE REVIEWchanges over time can be considered as unsupervised learning that in-corporates clustering for its function, and temporal rule-based classi002ca-tion is an instant of classi002cation and can be considered as an exampleof supervised. In subsequent sections both classi002cation and clusteringare discussed in more detail with regard to machine learning and patternrecognition.2.3 Classi002cationAs mentioned previously , Classi002cation is an instance of supervised learn-ing. Supervised learning classi002cation process includes a training phaseto create a model 050classi002er051. The entire process of using a supervisedclassi002cation method is illustrated by Kotsiantis [1] as shown in Figure2.1, with the training step being an important part of it.Different classi002er models are created by using different classi002cation al-gorithms, which can be divided into four main categories: Decision TreeClassi002er, Probabilistic Classi002cation, Support V ector Machines and Lin-ear Discriminant Analysis [2]. These classi002ers are discussed in the fol-lowing subsections, with particular consideration of Decision Tree Clas-si002ers deployed in this research.2.3.1 Decision T reesAs described by Zaki et al. [2], Decision Tree is a classi002cation modelwhich recursively partitions the data space into two parts. The split canbe considered as a hyperplane parallel to one axis of the data space. Theprocess repeats by dividing each new part into two smaller parts, andthis process continues until each sub-part mostly contains items of onlyone of the target classes. The 002nal result of this partitioning process canbe represented by a tree, where each node is a decision concerning which112.3. CLASSIFICATION
Figure 2.1: General process of classi002cation methods. From [1]part an item belongs to, and the leaves represent one of the target classes.As an example of the decision tree partitioning, consider the iris data setwith 150 entries of three classes. The items are displayed in Figure 2.2050a051,which plots their sepal length and width as X, Y axes. The partitioningprocess created six different regions, which are divided by lines insteadof hyperplains, as in two-dimensional data space the hyperplanes canonly have one dimension. Multiple regions might represent one of thetargeted classes. The tree representation of the iris data space partition isshown in Figure 2.2050b051.C4.5 might be one of the most famous decision tree algorithms for clas-si002cation [18]. C4.5 is build on ID3, both of which were introduced by12CHAPTER 2. BACKGROUND AND LITERATURE REVIEW
050a051 Recursive Splits
050b051 Decision TreesFigure 2.2: Decision trees representation for splitting items of the data bycreating hyper-plains which are parallel to one of the axes. From [2]Quinlan [19]. This algorithm relies on information gained to create itstree for classi002cation. In this algorithm attributes with higher normalisedinformation gain are used for decide the splits in the data. The the nexthighest attribute is used for subpartitioning the data recursively [19].This algorithm is superseded by a new version C5.0, which is more ef-002cient as it uses less memory and functions more ef002ciently and effec-tively , generating a smaller and more concise decision tree, while it is132.3. CLASSIFICATIONmore general as it can classify more data types than its predecessor. Italso incorporates boosting, which means multiple classi002er trees can begenerated and they will vote for predicting items' classes. Boosting is abootstrap aggregate 050bagging051 mechanism which may improve the stabil-ity and accuracy of the 002nal result of the classi002er [18]. The last aspect ofthe algorithm is similar to what is provided by Random Forest algorithm,which creates many decision trees from random subsets of the trainingdata [20].C4.5 has two drawbacks [21], the 002rst of which is over002tting, which mightbe solved by pruning the decision tree to be more general. Two typesof pruning can be done on the tree pre-pruning and post-pruning. Pre-pruning is the operation of preventing particular branches from growingwhen information becomes unreliable. Post-pruning is the operation ofcutting branches of a fully grown tree to remove unreliable parts. Thesecond drawback originates from the very nature of the algorithm by se-lecting attributes with the highest information gain value. This processwill become bias to the attributes with a large number of values.Conditional Inference Tree 050Ctree051 was introduced by Hothorn et al. [21]to overcome the attribute bias of the information gain based algorithms.This algorithm uses signi002cance to select covariants of attributes. The sig-ni002cance is determined through P-value which is derived from ANOV AF-statistics. During the training phase, all data permutations will betested to calculate the p-value.Rule-Based Classi002cationA rule-based classi002er uses a set of rules to classify items in a data set.The rules are formalised in the form of IF-THEN clause. The conditionsof the IF clause represent the rules that an item should ful002l to be ac-cepted as a particular class. If the rules are ordered and have priority14CHAPTER 2. BACKGROUND AND LITERATURE REVIEWthey can be represented in nested IF-THEN-ELSE clauses and might becalled decision lists [3].Figure 2.3a shows a simple data set with items labelledaorb. We canproduce multiple variations of rules to classify items in this data set. It ispossible to 002lter out all classaitems 002rst then all others remaining willbe classb: If x>1.4 and y<2.4 then class =aOtherwise class =bConversely , if b class items are 002ltered out the remaining items will beclassi002ed asa: If x61.2 then class =bIf x>1.2 and y62.6 then class =bOtherwise class =aIn most cases, rule-based classi002cation systems and decision trees can beused interchangeably; C4.5 provides both decision trees and classi002cationrules [18]. A decision tree representing the rule-based classi002er is shownin Figure 2.3b. The rules above and the decision tree can be consideredas an equivalent classi002ers, but most of the time people prefer rule-basedclassi002ers on decision trees as they are more intuitive for human under-standing [3], due to being simpler and more concise [18].Various methods are used to generate rule-based classi002ers in different002elds of application. The remainder of this section presents more effec-tive samples of these works with a brief explanation of their methodolo-gies.Rodriguez et al. [22] used rule-based classi002cation to classify power qual-ity disturbances of signals. They used S-transform to extract featuresfrom signals, as this transform can generate variable window size withthe ability to preserve phase information during decomposition [23]. Theyused leaner and parabolic lines to separate between classes. The separa-152.3. CLASSIFICATION
Figure 2.3: Classifying same data set using both rules and a decision tree.From [3]tion line is produced using a heuristic function to guarantee maximisa-tion of the number of correctly classi002ed signals from the provided train-ing set.Chung et al. [24] use a two-stage classi002cation method to classify powerline signals, in the 002rst of which they used a rule-based classi002er to differ-entiate interrupt signals from others, which were then further classi002edusing Hidden Markov Model classi002er. The rules of the 002rst stage classi-002er are created by domain experts relying mainly on the IEEE standardsfor signal interruption conventions, thus this classi002er does not require atraining set, as it is a static set of rules that can be calculated directly .McAulay et al. [25] used genetic algorithms to create rule-based systemsto identify alphabetical numbers. The system uses a random rule gen-erator to create initial rules, which are enhanced through multiple gen-erations by adjusting the initial rules. However, they notice that geneticalgorithms might override even good rules which can identify speci002c16CHAPTER 2. BACKGROUND AND LITERATURE REVIEWcharacters. To prevent overriding rules they introduced the concept ofremembering rules for a long time if they succeeded to correctly identifythe training set example.Orriols-Puig et al. [26] used an evolutionary algorithm to create a rule-based classi002cation system in which the system initiates with a set ofclassi002er rules, then evolves online with the environment 050new trainingitems051 to produce an accurate classi002cation model. They proved thattheir classi002cation method outperforms other methods 050including sup-port vector machine051 in classifying data sets with imbalanced class ratios.Nozaki et al. [27]used fuzzy systems to create a rule-based classi002er. Gen-erating fuzzy rule-based classi002cation system requires two phases, 002rstpartitioning the patron space into fuzzy subspaces and then de002ning afuzzy rule for each of these. Nozaki et al. used a fuzzy grid introducedby Ishibuchi et al. [28] with triangle-shaped membership function to gen-erate fuzzy rules from fuzzy subspaces. To enhance the classi002cationresults they introduced two procedures, error correction-based learningand signi002cant rule selection. Error correction-based process increasesand decreases the procedure of increasing or decreasing rule certaintyaccording to its classi002cation of the items; if a particular rule correctlyclassi002ed an item its certainty will increase, otherwise it will decrease ac-cordingly . Signi002cant rule selection is a mechanism to prune unnecessaryrules to construct a compact set of a fuzzy rule-based classi002er.As demonstrated above, many domains of computer science and ma-chine learning are used to generate and optimise rule-based classi002ca-tion systems, including expert systems, genetic algorithms, evolutionaryalgorithms and fuzzy systems. While these classi002ers are ef002cient andeffective methods to classify underlying data sets, they require a train-ing data set for rule generation and optimisation. This means a suf002cientamount of correctly labelled samples should be available to cover all ormost of the aspects and possibilities of situations and characteristics that172.3. CLASSIFICATIONhave to be classi002ed.The availability of the training data set might not always be an optiondue to the fact that labelling items is a tedious and laborious undertak-ing requiring a extensive periods of professionals' valuable time. Expertsmight know the general rules for classifying items but they cannot iden-tify the attributes of the classes individually due to the complexity of theunderlying data sets. Moreover, domain experts might not quite agreeon the 002ne differences between classes, so that it is hard to have a generalsingle view for classifying items in the data set 050such as in public goodsgames case study051.After the training stage these methods create a list of rules that representthe 002nal rule-based classi002er model, which might not cover all differ-ent opinions for nuanced cases of the classi002cation 050i.e. after the trainingstage, the classi002er might lack the required generalisation051. As noted pre-viously , the generalisation problem might be solved by using rule prun-ing [27]. However, this generalisation can be called local, as it depends onthe training data, which is probably classi002ed and labelled using expertsingle views.Another aspect which is lacking in the presented methods is that they donot consider the classi002cation of temporal data sets, as demonstrated inlater sections. However, these methods also require training samples.2.3.2 Support V ector MachineSupport V ector Machine 050SVM051 is a binary parametric classi002er that clas-si002es items by creating a hyperplane between classes. This algorithmtries to 002nd an optimum position for the hyperplane so that it splits theclasses with the maximum margin between class items and minimumempirical risk. The items on the edges of the margin are called supportvectors, as each item can be seen as a vector. An example of an SVM18CHAPTER 2. BACKGROUND AND LITERATURE REVIEWclassi002er's hyperplane is shown in Figure 2.4. It can be noticed that in atwo-dimensional data set the hyperplane is represented as a line [4].
Figure 2.4: Hyperplane of support vector machine between items of twoclasses showing vectorwand points on the dotted lines are support vec-tors. From [4]AssumeD=f050xi; yi051gni=1is a dataset to be classi002ed. The data set has nitems in d dimensions, and each item has a set x of d attributes and y as aclass label. For two classes we can assume that y can have one value of 1or -1. The SVM's hyperplaneh050x051equation is de002ned ash050x051 =wTx+b.In this equation, w is a d dimensional weight vector and b 050bias051 is ascalar. The points on the hyperplane equal to 0 050h050x051 = 0051, so that for anyxiifh050xi051>0thenyi= 1and ifh050xi051<0theniy=0001[2].One of the advantages of SVM is that it can use kernel trick. For a data setwith nonlinear separation between classes, we can map the d-dimensionalitemsxiof input space into a high-dimensional feature space using a non-linear transformation function [2].SVM has been used as an elementary stage to create rule-based classi002ers.Nunez et al. [29] used rule extraction mechanism to extract rules from anSVM model generated via training samples. The rules are constructedusing multiple of ellipsoid equations. While these rules might presenta good visual illustration for the rules, especially for two-dimensionalspaces, these equations have mathematical forms so that the generated192.3. CLASSIFICATIONrules are not intuitive and easy to understand as standalone rules. More-over, the ellipsoids are not one-to-one maps for the actual hyperplanes ofSVM, so the rule-based classi002ers are not as ef002cient as their SVM coun-terparts and they have a higher error rate.2.3.3 K-Nearest NeighboursThe K-Nearest Neighbours 050KNN051 classi002er is a nonparametric lazy clas-si002er. In nonparametric classi002cation the algorithm does not assume anyspeci002c distribution for the data sets. Lazy classi002ers do not generalisethe classi002cation model and calculate the class of the item at the time oftesting instead of training, which makes training very ef002cient by reduc-ing the cost of testing time [30].KNN estimates items' classes according to their nearest neighbours. Themajority of the K nearest neighbours decide the class of the input item.An odd number of for K is selected 050between 3 to 9051 to prevent ties. Thenearest neighbours are decided using one of the distance measures 050e.g.Euclidean distance051, as shown in Figure 2.5 [2].
Figure 2.5: K-Nearest Neighbour Classi002cation with K = 5To prevent attribute bias due to different magnitudes of values it is stronglypreferred to normalise all attributes before classi002cation. Non-numericalattributes can also be used with KNN classi002cation, similar attributes20CHAPTER 2. BACKGROUND AND LITERATURE REVIEWwith the K neighbours have zero distance, and different attributes havethe distance of 1 [2].While this classi002cation algorithm is different from rule-based classi002ers,we used a variation of this classi002cation for temporal attributes, as ex-plained in chapter six, as a comparison with our proposed classi002cationalgorithm to test the performance difference between the algorithms.2.3.4 Classi002cation Performance MeasuresMultiple methods exist to measure the performance of a classi002cation al-gorithm and classify a data set into two classes, positive and classi002ed.The terminology was developed in the medical 002eld, where positive de-notes the presence of a disease and negative indicates its absence [31].In a test data set D with n instances, a classi002er tries to identify the classof instances for binary classi002ers, whereby four possibilities exist. Thesepossibilities for any classi002er can be demonstrated as a confusion matrix,which is shown in Table 2.1, and explained below [2]:017True PositiveTP: Number of correctly identi002ed positive cases bythe classi002er.017False PositiveFP: Number of incorrectly identi002ed cases as positivebut their true labels are negative.017True NegativeTN: Number of correctly identi002ed negative cases bythe classi002er.017False NegativeFN: Number of incorrectly identi002ed cases as nega-tive but their true labels are positive.To measure the overall performance of a classi002er directly from the con-fusion matrix we can calculate the accuracy and error rates. The accu-racy of a classi002er is the fraction of correctly classi002ed instances so that:212.3. CLASSIFICATIONTrue diagnosis
Positive
Negative
Total
Screening test
Positive
TP
FP
a+b
Negative
FN
TN
c+d
Totala+c	b+d	NTable 2.1: Confusion MatrixAccuracy=T P+T N
n. In contrast, the fraction of all misclassi002ed instancescomprise the error rate which is:ErrorRate=F P+F N
n[31].To measure class-speci002c performance we can use recall and precision.Recall is the ratio of correctly predicted number of a class labels to the realnumber of instances of that class in the data set. Recall for the positiveinstances in the data set is called sensitivity . The sensitivity is the ratio oftrue positive to the real number of positive cases in the data set so thatsensitivity=T P
T P+F N. Precision is a class-speci002c accuracy; it is the ratioof the number of correctly predicted instances of a class to the numberof predicted instances of the same class. A speci002c case of precision forthe negative class is called speci002city . The speci002city is the ratio of truenegative to the real negative cases in the data set so thatspecif icity=T N
T N+F P[31].For a classi002er, there is a trade-off between recall and precision; maximis-ing one of them might cause the other to decline. Consequently , measuresare introduced to overcome this problem and create a balance betweenthese two measures. F-measure is computing the harmonic mean of theclasses' recall and precision [2] so that:F=2
1
precision+1
recall=2002precision002recall
precision+recallArea Under the Curve 050AUC051 of receiver operating characteristic 050ROC051is a measure used to calculate the performance of machine learning algo-rithms such as classi002cation [32] . The ROC curve is a graph of the true22CHAPTER 2. BACKGROUND AND LITERATURE REVIEWpositive and false positive rates of the predicted classi002er's result com-pared to the real class for each item. Figure 2.6 shows ROC curves fordifferent algorithms with various performances. AUC is the area underthe ROC curve plotted as a performance result of the classi002er. Meth-ods of calculating AUC vary according to the nature of application andavailable data. The multi-class AUCs are calculated using the equationsof [33].auc=2
c050c0001051Paucs. Where c is number of classes and aucs is aset of auc between any two classes.
Figure 2.6: Receiver operating characteristic 050ROC051 curves for variousclassi002ers. From [5]2.4 ClusteringUnsupervised machine learning methods aim to 002nd patterns or groups050clusters051 in data sets so that the most similar items in the data set willbe gathered in the same cluster, and dissimilar items will be in differentclusters. The task of clustering is required in many 002elds, especially whenlittle information is known about the datasets, and 002eld experts have fewassumptions about it. Examples of 002elds in which clustering is requiredinclude data mining, pattern recognition, decision making, document re-trieval and image segmentation [6].232.4. CLUSTERINGIn this thesis, multiple clustering algorithms are used to cluster items ofeach time point in temporal data. Each time point was used separately , sothere is no time effect on the clustering because each time point is treatedas a separate data set. This clustering process is part of the proposedmethod to measure changes over time in temporal data 050as presented inchapter four051. We also used clustering multiple temporal clustering algo-rithms as a comparison with our proposed classi002cation method 050chaptersix051.Figure 2.7 shows the main steps of a clustering method. It can be noticedthat unlike supervised methods, clustering methods do not have trainingdata set to generate their model. Instead, they entirely depend on thegiven features of the items in the data set to group them into clusters.
Figure 2.7: General steps of clustering methods. From [6]The 002rst step in any clustering task is feature selection/extraction. Fea-ture selection refers to selecting a group of features 050attributes051 of theoriginal dataset which are most effective and representative for the in-stances or items which have to be clustered. Feature extraction is theprocess of deducing new features by transforming existing ones to ob-tain more effective features. The aim of feature selection and extractionis to obtain an effective and ef002cient clustering method by creating betterquality of clusters in shorter computation time [6].The second step is detecting pattern similarity by 002nding the distancesbetween items in the data set. Multiple distance measures are availableto measure the similarity between any two points in a hyperspace of fea-tures like Euclidean and Manhattan distances and correlation coef002cients[6].24CHAPTER 2. BACKGROUND AND LITERATURE REVIEWThe next step is the actual clustering process to identify patterns in datasets using one of the available clustering algorithms. There are multipleclustering algorithms which can be classi002ed into four types Centroid-based clustering, Density-based clustering, Fuzzy clustering and Hierar-chical clustering [2].The last step is feedback or clustering evaluation. There are many waysto evaluate the results of clustering algorithm, including using externalclustering validity indices to compare generated clusters with the trueclasses of the items or using internal clustering validity to evaluate thestructure of the clusters and the similarities between items of one clustercompared with dissimilarities with items of different ones [6, 2].2.4.1 Centroid-Based ClusteringCentroid-based or representative-based clustering is a method of 002ndingthe best k clusters of items in the D data set. Each cluster contains a rep-resentative point which might be called centroid [2]. Two examples ofcentroid-based clustering discussed below are K226means and PAM clus-tering methods.K226means ClusteringK226means clustering is partitional-based and produces k clusters, min-imising the distance between the centre of the cluster and cluster mem-bers. The criterion used to calculate the quality of the cluster is the sumof squared errors to the centroid. The aim of the algorithm is to 002nd cen-troids that minimise the sum of squared error for all clusters [2].The process starts by assigning k random items as centroids, after whicheach item is appointed to a cluster with the nearest centroid to it. Thelocation of the centroid is updated according to the existing items in the252.4. CLUSTERINGcluster. The process of assigning instances to clusters and updating cen-troids is reiterated until convergence 050i.e. the centroids stabilise051 or a 002xednumber of iterations has been reached [6].K226means works as a greedy optimisation algorithm so that it might con-verge to local optima [2]. Moreover, using the sum of squared error as acriterion for 002nding better clusters makes K226means sensitive to outliers,so that extreme values might distort the distribution of the data [6].PAM ClusteringPartitioning Around Medoids 050PAM051 clustering is another centroid-basedtechnique, but unlike K226means it uses actual instances of the data setas representatives for the clusters instead of virtual centroids. It uses asimilarity measure to identify members of a cluster. The members mostsimilar to a medoid are considered in the same cluster so that the sum ofsquared errors can be used with PAM algorithm to identify the quality ofclusters [34].Similar to K226means, PAM algorithm starts with random k set of medoids,then each instance is registered as a member of a cluster according to itssimilarity distance from the medoid. The sum of squared errors is cal-culated for the current set of medoids. In the original algorithm, differ-ent instances are selected as nominees for medoids to optimise the ini-tial state, and the sum of squared errors are calculated according to theselected instances [34]. If the selected instances perform better than theoriginal set of medoids then they will be replaced with the new ones. Thisprocess can be repeated multiple times until convergence. However, dueto the large time requirement and complexity of this method it is usuallyused only for small data sets, and for larger data sets a modi002ed versionof the original version is preferable to 002nd optimum medoids in an ac-ceptable time frame [35].26CHAPTER 2. BACKGROUND AND LITERATURE REVIEW2.4.2 Fuzzy ClusteringFuzzy sets are used in fuzzy logic and can be considered as a generali-sation of set theory . An element can be a member of a particular set ornot in set theory , while in fuzzy set theory an element can have a gradualtransition membership between sets. Hence, fuzzy clustering uses thefuzzy set to allow an instance to be in more than one cluster at the sametime [36].The most well known and used fuzzy clustering is fuzzy c226means al-gorithm, developed by Dunn [37] and later improved by Bezdek [6] whointroduced the concept of the fuzzi002er parameterm. This parameter, alsocalled 'fuzziness index', is used to control the fuzziness of the member-ship of each item in the data set. Usually , m = 2 is used without any par-ticular theoretical basis for this choice. For m = 1 the fuzzy c226means willbehave as k226means algorithm, and the fuzziness of the system increaseswith the larger value of m parameter [38].The fuzzy c226means algorithm has a similar approach as k226means algo-rithm. It requires a prede002ned number of clusters. Both algorithms startwith random initialization of the cluster centres so c226means might havethe same problem as k226means by converging to local optima. The resultof the cmean algorithm is expressed as a membership percentage of eachinstance to the available clusters. This fuzzy membership clustering canbe converted into hard clusters by choosing a cluster for each item withthe highest membership ration [36].2.4.3 Hierarchical ClusteringHierarchical clustering is a method to group instances of a data set into aseries of nested clusters or a tree of clusters called a dendrogram, whichrepresents the similarity level between instances in the data set. An ex-272.4. CLUSTERINGample hierarchical clustering is shown in Figure 2.8. The 002gure shows asimple two-dimensional data set with three distinctive clusters. The dataset is represented as in a hierarchical clustering model using a dendro-gram. The dendrogram can be cut at any level 050represented as a dottedhorizontal line051 to separate different patterns of the data set [6]. The levelof the cutoff line is subjective and may vary from one data set to another.Cutting a dendrogram from a higher level produces fewer patterns 050clus-ters051 [36].
050a051 Two dimentional data set with three obvoius clusters
050b051 Dendrogram of the data setFigure 2.8: A simple data set with a possible dendrogram for hierarchicalclustering algorithm. From [6]28CHAPTER 2. BACKGROUND AND LITERATURE REVIEWBased on the internal functioning of the hierarchical clustering algorithm,they can be divided into divisive and agglomerative types. The divisivemethod starts by assigning all instances into one cluster then partitionsthat cluster into two smaller clusters according to the similarities betweeninstances. The process of sub-dividing each subcluster into another twoclusters continues until each cluster contains single instance. In contrast,agglomerative hierarchical clustering starts by assigning each instance ofthe data set as a cluster, then starts to combine two most similar clustersinto a single bigger cluster. This process is repeated recursively until asingle cluster is achieved or a certain number of clusters are reached [2].Whether divisive or agglomerative approach is used, a prerequisite to be-gin clustering is a proximity matrix, a symmetric matrix containing thesimilarity between every point in the data set using a distance function.This matrix is updated after each iteration to re003ect the status of the dataset under the method of clustering. The distance function can be Eu-clidean, Manhattan or any other distance function [2]. Sections showshow time-based distance measures can be used to cluster temporal datasets.To determine the similarity between clusters using proximity matrix inagglomerative method, one of the available linkage methods can be used[36]:017Single linkage: calculates the minimum distance between any itemsof two different clusters.017Complete linkage: calculates the maximum distance between anyitems of two different clusters.017Average linkage: calculates the average distance between all itemsof two different clusters.017Centroid linkage: calculates the distance between centre of two dif-ferent clusters.292.4. CLUSTERINGDue to the time complexity hierarchical clustering can not be used withvery large data sets which can not 002t the memory . Moreover, the nature ofthe algorithm do not allow to reconsider the previous steps of the recur-sive clustering operation 050dividing or joining051 in contrast with the otherclustering technique which we see before [36].2.4.4 Clustering V alidationMany clustering methods exist to be used in different situations accord-ing to the underlying data to be analysed and clustered. There are manymethods to assess clustering results and their initial con002gurations, whichcan be categorised into three main types: clustering tendency , cluster sta-bility and cluster evaluation [2].Clustering tendency or clusterability assesses the suitability of the datafor clustering. The aim is to determine that the data has meaningful pat-terns to be clustered. The spatial histogram method for cluster tendencycreates a histogram for the input data set and distance distribution bycalculating the pairwise distance between data points. An example ofnon-clusterable data is uniform instances of a data set, as shown in Fig-ure 2.9 [2].Cluster stability is concerned with the initial parameters of clustering al-gorithms, like the number of clusters in K226means. The aim of this methodis to determine the optimum initial parameters for the clusters, so that thecluster of different samples of data from the same underlying populationguarantee comparable results. Methods of determining the stability ofclusters include generating perturbed versions of the data set, using dis-tance functions 050e.g. Euclidean051 and similarity measures like Rand index[39].Clustering evaluation can use cluster validity indexes to evaluate thequality of the produced clusters. This task can be further divided into30CHAPTER 2. BACKGROUND AND LITERATURE REVIEW
Figure 2.9: An example of uniform data which can not be clustered. From[2]three categories [15, 40, 2]:017External: External validation derives the estimation for the qualityof the generated clusters from sources outside the data set. Themost general case is using true labels of items, provided by 002eldexperts.017Internal: Internal validation derives the estimation for the qualityof the generated clusters using the structure of the data and the clus-ters. It computes the compactness of the clusters and the separationof clusters from each other.017Relative: External validation compares between the results of twodifferent clusterings for the same data set. The clusterings might begenerated using different clustering algorithms, or the same clus-tering algorithm with different initial parameters.The following subsections focus on the cluster validity indices, especiallythose used in this thesis.312.4. CLUSTERINGExternal CriteriaExternal criteria validate the results of clustering based on some prede-002ned structures of the data which is provided from an external source.The most well-known example of structural information is labels for thedata provided by experts 050called true classes051. The main task of this ap-proach is to determine a statistical measure for the similarity or dissim-ilarity between obtained clusters and labels [15, 41]. According to themethods incorporated in the external criteria, they can be divided intothree types: pairwise measures, entropy-based measures and matchingbased measures [2].As mentioned previously , the four types of classi002cation guesses evalu-ation are true positive, true negative, false positive and false negative.These terms are used in the terminology of external cluster validity , es-pecially when using pairwise measures, but with slightly different mean-ings to enable the evaluation of clusters in the same manner as classi002ca-tion [2]:017True PositivesTP: Any two instances with the same label that arein the same cluster.017False NegativesFN: Any two instances with the same label that arenot in the same cluster.017False PositivesFP: Any two instances with different labels that arenot in the same cluster.017True NegativesTN: Any two instances with different labels that arenot in the same cluster.In this thesis we use various external cluster validity indices to determinedifferences between a reference of behaviour for items in a temporal dataand clusters of items in each time point. The method is discussed in moredetail in chapter three, and implemented in chapter four for public goods32CHAPTER 2. BACKGROUND AND LITERATURE REVIEWgames and chapter six for stock market data. The used criteria in thethesis are listed below:Jaccard Coef002cient:This coef002cient is a pairwise measure representingthe degree of similarity between clusters. With this coef002cient each clus-ter is treated as a mathematical set and the coef002cient value is calculatedby dividing the cardinality of the intersection of the resultant cluster withthe prior cluster to the cardinality of the union between them [42]:Jaccard=T P
T P+F P+F NWith a perfect clustering, when false positives and false negative equal tozero, the Jaccard coef002cient value equals 1. This measure ignores the truenegatives and only focuses on the true positives to evaluate the qualityof the clusters [2].Rand Statistic:The Rand statistic measures the fraction of true positivesand true negatives over all point pairs; it is de002ned asRand=T P+T N
NWhere N is the total number of instances in the data set. This measureis similar to Jaccard Coef002cient, so its value equals 1 in perfect clustering[2].Fowlkes-Mallows 050FM051 Measure:FM de002ne precision and recall valuesfor produced clusters [43]F M=p
prec:recall=T P
p
050T P+F N051050T P+F P051Whereprec=T P
T P+F Pandrecall=T P
T P+F N. For the perfect clustering thismeasure equals 1 too [2].V ariation of Information VI:This index measure is based on contin-gency table which is a matrix withr002k, whereris number of producedclusters andkis the number of externally provided clusters. Each ele-ment of this matrix contains a number of agreed instances between any332.4. CLUSTERINGtwo clusters of the externally provided and produced clusters. As intro-duced by Meila [44], this index calculates mutual information and en-tropy between previously provided and produced clusters derived fromthe contingency table:V I050C; T051 = 2H050T; C051000H050T051000H050C051WhereCis produced clusters,Tis ground truth clusters,H050C051is entropyofCandH050T051is entropy ofT[2].Internal CriteriaInternal criteria measure the 'goodness' of clusters for the data by extract-ing information from data and clusters alone, such as the compactness ofdata points inside one cluster and the separation of clusters from eachother [41]. These criteria were used as part of the cost function, to deter-mine the quality of the selected classi002cation rules in each time point, andto compare different clustering algorithms' performances, as presented inchapter six.Dunn Index:This index calculates the ratio of minimum distance be-tween clusters to the maximum distance between any two instances ofthe same cluster [45]:Dunn=min16i6c032min032d050ci; cj051
max16i6k050d050Xk051051033033Whereci; cj2cof sizemand the maximum distance can be computedfrom the mean or between all pairs. A larger value for Dunn index means,better clustering output, because it means that the closest instances be-tween two clusters are larger than the distance between two farthest in-stances in the same cluster [2].Davies-Bouldin Index:This measure is introduced by Davies et al. [46].It calculates intera cluster compactness and inter cluster separation by34CHAPTER 2. BACKGROUND AND LITERATURE REVIEWproducing the ratio of spreading sample points around mean 050i.e. varia-tion051 to the distance between mean of clusters [41].DB=1
kkXi=1kXj=1maxi6=j032s026i+s026j
016050026i; 026j051033Wherekis number of clusters,s026iands026jare the spread of points aroundany two clusters cluster mean 224Centroid224, and016050026i; 026j051denotes the meanof both clusters.A smaller value of this measure indicates better the clustering, as in suchcases the clusters are well separated and each cluster is well representedby its mean; in other words, larger values mean better compacted in-stances in the clusters and clusters that are well separated from each other[2].SD:This measure is introduced by Halkidi et al. [47]. It calculates theaverage scattering for clustering and total separation among clusters.SD=a002Scatter+DistributionWhereais a weighting factor equal to the maximum distance of two in-stances in the data set. TheScatterindicates the average compactness ofclusters. A smaller value ofScatteris a signal for a compact cluster, andits the value increases for less compact clusters. TheDistributionis themeasure of the total separation between clusters. A larger valueScatterindicates better clustering and smaller value of this term indicates greaterproximity between clusters to each other.ScatterandDistributionhavedifferent ranges, so thata050the weighting factor051 is important to maintainthe balance between them. As SD measure is a total ofScattererandDistributionso that the smaller SD value indicates better clustering [47].S
Dbw:This measure is introduced by Halkidi et al. [48]. The S
Dbwindex is similar to SD index as it measures the intracluster and interclus-ter variances [41]. The de002nition of S
Dbw indicates that both criteria of352.5. TEMPORAL DATA ANALYSIS224good224 clustering 050i.e. compactness and separation051 are properly com-bined, enabling reliable evaluation of clustering results.SDbw=Scatter+DensbwAs with SD, theScatterindicates the average compactness of clusters,smaller smallerScattervalue indicating a compact cluster, with an in-creased value for less compact clusters. Dens
bw050c051 indicates the inter-cluster density by calculating the average number of points between theclusters in relation with density within clusters, thus a small value ofDens
bw means good separation among clusters. As in SD, a smallervalue of this measure is an indication of well de002ned clustering [48].Relative CriteriaRelative criteria are used to compare between two clusterings with samedata and clustering algorithm but different initial parameters, like num-ber of clusters [40]. These criteria mostly use internal clustering validityindices like Dunn index and Davies-Bouldin Index to compare betweenclusterings' initial parameters [49]. On the other hand V endramin et al.[42] proposed a novel method to compare relative criteria, using externalcluster validity indices like Jaccard and Rand.2.5 T emporal Data AnalysisTemporal data analysis is concerned with mining and analysing sequen-tial data sets [50]. A sequential data set is ordered according to someindex. A special case of sequential data is temporal data, which is or-dered according to a time reference. According to Han et al. [51], 224Atime-series database consists of sequences of values or events obtainedover repeated measurements of time.224 In this thesis we use the terms224time series224 and 224temporal data224 interchangeably . Sequential data sets36CHAPTER 2. BACKGROUND AND LITERATURE REVIEWcan be used in applications to study protein order series, DNA sequenceand lists of moves in a chess game. Examples of temporal data includestock market data and public goods game data set. Data streams can beconsidered as a special case of temporal data with an endless sequenceof 003owing data, such as satellite remote sensor, data from electric powergrids and telecommunications data [51].In the following subsections we discuss methods to measure changes intemporal data as well as classifying and clustering them.2.5.1 Measuring Changes in T emporal DataSpiliopoulou et al. [52] introduced the MONIC model, which 002nds clus-ter transition over accumulating data sets, providing an ageing functionfor clustering data that prioritizes new records over old ones and elimi-nates records older than two time points. Matching for clusters in onetime point to the next one is carried out by passing a threshold thatdetermines normalized maximum number of records that exist in bothmatched clusters in the two time points. This model de002nes two kinds oftransitions, external and internal. In external transition clusters may sur-vive, split, be absorbed, disappear or emerge, while in internal transitionclusters can change in size, compactness or location.According to MONIC, each cluster has a lifetime, which is the numberof time points throughout which it can survive. Longer cluster lifetimesenable more predictable clustering while short lifetimes lead to volatileand unpredictable clustering.It can be observed that this model relies on accumulated data over time todetect cluster matches, therefore it cannot be used with non-accumulateddata. Moreover, it emphases the measurement of cluster changes andcannot detect changes in cluster membership for individual items clus-tered over time points.372.5. TEMPORAL DATA ANALYSISGunnemann et al. [53] introduced a method which traces cluster evolu-tion as change in behaviour types indicated by the value of objects 050e.g.persons051 in high-dimensional data sets. Different types of mapping func-tion were introduced to map clusters according to their values in differentdimensions and subspaces instead of object identi002er.Using this method cluster evolutions were detected and counted in theforms of emerge, disappear, converge and diverge. Moreover, the lossand gain of dimensions of subspace clusters were calculated.This method counts the number of various changes that occur to clustersof any high dimensional data set, but it lacks to any mean by which toquantify the changes themselves; in other words, there is no indicationof the quantity of change that happens to any cluster in two consecutivetime points.Hawwash et al. [54] proposed a framework for mining, tracking andvalidating clusters in a data stream using statistical cluster measures likecardinality , scale and density of clusters to detect milestones of clusterschange and monitor the behaviour of cluster.This framework targets accumulative clustering on data streams, but in-stead of using 002xed-time window for clustering it uses milestones to de-tect the next-best clustering time.Hawwash et al. [54] used a linear model in their metrics, which cannotrepresent real-life situations. They made this concession due to time lim-itations and the memory complexity of higher degree models. With someenhanced models this method could be pro002tably used to determine crit-ical time points in the data stream clustering and to track clusters be-haviour in general using statistical measures for representative numberspertaining to the situation of clusterings.Kalnis et al. [55] introduced a method to discover moving objects in thesnapshots of spatio-temporal data using cluster mapping function, treat-38CHAPTER 2. BACKGROUND AND LITERATURE REVIEWing clusters as sets and calculating the cardinality ratio of intersection foreach two time constitutive clusters over their union; if the ratio passes acertain threshold the cluster is considered to be a moving cluster.This method detects move in overall clusters and provides visual aidsenabling human experts to grasp changes in the underling data [56, 57].This method is excellent for tracking moving cluster change [58] , butit still lacks a method to quantify the magnitude of change for overallclustering objects.Aggarwal [59] introduced a new method to detect changes for single clus-ters in the data streams that also works for snapshots of data as specialcases. This method uses forward and reverse time slice density estimatesbased on 002xed length time window to calculate velocity density at timeand space dimensions.By calculating velocity density three types of change can appear on theclusters in evolving data streams: 1051 they may coagulate if the valuepassed a user speci002ed threshold; 2051 they may decay if the value doesnot pass the threshold; or 3051 they may shift their location to another. Thismethod is particularly germane to visually understanding the character-istics of underlying data.In summary , the previously mentioned methods: 1051 are mostly designedto work with data streams or snapshots of spatio-temporal data sets; 2051detect changes inside data by monitoring cluster change in terms of split,absorbed, disappear and emerged etc., which is a good indication fordetecting existence of change, but which does not specify the magnitudeof change. Our aim is to create a simple factor 050scalar051 to express themagnitude of change among members of clusterings in temporal datasets.392.5. TEMPORAL DATA ANALYSIS2.5.2 T emporal Classi002cationTemporal and sequence classi002cation is an automatic system that assignsone of the prede002ned classes to the time series or sequence input [50].Many temporal classi002cations have been introduced that reuse traditionalclassi002cation algorithms in terms of criteria and measurements craftedfor temporal data. Three main methods exist for classifying temporaldata set: distance226based, feature extraction226based and model226based [60,50].Wang et al. [61] proposed a rule-based classi002cation method for cate-gorical and high-dimensional data sets that relies on calculating frequentitem sets using frequent pattern mining and association rules, then usingthe highest con002dence sets covering rules for grouping according to ruleheads 050class labels051. This method has been found to result in an ef002cientand accurate rule-based classi002er, but it might produce a very large num-ber of rules, as they are extracted from association mining, which mightbe hard for humans to follow and comprehend. Moreover, to create thefrequent item test it is required to have training data sets, which mightbe expensive and labour intensive to acquire and deploy .It is possible to use traditional classi002cation algorithms 050non-temporal051 toclassify temporal data set by using distance measures specially designedto evaluate distances in a temporal data set. Many temporal supervisedand unsupervised algorithms use dynamic time warping 050DTW051 [62] toalign between two sequences or time series and 002nd the distance betweenthem. This method was originally used in speech recognition to identifyhuman speech patterns [63].Dynamic time wrapping tries to 002nd best match between two time se-ries to calculate the smallest distance between them, unlike Euclideandistance, which uses one-to-one mapping between the same time pointsregardless of any time shift. Figure 2.10 compares these two distance40CHAPTER 2. BACKGROUND AND LITERATURE REVIEW
Figure 2.10: Difference between time alignment and Euclidean distanceof two time series. Aligned points are indicated by arrows. From [7]measures. Dynamic time wrapping creates wrapping matrix which con-sists of Euclidean distances between every two points in both time series,then a local cost function 002nds the shortest path between two time se-ries that represents the best match. Dynamic time wrapping has beenimplemented successful in numerous temporal classi002cation and cluster-ing methods, but it has a drawback in using heuristic methods, whichare inef002cient due to searching for the best path in the wrapping matrix[7]. The wrapping matrix and time wrapping distance between two timesierras are shown in Figure 2.11.
Figure 2.11: Calculating the distance between two time series usingwrapping matrix. From [7]Distance-based K-Nearest Neighbours classi002cation method 050KNN051 is usedwith temporal and sequential data with Euclidean distance measure [64].However, for complex time series, Euclidean distance is sensitive to thetime 003uctuation; thus DTW has been used [65]. Figure 2.12 illustrates412.5. TEMPORAL DATA ANALYSIS
Figure 2.12: K-Nearest Neighbour with dynamic time wrapping. From[8]temporal KNN operation.It is possible to use feature extraction in order to extract useful featuresfrom time series so that it become possible to use traditional classi002cationmethods to classify temporal data. Agrawal et al. [66] proposed the useof the Discrete Fourier Transform 050DFT051 to transform a sequence fromthe time domain to the frequency domain. Using DFT allows selectionof the most important frequencies then representing them back in theoriginal dimensional space. The DFT has an important property as it canignore shifts and 002nd similar sequences, because the Fourier coef002cientis invariant for shifts.Chan et al. [67] used Discrete Wavelet Transform 050DWT051 to translate eachtime series from the time domain into the time/frequency domain. Thistransformation is linear as it changes the original time series into variousfrequency components in a lossless transformation. The sequence is thenrepresented by its features, expressed as wavelet coef002cients. Only a se-lected number of coef002cients are necessary to represent the original timeseries, which allows a better and ef002cient use of the available classi002ca-tion algorithms.Douzal-Chouakria et al. [68] used classi002cation trees to classify time se-ries data by introducing new splits for the tree nodes using time series42CHAPTER 2. BACKGROUND AND LITERATURE REVIEWproximities, relying on adaptive metrics considering behaviours and val-ues. Other methods use SVM as a temporal data classi002er using differentkernels [69].Model-based classi002ers can also be used for temporal and sequential clas-si002cations, like Naive Bayes sequence classi002er [70] and Hidden MarkovModel [71]. In the training step, the parameters of the model are createdand trained depending on some assumptions, and a set of parametersdescribing probability distributions. In the classi002cation step, a new se-quence is assigned to the class with the best possible similarity [72].2.5.3 T emporal ClusteringClustering is an unsupervised machine-learning method whose goal is to002nd natural groupings 050clusters051 of instances in data sets. All clusteringmethods strive to detect compacted clusters by maximising the total sumof inter-cluster distance and minimising the total sum of the intra-clusterdistance between instances [73]. The distance can be measured usingEuclidean distance, DTW distance, or any other similarity measures.Jebara et al. [74] used hidden Markov model 050HMM051 to cluster time se-ries data, while Oates et al. [71] compared two methods for clusteringtime series data sets, 002rst using HMM alone and then using DTW withHMM.DTW returns the minimised area between two time-series vari-ables, which can be used as a similarity measure between them. Theyconcluded that using DTW enhances the ef002ciency and effectiveness ofthe clusterings of the time series data set.Rodrigues, Gama and Pedroso [75] used hierarchical clustering to clustertime series data sets. A hierarchical clustering method works by group-ing item into a tree of clusters. The tree can be generated in two ways, ei-ther by starting from single items then agglomerating them into a higherstructure, or starting from the entire data set and dividing it until ends432.6. APPLICATIONSup with single items in each branch of the tree [76]. Another methodused a scaled-up version of DTW [77] with hierarchical clustering, whichcalculates the distance between temporal variables ef002ciently .Soheily-Khah et al. [78] proposed k226means-based clustering for tempo-ral data sets using DTW, the Dynamic Temporal Alignment Kernel, andthe Global Alignment Kernel. Items of a data set are partitioned by k226means clustering, minimising the total distance of items to a centre of theclusters chosen randomly at the initial stage, but later recalculated in aniterative manner, and items are allocated to the nearest centroid to formclusters with minimum intra-cluster distance [2].2.6 ApplicationsIn this thesis two types of temporal data sets are used as case studies pub-lic goods games and stock market data sets. The following subsectionsbrie003y describe each one of them with use cases in the data mining.2.6.1 Player Types and Behaviour Public Goods GamePublic good is any service or resource that cannot be withheld from anyindividuals due to inalienable characteristics relating to citizens' rights[79]. Examples of public good resources include city parks, street light-ing and roads, which are funded by the state but which are available toall. The public goods game is an experimental game that simulates realsituations of public good in a lab with controlled conditions and focusedpurposes of conducting experiments. There are many slightly differentvariations of this game, but the data been used in this paper as a casestudy is based on the model of Fischbacher et al. [11].The public goods game experiment of Fischbacher et al. [11] consists offour players, each of whom has a choice to contribute to a project repre-44CHAPTER 2. BACKGROUND AND LITERATURE REVIEWsenting the public good. After all players have made their choices of con-tribution the game is 002nished, and their outcomes are revealed to them.Players are then redistributed to play with other new partners for an-other round of the game. Obviously it is assumed that players mightadjust their strategy of contribution and learn general players' behaviourin previous games. For every round, each player has 20 tokens to playwith representing money , which they can contribute with, and after theend of the experiment they will be exchanged for real money , to ensurethat players are playing thoughtfully .Gaining the maximum amount of tokens is the main goal of each player,and it is the basis for determining whether players change their behaviourin the next round or not. As each player has 20 tokens, they can con-tribute all, none or any amount to projects representing the public good,so that the total amount of contribution of all players and its extra ben-e002t is distributed among them evenly . The amount of gain for a playeri 050gaini051 is demonstrated by the equationgaini= 20000gi+ 0:4P4j=1gj,wheregiis the player's own contribution andgjrepresents all players'contributions. To illustrate this equation: 0501051 if no player contributes inthe project then each will end up with 20 tokens as they started; 0502051 if allplayers contribute with 10 tokens then each player will end up with 20-10+0.4 05010+10+10+10051 = 26 tokens; and 0503051 if only one player contributeswith all 20 tokens while the others do not contribute, then she will endup with 8 tokens while all others will gain 28 tokens.Regardless of players' potential adjustment of their contribution behaviourduring multiple rounds 05010 rounds or more051, economists [80] classifythem based on a contribution table of static data 002lled once by the play-ers before the game rounds. This table consists of players' answers for ahypothetical rounded average contribution of others. For each possiblecontribution from 0 to 20 tokens, as an average, from her partners sheshould decide how much she is willing to contribute. Naturally , this ini-452.6. APPLICATIONStial willingness for contribution might change due to the factor of learn-ing about other players' contribution behaviour, which causes conceptdrift throughout game time points 050rounds051. The classes as de002ned byeconomists are:017Conditional Co-operator: players who show more willingness tocontribute when other players contribute more.017Free Riders: players who do not contribute to the project regardlessof other players' contribution status.017Triangle Contributors: players whose contribution rises to a pointthen starts to decline in relation other players' contributions.017Others: players with no clear pattern in their contribution style.Burlando et al. [81] described another type of player called pure or un-conditional contributors, who contribute regardless of the behaviour ofthe other players. In the model above, This type of contributor is mergedwith the others which are unclassi002able group according to the Fischbacher's[80] rule for classi002cation. Rustagi et al. [82] split the conditional contrib-utors into two parts according to the signi002cance of their contributions.2.6.2 Stock Market Classi002cationIn this thesis the proposed method of classi002cation is deployed to clas-sify stock market data according to stability; this classi002cation might bean important tool for market forecasters. The proposed method for rule-based temporal classi002cation has an advantage of classifying stocks ac-cording to a set of loosely de002ned rules presented by human expertswithout the need for a training data set. In addition, we present the pro-posed method of measuring changes over time as a tool to participate inthe debate of cluster predictability by measuring changes over time, andcomparing stability classes of the stocks for two consecutive quarters of46CHAPTER 2. BACKGROUND AND LITERATURE REVIEWthe year.The economists' debate on stock market predictability is not settled, withone group emphasising the essential randomness of the stock market,thus precluding any possibility of future price prediction-based on his-torical values [83]; and another group claiming that market prices havean element of predictability [84].Subha [85] used KNN to classify the Indian stock markets BSE-SENSEXand NSE-NIFTY for the period from January 2006 to May 2011. The aimwas to determine the predictability of the stock market by predicting thefuture prices. He used Euclidean distance to determine the differencesbetween any two stocks. He concluded that the square error of the pre-diction and actual prices was small, so the opportunity for forecastingmarket prices is tangible.2.7 ConclusionThis chapter presented the available, well-known and traditional non-temporal classi002cation methods as well as classi002cation assessment ap-proaches, and discussed temporal classi002cation methods including fea-ture extraction and dynamic time wrapping methods. It can be con-cluded that most of the available classi002cation algorithms 050temporal andnon-temporal051 require training data sets to construct their classi002er mod-els, thus we introduced a temporal classi002cation method which optimisesrules provided by 002eld experts.From the available literature it is clear that there is no suf002cient researchtoward producing understandable rule-based classi002cation algorithmsespecially for temporal data sets. As we pointed out in chapter one thereis a need for a temporal classi002cation algorithm which economists canunderstand and amend its rules easily . This approach of directly col-472.7. CONCLUSIONlaborating between experts and machine learning algorithms to produceclassi002cation rule might open a new way of studying public goods gamesplayers behaviour and other similar behavioural experiments. Moreover,this proposed algorithm might be generalised to classify other temporaldata sets like stock market data set as we will see in chapter six.Multiple algorithms are discussed for measuring changes over time 050likeMONIC051, but these methods are mainly used to determine cluster changesand focused on changes in the entire pattern. In this thesis, we present amethod which 002xes the number of clusters and focuses on the changes ofindividual items between time points of a temporal data set. This methodcan detect the behaviour change of the public goods game players whichis important determine the strategy change of the players regarding dif-ferent game set-ups. The proposed method will be used to detect theamount of change over time for stock market data. Detecting changes inthe stock market might present a tool for economists to settle the argu-ment on the ability to forecast stocks.Our proposed method for measuring behavioural changes over time usesnone-temporal clustering algorithms to identify similar groups of be-haviour at each time point and external cluster validity indices to mea-sure change between clusters 050Will be discussed in more detail in chap-ter three051. So that this chapter also covers well known and widely usedclustering methods and the cluster validity indices which can be used toimplement this method.Finally , this thesis uses multiple data sets from different 002elds, namelythe public goods game and the stock market, so a brief introduction tothese two topics was given.48Chapter 3Methodology3.1 IntroductionThis chapter centres around three main subjects. The 002rst provides a de-tailed description to the problems and questions posed in the 002rst chap-ter. The second offers a methodology to solve these problems and propos-ing methods to implement these solutions. The third introduces a num-ber of data sets for testing the methodology and proposed methods forsolving the problem.Our main concern is how to measure the behaviour of the same popula-tion at two different time points. The 002rst step was acquiring data thathas multiple records for same items' behaviour at different time points050This will be discussed in detail later in section 3.7051. We had obtained thedata with the aforementioned speci002cation in public goods game exper-iments as the same players were playing multiple rounds of the experi-mental game and their contribution behaviour recorded.To create a scalar which could be used as an indicator for the magni-tude of the recorded populations' behavioural difference between anytwo time points, we reused the existing methods of cluster validity . Theoriginal purpose behind external cluster validity methods is to 002nd the493.2. FORMALISING THE PROBLEMdifference between the ground true classes that the items have and thelabels which are provided to them by a particular clustering algorithm.However, there were concerns about comparing any two time pointsamong multiple time points as they might not have been an accuraterepresentation of items' behaviour. Therefore, the recordings of items be-haviour had to be compared to an overall general behaviour of the items.To overcome this concern the items behaviour were classi002ed prior to thecomparison.The existing items in the data set had to be classi002ed using one of thetemporal classi002cation methods in order to obtain the general behaviourof the items. However, it might have been challenging to train a classi002ermodel as the items 050players051 did not have prede002ned classes based ontheir behaviour over time. To overcome the lack of the label for items weproposed a method for optimising rule-based temporal classi002cation.3.2 Formalising the ProblemConsider a temporal data set TD which consists of T time points andeach time point has records for properties of N items. The main aim ofthis study is to 002nd a function which produces a scalar measure M whichcan quantify the amount of change that occurs on the items between anytwo time points. The aim can be represented in this simple equationM=016050T D[i]; T D[j]051when i, j are integer numbers representing the time pointorder in the data set and TD[i], TD[j] are static data records for items in aspeci002c time period.Items can be any object which has recorded properties over time. Asde002ned by Ra002ei [86], time series is a sequence of data with a 002xed timeintervals between them. According to this de002nition, each item in ourtemporal data is a time series. Moreover, each item can have single or50CHAPTER 3. METHODOLOGYmultiple recorded properties they can, therefore, be single dimensionalor multidimensional time series [87]. However, as the problem is to 002nda measure of the items' difference between two time points, it is better tomodel the data around time points rather than items and consider eachtime point as a snapshot of the speci002c time for items' property records.Figure 3.1 compares between these two different models of the data.
050a051 Focusing on time series individuals in the data
050b051 Focussing on the time pointsFigure 3.1: Two different models focussing on temporal data. The 002rstone focuses on the individual time series items while the second focuseson the time points and evaluates items according to their value in thattime point.Before 002nding items' behavioural difference between any two time points,we had to 002nd the categories for the behaviour of the items and howto group items according to these categories. It is important to cate-gorise these behaviours so that neither nuance changes nor the shift of513.3. MEASURING CHANGES OVER TIMEall groups are considered as a change in behaviour. For example, if wehave two groups 050poor and rich051 of people's behaviour regards annualexpenditure a slight change in the expenditure can not be considered as asigni002cant change of behaviour, one that changes its status from poor torich or vice versa. Moreover, a change of expenditure for the entire cate-gories' might not be an indication of the change of behaviour. Instead, itmay be due to in003ation.Another issue which could affect how to measure differences betweentime points in a data set with multiple time points 050more than two timepoints051 is what to consider as a normal reference behaviour of the item.By normal behaviour, we mean the general behaviour throughout in theirdata set. The 002rst data point or any particular data points might not bea representative behaviour of an item. Therefore, this problem has alsobeen addressed using different approaches in the study .3.3 Measuring Changes Over TimeMeasuring behaviour differences of items between time points requiresthree steps: The 002rst step is to address time points, the second step isgrouping similar behaviour and the last step is to 002nd and measure theamount of differences between these time points. These steps will beaddressed in the following paragraphs, and will be implemented andtested on the data in the next chapter.The temporal data has to be split into separate time points. If the tempo-ral data has discrete records of time, then each timestamp can representa single time point. If the data set has continuous timestamps, then itmight be converted to discrete using 002xed intervals of time windows asused by many studies like [52]. It might be preferable that the time pointshave similar intervals between them so that the behavioural change mea-sure M can represent the difference between any two time points in the52CHAPTER 3. METHODOLOGYsame data set uniformly . Moreover, the items in each times point have toappear exactly once. This means if the items appear more than once ineach time point an average value can be evaluated for the window. Asan illustration considert2Tand the time intervals between [t-1, t] and[t, t+1] are equal which makesm1 =016050t0001; t051andm2 =016050t; t+ 1051, so m1and m2 can represent the two de002ned time intervals uniformly .The second step is grouping similar behaviours of the items in the dataso that we can identify each items' category of behaviour at every par-ticular time points. As de002ned by Estivill-Castro [88] clustering is thetask of 002nding groups of more homogenous 050similar051members in a het-erogeneous group of objects. Each time point is, thus, clustered usingone of the clustering methods to 002nd similarly behaving groups at eachtime point. The clustering algorithms used in the process of measuringthe difference between time points in this study are K226means, PAM, andhierarchical clustering. Please refer to the previous chapter for the de002-nitions and properties of these clustering methods.Clustering items in each time point eliminate both the problems intro-duced in the previous section, namely potential minor changes in be-haviour and the shift of all items in the same group. These problems aresolved by clustering each time point separately without being in003uencedby other time points. Clustering will ensure that any values attributedby minor changes in items do not affect their membership in the group,and clustering each time point's data independently ensures that the en-tire movement of a group will not affect the measures of items' behaviourchange. Please see Figure 3.2 for further illustration.The last step is to 002nd the number of items which have changed theirbehaviour signi002cantly so that they can be counted as they are in othergroups or using the percentage of items' behaviour change. This means002nding the016function as described in the previous section. It is also pos-sible to use AUC of ROC to 002nd the difference between items' clusters533.3. MEASURING CHANGES OVER TIME
050a051 Original dataset
050b051 Small behaviour changes
050c051 Entier group shiftFigure 3.2: Three 002gures illustrating the small changes and the entirecluster move between two time pointsin any two consequent time points by using cluster labels of t and t+1instead of true class labels and predicted classes by a classi002cation modelas inputs to the AUC function so that it 002nds the difference between thesetwo time points.However, straightforward counting of items in clusters or using cluster-ing labels as classes of the items might not be possible as it is hard to002nd one to one matching between clusters in consequent time points asdescribed by Gunnemann et al. [89] and Xu et al. [90]. Therefore, weuse external cluster validity indices to compare between clusters of twotime points and we replace the external labels with t cluster labels andguessed clusters by a clustering algorithm with t+1 cluster labels. Thismethod can present a scalar measure as an indication of how much dif-ference there exists between any two time points.54CHAPTER 3. METHODOLOGYMultiple tests are implemented in Chapter four to check that this methodcan re003ect the change in items' behaviour which is happening to the clus-ters 050same behaviour grope051. The tests include multiple external cluster-ing indices as well as 002nding cluster pairs across time points so that othertechniques like AUC can be tested. However to solve the problem of be-haviour reference for the items as described in the previous section a newclassi002cation method is proposed. This will be elaborated on in the nextsection, and the detailed implementation of it in Chapter 002ve.3.4 T emporal Rule-Based Classi002cationThis section describes and explains the methodology for implementingthe proposed rule-based temporal classi002cation. As it has become obvi-ous by now, this method targets temporal data with univariate or multi-variate attributes. However, as stipulated by economists, the experts ofpublic goods game, the rules should be presented in a simpli002ed way , onehuman agents can understand. This provides simplicity and clarity withregards the rules for classi002cation, and are expressed by using aggregatedattributes which are derived from the temporal attributes. However, the002nal rules are formulated by considering of the temporal origin of theseaggregated attributes.To achieve the con003icting goals of simplicity and consideration of thetemporal attributes the classi002cation process is divided into two mainsteps; rule generation and rule optimisation 050as shown in the Figure 3.3051.In the 002rst step, rules are expressed using aggregated attributes of itemswith ranges of [min, max] values for each rule. In the second step, thisrange is optimised using temporal attributes to 002nd the best cut in theprovided range and select a single value for the rule.This method might be both more effective and 003exible than using ag-gregated attributes alone to classify items as it provides the 003exibility to553.4. TEMPORAL RULE-BASED CLASSIFICATION
Figure 3.3: The 003owchart of the proposed rule based temporal classi002ca-tionoptimise rules in various ways: First, the aggregated attributes can bedriven and optimised from different sets of items' temporal attributes.Second, it provides a way to include multiple inconsistent or overlap-ping ideas of experts on boundaries of classes, and by optimising theserules, the best possible classi002er will be produced. This data set mightbe bene002cial for cases when the items have both temporal and static datalike expenditure behaviour 050temporal051 and career specialisation. Startingwith a 003exible model of rule-based classi002cation and then determiningthe cut with an optimisation process might solve the problem of over-002tting. This is because there is no requirement for the new data in thedata set to follow the 002nal cut of the old data, and the optimizer mightgenerate slightly different values for 002nal rules.3.4.1 Generating Initial RulesProviding 003exible rules for class boundaries is the 002rst step of the tempo-ral rule-based classi002cation. To obtain these initial rules, this classi002ca-tion mainly relies on the experts of the 002eld of knowledge for the data set56CHAPTER 3. METHODOLOGYand the intended items to be classi002ed to obtain. As mentioned, the rulesshould be easy to read and interpret by human experts so that the pro-vided rules are classifying temporal data sets on the basis of aggregatedfunctions for each time series. However, the 002nal result will also dependon the time dimension of the items.There are numerous ways of using experts' knowledge to create classesboundaries to classify items. The most accessible method is to use theirde002nition for the classes to create the rules for them. However, the def-initions might not exist or can not be applied directly to the data. Thesecond method involves asking their opinion on the rules of each classfor the existing data. Experts' opinion can be developed interactively inmultiple stages by creating pro002les for items and viewing the results ofprevious rules that they have provided. Items' pro002les illustrate theirproperties in a way that experts can create their opinion about the rulesfor the underlying data set.To provide simple rules for classes so that they can be used by humanagents to form de002nitions from them, complex temporal attributes haveto be aggregated using one of the available functions such as the mini-mum value, maximum value, mean, mode, median and standard devia-tion. Each time series of the temporal data 050items' speci002c data051 can be ag-gregated using one or more of the aggregation functions so that suf002cientquality and quantity of attributes are created to meet the requirements ofthe rules.By 003exible rules, we mean that each rule 050or condition051 has a range ofcandidate values which might 002t it. The general form of the rule can bewritten asAttributefOPgV alue. TheAttributecan be any static propertyof the items either derived from a temporal attribute of the items usingan aggregation function or other static values which are in the data setrecorded separately from any temporal attribute. TheV alueis a vectorwhich contains all possible cuts between two classes. It can be expressed573.4. TEMPORAL RULE-BASED CLASSIFICATIONas [min, max] pairs to represent the beginning and the end of the range ofthe cut between two classes in its dimension. ThefOPgcan be any of thecomparison operators likef6;>; <; >;=and6=g. The classes might havemultiple conditions which represent the boundaries of the class. Theseconditions can be combined using logicaland==oroperators. Figure 3.4shows an illustration for ranges of values created by using 003exible rulesfor two attributes to split items into different classes.
Figure 3.4: An illustration of the ranges which splits between neighbor-ing classes. These ranges will be changed into crisp lines after optimisa-tion processThe range value [min, max] of two neighbouring classes for the same at-tribute might overlap due to the differences in experts' opinions abouteach class limits or from slightly different de002nitions for each class. Toprevent an item possibly falling into two classes at the same time due tothe overlapping problem, the classes have to be prioritised. This meanswhen an item ful002ls the condition of the higher priority class, there isno need to check for lower priority classes. This might be done usinga nested if-else statements. Moreover, the lowest priority class mightbe without any condition because if an item does not fall into any class58CHAPTER 3. METHODOLOGYcategory , they might be in the last one. However, if conditions are notused for the least priority class, a careful design for higher priority classesshould be undertaken to prevent ambiguity or it might be better to con-sider a non-exclusive label for the last class like others or not-determined.The next step focuses on changing the ranges of values of rules into singlevalues by using temporal attributes of the items.3.4.2 Optimising Initial RulesThe result of the 002rst step of temporal rule-based classi002cation is creatinggeneralized rules with indeterminate boundaries of classes for classifyingitems. In the second stage, the boundaries of classes will be convertedfrom vector ranges of values to scalers with a single value. Figures 3.4and 3.5 should be compared to provide an illustration of the task for thisstep of classi002cation. To link temporal features of the items and their cor-responding non-temporal aggregate attributes, which are generated tocreate rules for classi002cation, this stage will use temporal data to decideon choosing a scalar among the provided range of values.For each provided vector in the rules, this step 002nds the best scalar todivide adjacent classes. The point is considered as the best dividing pointwhen it produces the most compacted classes of items at every time pointusing the temporal features to measure the distance between items. Thisprocess can be accomplished by iterating through all possibilities of thevalue ranges for the rule-based classi002ers, as implemented in chapter 002veor using a heuristic search algorithm as implemented in chapter six usingDifferential Evolution. See algorithm 3.1 for the brute force method todetermine the best classi002er.The classi002cation step uses provided rules with a single value for eachrange of the values. If the value ranges are continuous, they should bediscretised into acceptable discrete values. Selecting the acceptable dis-593.4. TEMPORAL RULE-BASED CLASSIFICATION
Figure 3.5: An illustration for the boundaries of classes and how theranges are converted into line separators.cretisation intervals is a speci002c area and underlying data which can bedecided by consulting area speci002c experts. By iterating though all val-ues, the classi002er tries values to classify underlying data labels items ac-cordingly and sends them to the next step to be evaluated.The evaluation step uses item labels provided by the classi002er of the pre-vious step and uses temporal attributes to evaluate compactness of theclasses in each time point. The compactness of classes can be calculatedusing different criteria, such as standard deviation, internal clustering in-dices or measures of distance. To calculate a measure for compactness,we created a weight function to be used as a cost function for evaluatingthe goodness of every classi002er, and then returned the best classi002er as a002nal result for the optimisation process. After this process, the items canbe classi002ed by the best rule-based classi002er values.For a generalised optimisation process, it can be assumed that experts'de002nitions and consultations produce N classes for items have to be clas-si002ed using aggregated attributes of temporal data, producing D of pos-sible classi002ers of rule-based classi002cation for different ranges of values60CHAPTER 3. METHODOLOGY
Algorithm 3.1:Using brute force to optimize rule ranges
Data:Temporal data and aggregated attributes to representclassi002cation rulesData:R= set of classi002cation rules which includes discrete value ragesData:minCost = Inf1foreachr in Rdo
2c = classify050PG, r051;3cost = calculateCost050c051;4ifcost 241 minCostthen
5minCost = cost;6bestClassi002er = r;7end8end9print bestClassi002er;10FunctioncalculateCost 050C051
11foreacht in Periodsdo
12foreachc in Classesdo
13costs.append050CM050ct 051 * count050c051051;14end15end
for each class. Our task is to select the best classi002er among a set S ofsize D classi002ers, hence reducing each provided separator range betweenneighbouring classes into a single line of separation, using the temporalattributes of T time points. A cost function for eachC2Scan be pro-duced using any compact measure 050CM051 that measures the goodness ofclasses in each time point. The can be de002ned as:f050C051 =TXt=1NXn=1CM050ctn051002 jcnjwherejcnjis number of items in each class to prevent creating single bigclasses. The classi002er with the smallestf050C051value can be considered as613.5. EVOLUTIONARY ALGORITHMSthe best classi002er among S.3.5 Evolutionary AlgorithmsIn nature, evolution consists of two steps, selection and random varia-tion. A population of individuals living in an environment do not havethe exact same traits. Some of these traits might be more advantageousand 002t better for that speci002c environment. These individuals have morechance of surviving and producing offspring while others will die out.This 002tness for the experiment is the natural selection. The surviving in-dividuals will carry their traits through to the next offspring of the popu-lation though DNAs. However, the offspring of the surveyed individualsmight not have the exact DNAs as their parents because the operation ofreplicating DNAs consists of randomly crossing both parents' DNAs. Theoperation itself might result in some errors which might lead to new mu-tations. This operation of creating new traits through random crossoversand mutations is called random variation which might be more bene002cial050best 002tting051 for the environment [91].Evolutionary Algorithms are inspired by the natural evolution in biol-ogy . Given that, they comprise the same steps as their natural counter-feits. There are many 003avours of the algorithm with slightly different im-plementations. However, all of them have the same basic components asshown in shown in Figure 3.6, this 002gure represents the general 003owchartfor evolutionary algorithms [9].In their book [9] Eiben and Smith listed the components of evolutionaryalgorithms as follows:017Representation: Is the operation of mapping the real world into theEvolutionary Algorithm world. This process consists of translatingphenotypes into genotypes which are typically accomplished by the62CHAPTER 3. METHODOLOGY
Figure 3.6: General operations of evolutionary algorithms . 050from [9].051domain experts.017Fitness Function: Also known as evaluation function, this functionassigns a quality measure for each genotype helping the process ofselecting the desired behaviours from the population. Hence thisfunction acts as the environment for a population which favourscertain phenotypes according to their genotype. The most 002ttedbehaviours or phenotypes represent the solution for the underlyingoptimisation problem of the evolutionary algorithm.017Population: The population consists of individuals carrying dif-ferent genotypes. These genotypes represent a possible solution forthe issue of optimisation. In most evolutionary algorithms, the pop-ulation size remains constant, which means that after producing anumber of the new generation, the same amount of the individualswill be eliminated for the next phase of the population.017Parent Selection: Is a mechanism of selecting individuals to un-dergo the operation of generating a new individual 050child051. Thisprocess is statistical; this means, the individuals of a higher qual-ity will be selected at a higher rate than low-quality individuals.Nevertheless, the low-quality individuals also have a high chance633.5. EVOLUTIONARY ALGORITHMSof being selected, so that the search does not become greedy andstuck in a local optimum.017V ariation: Variation consists of two different operations; recombi-nation and mutation:226 Mutation: Is a stochastic process which changes some valuesof the selected children's' genotype to mimic the natural muta-tion. This process might produce individuals with better char-acteristics than the available population and helps to avoid lo-cal optima [92].226 Recombination: Also called crossover, it is a process of creat-ing the genotypes of new offspring using random parts of theselected parents' genotypes.017Survivor: Also called replacement, this is the process of selectingsome new offsprings to survive and pass their genotypes to the nextgeneration. This process, with parent selection is responsible forkeeping the population size constant.3.5.1 Differential EvolutionDifferential Evolution is introduced by Storn et al. [93] as a type of evolu-tionary algorithms. As described by Storn et al. [93], this method can op-timise nonlinear, none-differentiable continuous and multidimensionalspace function.The obvious difference between differential evolution and other evolu-tionary algorithms like genetic algorithms is it can operate on real num-bers rather than integers. Furthermore, differential evolution employsthe components of evolutionary algorithms in a different way as describedbelow [93]:017Initialisation: The initial population must cover the entire search64CHAPTER 3. METHODOLOGYspace. This can be accomplished by randomly assigning values forthe individuals. The random values have to be in the range of theminimum and maximum values of the search space.017Mutation: Mutation is accomplished by creating a mutant vectorfrom individuals of the population. This is called target vector. Themutant vector is a result of a target vector and the difference of twovectors which might be chosen randomly or from the best qualityindividuals.017Crossover: Is the operation of copying a fraction of the mutant vec-tor to its corresponding target vector. This ratio of the copy is con-stant and can be controlled by the end user. If the values of theresulting individual exceed the range of the search space, this indi-vidual will be reinitialized.017Selection: In this stage, the 002tness value of the target vector andresulted vector will be compared. The best 002tted vector will surviveand the other one will be eliminated.In chapter six of this study , we will use Differential Evolution with theproposed classi002cation method to optimise a classi002er from a pool of clas-si002ers provided by domain experts. The reason behind choosing differ-ential evolution for optimising the proposed classi002cation method is itscharacteristics as described by Stor et al. [93]. It has been successfullyimplemented with multiple data mining methods as listed by Das et al.[94]. Furthermore, Tusar et al. [95] proved that for most cases differen-tial evolution is more ef002cient and effective than other genetic algorithmsthat use multiple benchmarks.653.6. STATISTICAL MEASURES AND TESTS3.6 Statistical Measures and T estsIn this thesis, multiple statistical measures and tests are used for differentreasons such as measuring the spread of a variable or 002nding similari-ties between resulting samples. In the following subsection, we brie003yintroduce some of these statistical tools. They are used across multiplechapters of the thesis. Other statistical measures, when used, will be in-troduced in their respective chapters.3.6.1 V ariance and Standard DeviationVariance measures the spread of random variables around their mean.It uses the sum of squared difference between readings and the mean tocalculate the amount of spread [96]. For the random variableXwhichconsists ofNreadings and its average is
Xits variance 0500332051 will be:0332=P050X000
X0512
N0001Standard deviation measures spread of variables as it is calculated as asquare root of variance0332. It is denoted as033. In this thesis, we refer tostandard deviation as StDev . To calculate the standard deviation [96]:033=p
0332=s
P050X000
X0512
N00013.6.2 Interquartile RangeInterquartile Range IQR, also known as H-spread, is the range of the mid-dle half of a random variable. For a ranked variable, the total range of thedata is divided into four quarters that is Q1, Q2, Q3 and Q4. Each quartileconsists of 25% of the readings. The Interquartile Range can be calculatedasIQR=Q3000Q3[97]. This range can be considered as another measure66CHAPTER 3. METHODOLOGYof spread. However this IQR ignores the outliers and extreme readingsof the variable.Quartiles can be graphically represented as boxplots. Normally a box-plot has a vertical line representing the range of values of the readings inthe variable with horizontal lines cutting through the main vertical lineshowing the range of each quartile. The second and third quartile areplaced in a box demonstrating the IQR of the variable as shown in Figure3.7.
Figure 3.7: An illustration of different parts of a boxplot showing quar-tiles and their interquartile range. 050from [10]0513.6.3 Wilcoxon T estThe Wilcoxon ranked test is a statistical method to test the null hypothesisof median equality between two paired variables [98]That is, the samesample has been used for two different experiments, in contrast to thet-test, this test does not assume normality of distribution for data which,thus, makes it a non-parametric test. However, it assumes that data issymmetric around median [98].673.7. USED DATA SETS IN THIS STUDY3.6.4 Friedman T estThe Friedman Test is a statistical non-parametric ranked test which cantreat multiple dependent samples sets [97]. The null hypothesis of theFriedman Test is that there is no difference between variables. The nullhypothesis can not be rejected if the result of the treated testes is higherthan the pre-appointed signi002cance value [99]. Non-parametric meansthat this test does not assume normality in the sample 050that is, the condi-tion of using this test is the data require a normal distribution around themean051 [97].This study uses the Friedman test to 002nd the signi002cance of the differ-ences between the results of the proposed methods, and other availablemethods of classi002cation and measuring changes over time. Given thecharacteristics of the Friedman test, multiple samples can be comparedwithout assuming normality . Moreover, this test is used in data miningand data analysis to compare the results of different algorithms of classi-002cation [100] and methods of concept drift [101].3.7 Used Data Sets in This StudyIn this study , four data sets are used for different purposes. A syntheticdata is used to evaluate the 002tness of the external clustering validity tomeasure the differences in the data. Two data sets of the public goodsgame are used to measure the players' behaviour change over time andclassify them using the proposed method. The 002nal data set is that of astock market, which is used to test whether the proposed methods can begeneralised to other cases or not.68CHAPTER 3. METHODOLOGY3.7.1 Creating a Synthetic DataTo check the validity of our method for quantifying behaviour changes ofitems over time, we create a simple 2D data set. These items are agglom-erated to form four distinct clusters with their centres separated aroundthe origin 0500, 0051 point. The original data set is mutated to create the nexttime point and to simulate the behaviour change of items.We used the mlbench.2dnormals method of package mlbench of R lan-guage which is developed by F. Leisch and E. Dimitriadou [102] to createthe original data set1. The data set contains 500 050x, y051 items 050points051 sep-arated randomly among four clusters. Each cluster's centre is placed ona circle with a radius equal to 6, and its centre is point of origin 0500, 0051.Items inside each cluster have a Gaussian distribution and spread fromits centre with 1.5 of standard deviation. Please refer to Figure 3.8050a051 tosee the produced data set and its items distribution among clusters.To create the effect of time passing and items behaviour change, the set ismutated to create the next time point. By repeating the mutation processon the previously mutated data set, multiple time points are created 050forour tests, 20 time points are created051. For the data set DS for time t, D050t+1051= D050t051' where D050t051' is the mutated version of D050t051.Two methods are used to mutate the data and generate the next timepoint. First, by changing the x and/or y coordinates sign value frompositive to negative or vice versa of a randomly selected number of items.This change of sign make items jump from one cluster into another. The002rst change of data can be considered as a big change, which leads itemsto change their behaviour signi002cantly . The second kind of change isintroduced to all items in the data set by slightly changing their x andy values so that they will jiggle from their position without leaving thecluster. The amount of jiggle depends on the x and y values of the item as
1The R code for creating this synthetic data set is available at https://goo.gl/8DBuII693.7. USED DATA SETS IN THIS STUDY
050a051 First time point
050b051 Middle time point
050c051 Last time pointFigure 3.8: Three time points 050002rst, middle and last051 from the overall cre-ated 20 time points. The 002rst time point which contains 500 items sepa-rated into four clusters is the original data set other time points are cre-ated by mutating 050jumping051 items of four clusters from one cluster intoanother.each item will be displaced with a random value range from 1% to 2% ofits original value. Please refer to Figure 3.8050b051 and 3.8050c051 for the mutateddata sets which represent the middle and last time points for the temporaldata set.3.7.2 Public Goods Games DataThere are many variations and set-ups for the public goods game exper-iment 050cite051, However, the data which has been used in this study is col-lected through experiments conducted by Fischbacher et al. [11]. Theirexperiment for public goods game consists of two sub-experiments; P-experiment and C-experiment, both of which every participant 050player051has to accomplish. In the following sections, we will explain how thesetwo sub-experiments are conducted, and then describe the collected datawhich will be used in later chapters.70CHAPTER 3. METHODOLOGYGame Set-upPrior to each sub-experiment of P-experiment and C-Experiment, experi-menters explain the rules of the game for the participants so that they un-derstand the rules, and how their decision will affect their result and thenumber of points available. Participants should answer a number of con-trol questions correctly to demonstrate their comprehension of the game.Experimenters make every effort to ensure that the players are payingattention and playing thoughtfully by rewarding them extra points forcorrect guesses and well-thought out decisions during the game.In P-experiment, four players start the game with 20 points each in theirprivate account and they can contribute any amount they deem necessaryto a project which represents public good. The amount which they do notcontribute in the project will be kept only for the players themselves. Thecollected amount from the project will be distributed among all playersregardless of their contribution to the project. The amount of points eachplayer can accrue from the project is determined by this equation:P layerShareF romP roject=T otalAmountOf AllP layersContribution0030:4So that each players total point after the game will be:P layer0sP oints= 05020000ContributionInT heP roject051+P layerShareF romP rojectIn P-Experiment, players are asked to make two kind of contribution;conditional and unconditional. In conditional contribution, players areasked to decide what amount of points they wish to contribute in re-sponse to the rounded average of other players' contributions. This con-tribution will be 002lled out by the player in a form called the contributiontable as shown in Figure 3.9. The unconditional contribution players willinput the amount of contributions which they require in a single 002eld713.7. USED DATA SETS IN THIS STUDYwithout any conditions. Please see Figure 3.10 for unconditional contri-bution.
Figure 3.9: P-experiment's unconditional contributions user interface.which the user can enter their amount of contribution. From [11]
Figure 3.10: C-experiment Contribution table user interface in which theuser can enter their contribution for all possible conditions. From [11]For each player, only one of the two contributions will be selected by thecomputer as their 002nal contribution to the project. One of the four play-ers' conditional contribution will be randomly chosen to be used as their002nal contribution. while for the other three players their unconditionalcontribution will be used. This random selection of players' contributionsis one of the mechanisms that experimenters have used to make sure that72CHAPTER 3. METHODOLOGYplayers are thinking thoroughly about their decision for the contributionto the project.When the P-experiment is completed, players start C-experiment. C-experiment is similar to a repeated sequence of unconditional contribu-tion exceptthis time the player, in addition to their own contribution, will be asked toguess other players' rounded average of contribution. After each roundof the game, players will be noti002ed of their total points in that particu-lar game. The sequence length of the games can vary from one experi-ment to another. In this study , we will use data sets with 10 and 27 seriesof rounds of the game. In each round, four different random playerswill play the game so that players can not predict others' contributionsin advance. Players will gain extra points if they make correct guessesabout other players' rounded contributions. They will, therefore, not 002llin the boxes randomly . Please refer to Figure 3.11 for the interface of C-experiment.
Figure 3.11: C-experiment user interface has two 002elds. One for theamount of players own contribution and the other for guessing otherplayers rounded average contribution. From [11]733.7. USED DATA SETS IN THIS STUDYData Set AttributesTo measure and classify the behaviour of players in public goods games,this study used two different data sets. These experiments are conductedon different samples of players, so the 002rst data set has 140 players andthe second data set 128 players. These data sets have the same attributesand follow exactly the same experiment procedures, except for the P-experiment length, as the 002rst one consists of 10 rounds while the otherhas 27 rounds.Due to the limitations in space and equipment, all players in these exper-iments did not play at the same time. Instead they were distributed intomultiple sessions. However, each session consisted of suf002cient numberof players meaning that the random selection of each four players play-ing with each other is unbiased. The behaviour of each player will notbe affected by the session which they are in, as they are experiencing thegame for for the 002rst time and develop their understanding of the dif-ferent strategies during P-experiment. Therefore, we are able to considerthat the experiment has been conducted in one big session with all play-ers playing the rounds of the P-experiment at the same time. This meansfor the 002rst data set, we consider that all 140 players have played the 002rstround of P-experiment at the same time.The attributes of the data sets can be divided into two types the tempo-ral and non-temporal attributes. The temporal attributes are generatedin the P-experiment as it contains multiple rounds and non-temporal at-tributes are generated in C-experiment. The following is the list of all theattributes of the data sets. Please notice that the temporal attributes areunderlined:017Idtyp: labels for players categories assigned by experts. The cat-egories are: conditional contributors = 1, free riders = 2, trianglecontributors = 3, and others = 4. These categories are generated74CHAPTER 3. METHODOLOGYdepending entirely on the b0-b20 attributes. Figure 3.12 shows theaverage contribution behaviour of players in each category . Pleaserefer to the previous chapter for the detailed description of thesecategories.017Idsubj: a unique identi002er for each player during both C and Pexperiments.017b0-b20: twenty one attributes representing the contribution tablefor each player as their response in C-experiment to every possiblerounded average of other players' contribution.017u: the unconditional contribution of the player for C-experimentduring the actual game.017Predictedcontribution
: Players' prediction about other co-playersrounded average of contribution to the project.017Period: the session number for P-experiment. As P-experiment foreach player consists of multiple rounds, each players' playing timesare recorded to keep track of the number of games played.017Contribution
: players' actual contribution to the project in eachround of the P-experiment.017Belief
: players' beliefs about other players average contribution ineach session.017Otherscontrib
: Other co-players' rounded average contribution.Preliminary Behaviour Analysis of the PlayersAs mentioned before, experts use C-experiment data to classify players'strategies. However, we are using the P-experiment data to classify play-ers' behaviour over time and measure their overall change in contribu-tion. So before starting the analysis for classi002cation, it is bene002cial to753.7. USED DATA SETS IN THIS STUDY
Figure 3.12: Four type of players average own contribution according toco-players average contributionsee the general trend of players' behaviour over time and gain an overallidea about them. Heat maps are used to identify the density of players'contribution at each round of the game with regards their beliefs aboutother co-players' contribution. The heat map shows the percentage ofplayers who have the same contribution and belief. The more similar thebehaviour is of the players, the darker the box of that value becomes.Figures 3.13, 3.14 and 3.15 represent players contribution-belief heat mapsgenerated for the 002rst, mid and last rounds of the 002rst data set. As can benoticed, the overall players' contribution for the project and their belief ofco-players contribution drop signi002cantly from the 002rst to the last round.However, it can also be noticed that the players contribution drops fasterthan their belief as more dark boxes can be seen at the bottom of Fig-ure 3.14. This indicates players are starting to contribute less than whatthey believe the other players will contribute to the project to obtain morepoints from the project than contributing in it.3.7.3 Stock Market DataWe further tested the proposed classi002cation and measuring methods us-ing different data sets with similar required properties. The stock market76CHAPTER 3. METHODOLOGY
Figure 3.13: Heat map for players contribution according to their beliefin round 1
Figure 3.14: Heat map for players contribution according to their beliefin round 5data set was chosen as it contains elements 050stock051 in a temporal datawith varying behaviour 050prices051. One advantage of the stock market dataset is that we can select a larger set of unique items to be classi002ed andlonger time points to observe their behaviour change. This might be agood way to test the proposed methods to their full extent. However,773.7. USED DATA SETS IN THIS STUDY
Figure 3.15: Heat map for players contribution according to their beliefin round 10the downside of the collected stock market data is that there are no pre-classi002ed labels for the items in the data to be able to compare with in our002ndings. Therefore, we should rely on some other measures to evaluateour results.Data HarvestingFor this study , we have selected Standard & Poor's 500 050S&P 500051 stockmarket to run our tests as they contain a suf002cient amount of items ateach time point 050502 items [103]051. In addition, it is publicly listed and thisenables us to harvest long periods of their data freely . S&P 500, or histor-ically known as Composite Index [104] is designed to represent the largecap for domestic companies in United States [105]. This index comprisesvery diverse stocks which can be considered as a better representation ofthe U.S. market than Dow Jones . The large cap, in this context, refers tocompanies with more than 10 billion dollars worth of stocks [106].We used the available symbols for the companies listed in S&P 500 in-78CHAPTER 3. METHODOLOGY
Figure 3.16: Selected heat maps for players contribution according totheir belief in rounds 1, 5, 10, 15, 20 and 25 in the 27 rounds data setdex from cobe website as it is specialised in market analysis. Symbol 050orticker051 is a standard representation for a company in the stock market.We have used the list of S&P 500 symbols to download historic data of793.7. USED DATA SETS IN THIS STUDYthe companies from Yahoo Finance website using an R script2.A sample data for all companies listed in S&P 500's index from 1-1-2015to 1-7-2015, which represents a half year, are collected from the Yahoo002nance website. The number of time points which are collected for thistime period is 125 days, and the attributes for the collected data are:017Date: The date of the stock price. Each date can be considered as atime point and converted to a sequence of integer numbers.017Symbol: The standard symbol which identi002es companies' stocks.017Open: The price of the stock at the opening time for that date.017High: The highest price that the stock reached on that date.017Low: The lowest price that the stock hit at that date.017Close: The price of the stock at the close time of stock market at thatdate.017V olume: The number of shares which are traded at that date.017Adj.Close: The closing price of each stock might be amended tothat date because of one of multiple reasons that might affect theprice such as Stock Splits, dividends and Rights Offerings [107].Data PreprocessingThe harvested data should be cleaned and pre-processed before using itto test the proposed methods. The unknown 002elds should be handledproperly so that they do not subsequently affect the algorithms. The un-known 002elds are not the only problem as the stock price values from onecompany to another varies signi002cantly . As this may affect the classi002ca-tion process, they should be normalised. Moreover, for the sake of sim-
2The Symbols list, R script for fetching the data and manipulating it, and a sample ofthe data are available at https://goo.gl/U0STqJ80CHAPTER 3. METHODOLOGYplifying the classi002cation rules later, it is advisable to convert normalizeddata into integers. Table 3.1 shows a sample of the data with its headersafter the pre-processing stage.
Date
Open
High
Low
Close
V ol
Adj.Cls
Symbol
1
587
567
489
482
73
473
A
2
440
406
367
351
137
344
A
3
352
322
243
243
141
239
A
4
303
282
292
333
300
327
A
5
426
504
454
539
146
529
A
6
556
508
474
487
87
479
A
7
489
455
412
404
227
397
A
Table 3.1: A sample of the S&P 500 data set after cleaning and manipula-tion.A small number of the companies does not have the complete list of val-ues for the speci002ed date range on the Yahoo Finance website. As theproposed algorithm, cannot handle unknown data, they have to be han-dled prior to their use in the algorithms. One solution could be removingthem from the data series so that we have different lengths of data series.However, this is not an option because we cannot properly study theirbehaviour for the full length. The second solution might be 002lling themwith the average price from the available days prices. However, this willnot re003ect the proper behaviour of the stock. Therefore, we decided to re-move these companies from the list as there is a limited number of them.The remaining symbols 050companies051 in the 002nal list after removal is 497companies.We have converted dates into integers of absolute time points as the exactdates are irrelevant. Not all dates exist as there are stock prices only forworking days in the week, and the proposed classi002cation and analysisare concerned with the 003ow of consequent time points. Thus, the datesare ordered and each corresponding date is converted to an integer from813.8. TESTING ENVIRONMENT1 to 125. In this way , we preserve the correct sequence of the time pointsand simplify dates to a series of integers.As the share price for companies varies, the effect of the same changein the price might have impacts on them. To eliminate the effect of thisdifference in share price, the data is normalised. The variables of eachshare price are normalized separately so that they scale from 0 to 1. Forany variable 050Close price, Open price, etc.051 of share price x the equationof normalisation is used.x0=026x000min050x051
max050x051000min050x05100210000270503.1051The normalisation results for the shares are real numbers. To convertthese numbers into integer numbers without losing their precision, eachvalue is multiplied by 1000 and then its 003oor value is computed. Asmentioned beforehand, converting price values to integer simpli002es theiranalysis and classi002cation rules. Moreover, by using integer values, wecan compare the performance of the proposed algorithms between allavailable data sets.3.8 T esting EnvironmentThe machine used for carrying out the tests is a ThinkPad laptop withthese properties:017Processor: Intel050R051 Core050TM051 i3-4000M CPU @ 2.40 GHz 2.40 GHz017RAM: 8 GB017System type: 64 bit Windows OS017Storge: 100 GB of SSD82CHAPTER 3. METHODOLOGYWe used R language version 3.2.4 with IDE software RStudio V 0.99.893.The packages utilised for the R language is listed in Table 3.2.
package	version	authors	Usage
clv	0.3.2.1	Nieweglowski [108]	For validating clusters.	Speciallyinternal and external validity inde-ces methodsDEoptim	2.2.3	Ardia et al [109]	For differential evolution optimisa-tiondplyr	0.4.3	Wickham et al [110]	For data manipulationdtw	1.18.1	Giorgino [111]	For dynamic time wrapping algo-rithmgplots	3.0.1	Warnes et al [112]	To create Heat mapsHmisc	3.17.4	Harrell JR [113]mcclust	1.0	Fritsch [114]	For multiple clustering algorithmsmlbench	2.1.1	Leisch [102]	To generate data for testspROC	1.8	Robin et al [115]	For classi002cation evaluation spe-cially AUC or ROCstargazer	5.2	Hlavac [116]	To create latex tables directly fromR results
Table 3.2: The R packages which are used in this studyWe also used Java programmingJRE8update92; JDK1:8:092with Eclipse224Marse.2224 IDE V ersion 4.5.2 to compare our results of measuring itemsbehaviour change over time points with MONIC [52] results.833.8. TESTING ENVIRONMENT84Chapter 4Measuring Items' BehaviouralChange4.1 IntroductionThis chapter addresses the research questions raised in chapter one re-garding the usage of clustering and cluster validity indices as a methodto measure items behaviour through multiple time points. The questionsand hypothesis will be tested using the methods mentioned in Chapterthree Section 3.3 and related to items' behaviour measurement in tempo-ral data.The Hypothesis 1 in chapter one indicates that the result of quantifyingthe behavioural change will not be affected by using various clusteringalgorithms as long as all time points are clustered using the same algo-rithm. To test this hypothesis, we use multiple clustering algorithms likek226means, c226means, PAM and hierarchical clustering in this chapter tocluster the temporal data. Each clustering algorithm is used to clusterall time points of the temporal dataset separately from each other andwithout the effect of the time attribute.Hypothesis 2 indicates that different external cluster validity indices will854.1. INTRODUCTIONproduce similar results in measuring items' behavioural change betweenthe various time points. To check the validity of this hypothesis, we useddifferent external cluster validity indicess to measure changes betweenany two time points. However, not all external cluster validity indicessmight be suitable to be utilised for this task as we, later in this chap-ter, will explain the essential characteristics of the measure which can beused. Moreover, we have used Area Under the Curve AUC of ROC anal-ysis to measure changes over time for comparison purposes with externalcluster validity indices.This chapter also partially addresses the reference of behaviour for itemsin temporal data 050Hypothesis 3051. Reference of behaviour can be de002nedas a typical collective behaviour of elements of a temporal dataset. Refer-ence of behaviour can be used to compare other time point behaviours ofitems. In this chapter, we will use and test two different Reference of be-haviours for items. However, after we introduce the proposed temporalclassi002cation method in the next chapter, we will use it to classify itemsin the datasets and use these classes as a reference of behaviour for alltime points.Three datasets are used in our tests one synthetic dataset to check the fea-sibility of using the proposed method as a measure of quantifying changeover time and two different public goods games PGG datasets 050as men-tioned in chapter three, section 3.7.2051. Moreover, this chapter participatesin the argument of the players' strategy change during the PGG rounds[117, 118] by presenting a quanti002able method to measure the change instrategy by players.Finally , the results are compared with the MONIC model as it developedby Spiliopoulou et al. [52] to measure the cluster changes in the datastreams 050Further details on the MONIC method are provided in chap-ter two051. The appropriate statistical analysis is presented to provide evi-dence supporting or rejecting the hypotheses of the 002rst chapter.86CHAPTER 4. MEASURING ITEMS' BEHA VIOURAL CHANGE4.2 BackgroundIn economics, there is an interest in how players of public goods gamechange their strategy during multiple rounds of the game and jump fromone strategy to another [119], such as changing from conditional cooper-ator to free rider behaviour. This change can be seen as a drift from theoriginal label assigned to the players.There are many methods for classi002cation in machine learning, with theexistence of concept drift [120, 121, 122] and methods to detect it [123,124]. Moreover, measuring changes in clusters for different time pointshave been thoroughly studied in data analysis, especially for data streams[56, 125, 126]. However, these methods aim to 002nd overall patterns ofchange in clusters' location, size, merging, emerging and/or dissipatingrather than presenting a measure of how much change has occurred ineach cluster 050that is, in which ratio items change their membership fromone cluster into another051.External cluster validity is primarily used to check the performance ofclustering algorithms by measuring the difference between ground truthlabels given to the items by experts and the group in which they havebeen placed by a clustering algorithm [15]. This study uses externalcluster validity measures such as variation of information [127] VI andarea under the curve of the receiver operating characteristic AUC [32]as scaler measures, to show the amount of items that jumped from onecluster to another between two consequent time points. To accomplishthis measurement, the items should be clustered separately in every timepoint. As the clustering is performed at a single time point, which elimi-nates the time dimension for the collected data on items, any traditional050non-temporal051 clustering algorithm should theoretically be suf002cient.After clustering, an external clustering validity measure can quantify theamount of changes between clusters at any two time points.874.3. APPROACH4.3 ApproachAs has been explained in the previous chapter, to be able to measure thedifference in behaviour of a population of items from their collected char-acteristics in a temporal data, the items should be clustered in each timepoint. Then their change in behaviour can be measured using cluster va-lidity indices CVI or Aria Under the Curve AUC of ROC analysis. How-ever, to implement the available methodology on a speci002c data, certaindecisions have to be made to ensure that appropriate treatments are ap-plied to the underlying data. In the following sub-sections, the ratio-nale and reasons for selecting date set attributes, choosing the numberof clusters, clustering algorithms and various cluster validity indices areexplained.4.3.1 Preparing Datasets for ClusteringBefore starting with clustering, the temporal datasets have to be sepa-rated by their time points. In this chapter, three datasets are used for thetests. The 002rst dataset is the synthetic dataset as mentioned in section3.7.1. The second and third datasets are public goods game datasets withdifferent players and various length of time points.The synthetic dataset is straight forward as it has 20 time points. So, thedata will be split into 20 separate datasets with each subset representingone time point. The subsets are labelled so that the order of consequentsubsets are preserved. The data has two temporal attributes in each sub-dataset representing x and y coordinates.The 002rst public goods game dataset has 10 time points as presented by the224period224 attribute, so it will be split into 10 subsets of datasets with eachcontaining 140 items as the number of players in this dataset. The seconddataset contains records of 27 rounds for 128 players, so this dataset will88CHAPTER 4. MEASURING ITEMS' BEHA VIOURAL CHANGEbe split into 27 subsets with each containing information of 128 playersat a particular time point 050round of the game051.Both public goods game datasets have multiple static attributes and donot contain any temporal information. These static attributes are Idsubj,b0 to b20, u and Predictedcontribution. The temporal attributes are con-tribution, belief and otherscontrib. However, the otherscontrib is not di-rectly related to the players' own behaviour. Thus it is also not used inthe clusterings. The only two attributes used are players contribution andbelief of P-Experiment as these two attributes re003ect the players learningprocess for the game and the change in their ideas and strategies as thegame progresses through rounds.4.3.2 Choosing Clustering AlgorithmsAs each of the produced subsets of data represents one time point of thetemporal dataset, each subset alone, therefore, does not carry any infor-mation about the time dimension. This means it is possible to use non-temporal clustering algorithms to cluster items in each subset of the tem-poral datasets.Clustering algorithms can be categorised according to their method of002nding similarities between items in the data. These categories are parti-tional, hierarchical, density-based, grid-based and fuzzy clustering [128].However, the main clustering categories which we used are partitionbased clustering, hierarchical clustering and fuzzy algorithms. For thetests in this chapter, we used k226means and PAM as methods of parti-tioning clustering, hierarchical clustering with Euclidean distance and c226means as fuzzy clustering. As we aim to 002nd similarities between itemsaccording to their distance from each other, we therefore did not usedensity-based and grid-based clustering methods. Please refer to chaptertwo for further details on these clustering algorithms.894.3. APPROACHTo 002nd similarities between items, clustering methods can use linear dis-tance measures such as Euclidean distance or use non-linear kernels tocluster complicated patterns in the data items. In the tests, we only usedlinear distance-based clustering methods because the aim was to 002nd thesimilarity in behaviour based on the overall proximity of the attributevalues of items. For the same reason we did not use density-based clus-tering such as DBSCAN and grid-based clustering such as STING sincethese methods do not depend on the mutual proximity of cluster items toa centroid. This represents a behaviour category .4.3.3 Choosing Number of ClustersMost of the clustering algorithms require the number of clusters as anapriori condition to cluster the underlying data. This might be a chal-lenging task especially for the datasets as there are no known patterns tostart with [129]. Economists have classi002ed players of public goods gamedatasets used in this chapter into four classes [80]. However, as explainedin chapter three, these classes are dependent on the static attributes of thedata rather than temporal attributes.Numerous methods exist to estimate the appropriate number of clustersin the data [130, 131]. We used the elbow method [132] to determine thenumber of clusters in the temporal attributes of the PGG datasets. Thismethod involves clustering the dataset repeatedly with an incrementalnumber of clusters and then calculating the sum of square error or vari-ance of items within clusters. By plotting the produced values, an appro-priate number of clusters for the underlying data can be found.We used the ten round game dataset to 002nd the number of clusters inthe temporal attributes of the public goods game data. The data is splitinto ten subsets with each subset representing one time point. Each timepoint is clustered repeatedly using k226means clustering, starting with 290CHAPTER 4. MEASURING ITEMS' BEHA VIOURAL CHANGEclusters up to 15 clusters. The sum of square errors within each clusteris calculated and plotted. The results in Figure 4.1 indicates that there isno decisive number for clustering. However, four clusters might be anaccepted number of clusters for the data.
Figure 4.1: Using elbow method and calculating the sum of squared er-rors within groups to 002nd appropriate number of clusters for the publicgoods game data in each time point.We implemented an extra test to evaluate the group memberships ofplayers which are predicted by the clustering algorithm for cluster num-bers from 2 to 15. Each of the previously clustering results was com-pared with economists' classi002cations using Rand external cluster valid-ity . Please refer to chapter two for more information about Rand index for914.3. APPROACHexternal cluster validity . Using the elbow method once again, the resultsindicate, as shown in Figure 4.2, that economists' classes are adequatelyrepresented by using four clusters. Moreover, using four clusters is alsobene002cial for comparison reasons with the available classi002cation fromeconomists.
Figure 4.2: Using rand index to 002nd the best member ship matches be-tween clusters and classes.The synthetic dataset is created with distinct four clusters, so its resultscan be comparable with the results of the public goods game datasets.92CHAPTER 4. MEASURING ITEMS' BEHA VIOURAL CHANGE4.3.4 Choosing External Cluster V alidity IndicesAs explained in the Methodology section in chapter, three we proposeusing external cluster validity indices and area under the curve AUC tomeasure the changes which might occur in the behaviour of the itemsbetween multiple time points in a temporal data. Many external clustervalidity indicess are available [133] to measure the validity of clustersproduced by clustering methods compared with the natural partitionsthat exist. In chapter 17 of their book, Zaki et al. [2] categorised theexternal clustering validities into three types: matching based measures,entropy-based measures and pairwise measures. For more informationon external cluster validity indices, please refer to chapter two.As is the case for matching-based measures, external cluster validity in-dicess calculate the match of the clusters to the partitions. This means thismeasure is not concerned about individual element differences betweenclusters and partition. This category might, therefore, not be bene002cial incalculating the changes over time.The second category of external cluster validity indices, entropy-basedmeasures, calculates the difference of entropy between clusters and groundtruth partitions. This method is not concerned about individual items inthe clusters and partitions. However, we used one measure of this cat-egory , Variation of Information VI, because the entropy of the clustersmight be affected by the change of items within the clusters. We alsoused VI for comparison purposes with other indices.The last category , pairwise measures, measures cluster validity by com-paring the produced clusters and original labels of items' classes. Asthis category calculates the validity using all elements of the dataset, itmay , therefore, be the most appropriate category to calculate the items'changes over time points. Three instances of pairwise measures are usedin this chapter: the Jaccard Coef002cient, Rand Statistic and the Fowlkes-934.3. APPROACHMallows Measure. Please refer to chapter two for more details on each ofthese measures.A standard criteria for different external cluster validity indices mustbe maintained , so that the 002nal result which quanti002es the amount ofchange in each time point re003ects the actual change to the groups' itemsregardless of the measure used. To ensure the measures are standard,they should follow two rules 0501051 the scale of the measure should be be-tween 0 and 1 0502051 with 0 being the total change and 1 the perfect matchbetween any time point and reference of behaviour. However, not allmeasures follow these rules. For example, in the selected measures theVI is not bound to any scale, and zero is considered as a perfect match.Thus, the results of this measure should be 0501051 scaled to the range of [0-1]0502051 then reversed, by subtracting the current time points' result from themaximum change which can be obtained from the dataset.4.3.5 Using Internal Cluster V alidity IndicesWe have considered using internal cluster Validity Indices alongside ex-ternal cluster validity indices. We tested multiple internal cluster validityindices such as Davies Bouldin index [46], and Dunn index [37]. How-ever, all internal cluster validity indices are designed to measure the va-lidity of the clusters using an agglomeration of the items in the clustersand distances among clusters. This means that the Internal cluster va-lidity indices can detect changes which are happening to the clusters ingeneral but not the individual changes in items. We, therefore, dismissedthe results produced by this method.94CHAPTER 4. MEASURING ITEMS' BEHA VIOURAL CHANGE4.3.6 Using Area Under the CurveAs explained by Fawcett [31], AUC calculates the area under the ReceiverOperating Characteristic ROC curve and is plotted as a relationship be-tween true positive rate and false positive rate. As this criterion uses aelement-wise comparison to 002nd the number of true positive and falsepositives, this measure might be useful in calculating the changes be-tween two time points. Originally , this measure was used to demonstratethe quality of binary classi002cation. However, a generalised method ofmultiple classes is presented by Hand et al. [33]. Please refer to chaptertwo for more details on AUC.AUC is designed to measure how well a classi002er performs in predictingclasses of elements compared with the true labels of the elements. Thismeans, unlike pairwise external cluster validity measures, prior to usingAUC to measure the change over time, the cluster labels of time pointsshould be matched. There are a number of methods to match clusters[134, 15]. We have used these methods:017Using the cluster centroids of n time point to be the suggested startcentroid for the n+1 time point. However, this method only workswith k226means and PAM, but it is not an option for hierarchical clus-tering.017Using distances between centroids of the produced clusters in bothtime points as a reference for matching between clusters.017Comparing the elements' membership in clusters between thesetwo time points to 002nd the matches between clusters.4.3.7 Different Reference of Behaviours for ItemsThis study considers three different references of behaviours. However,in this chapter, we will test two. They are 1051 the 002rst time point is used as a954.4. TESTING THE PROPOSED METHODreference of behaviour for all other time points 2051 The previous time pointis used to be the reference of behaviour for the current time point. Inthe next chapter, a new classi002cation method will be proposed to classifyitems in temporal datasets. This classi002cation will be used as a referenceof the items behaviour in chapter six.Each of these different references of behaviour bring different meaningand can be used in various ways. The 002rst time point can be used as areference of behaviour to quantify the progress of change which happensto the items in any later time points in the dataset. An example of that is ifwe want to quantify the change of behaviour of players in PGG from the002rst round of the game to any round of the game. Using the previous timepoint as a reference for the current time point means we aim to stepwisemeasure changes in items' behaviour between any time point. This canbe used to measure the stability of change over time. An example ofusing this method is when we want to check the stability of changes thatcan occur in player behaviour between time points. Items' classes such asreference of rehavior can be used to quantify items' deviation from theirown generalised behaviour at any time point.4.4 T esting the Proposed MethodWe conducted this experiment to show that the proposed method can beused for measuring changes among various groups over time in temporaldata. The synthetic data is created so that obvious changes of behaviourcan be observed by introducing jumps for items from one group to an-other. The item set contains 500 items grouped into four distinguishablegroups. The data is mutated repeatedly using jumps and jiggles 19 timesto create 20 time points 050the original dataset is the 002rst one051. To illustratethe original and mutated data, three time points are shown in Figure 4.3.Please refer to section 3.7.1 in chapter three for a detailed explanation on96CHAPTER 4. MEASURING ITEMS' BEHA VIOURAL CHANGEthe method of creating the dataset.
050a051 First time point
050b051 Middle time point
050c051 Last time pointFigure 4.3: Three time points 050002rst, middle and last051 from the 20 timepoints created overall. The 002rst time point, contains 500 items and sepa-rated into four clusters, is the original dataset other time points are cre-ated by mutating 050jumping051 items of four clusters from one cluster intoanother.To test Hypothesis 1, multiple clustering methods are used in this exper-iment to group items in each time point of the synthetic dataset. Theclustering methods are chosen based on the criteria discussed in section4.3.2. Moreover to test Hypothesis 2, multiple external cluster validity in-dicess and the AUC of ROC are used to measure the amount of changeshappening to the items in the produced groups using different clusteringmethods. The choice of external cluster validity indicess are based on theprior discussion in section 4.3.4. We also tested the two types of referenceof behaviour for items. To do so, all tests are run twice. The 002rst occasionconsidered the 002rst time point as the reference of rehavior and then alltime points were compared with it. The second time considered previoustime point as the reference of rehavior for the current time point. Pleaserefer to section 4.3.7 for more details.Using this method, both clustering techniques , external cluster validityindices, and reference of rehavior, produce a result of an array of valueswhich quantify the difference between each time point and the referenceof rehavior. These values can be reported as a list of values, or a table.974.4. TESTING THE PROPOSED METHODHowever, to obtain an idea of the degree of change of items of groupsthrough time points, a x,y chart can be used with time points as x-axesand the amount of change values scaling from 0 to 1 as y-axes. Figure4.4 shows results of k226means, PAM, c226means and hierarchical cluster-ing methods using the 002rst time point as the reference of rehavior tocalculate the amount of changes which happen to the groups of itemsin consequent time points in the test dataset. The amount of change ismeasured by using different external cluster validity indices and AUC ofROC. Moreover, Figure 4.5 shows results for the proposed method usingthe same clustering techniques and external cluster validity indicess al-though it uses the previous time point as the reference of rehavior for thecurrent one.Figure 4.4 shows a gradual shift from the 002rst time point as each newtime point introduces further mutations for the dataset and, hence, fur-ther drifting from the original location of the items. While all measurescon002rmthe gradual change of progressing time points, however, not allof them react in the same way . The major noticeable difference is thatFM and Jaccard are overreacting to the changes and show high sensi-tivity to it. As the VI values are scaled and 003ipped, they correspond to002t the rules laid out in section 4.3.4. Results are, therefore, shown in avery saturated scale as the lowest point become zero due to the scalingand 003ipping. However, the actual changes are a small percentage of theoverall items suggesting that these scales of change by the two measurescould be due to the original design of these two measures to show thedifference between clusterings and real classes. Moreover, all results ofthe hierarchical clustering show a slightly different change pattern thanother clustering methods. Another noticeable result is that k means clus-tering shows an increased sensitivity for the changes between 14 and 15time points. The same sensitivity is not depicted by other clustering al-gorithms.98CHAPTER 4. MEASURING ITEMS' BEHA VIOURAL CHANGE
050a051 K226means Clustering
050b051 PAM Clustering
050c051 C226means Clustering
050d051 Hierarchical ClusteringFigure 4.4: Results of various clustering methods using the 002rst timepoint as reference of rehavior to calculate the amount of changes whichhappen to the groups of items in consequent time points in the testdataset. The amount of change is measured by using different externalcluster validity indices and AUC of ROC.Figure 4.5 shows the difference between any two consequent time points.PAM and c226means clustering methods created visually similar resultswhile k226means and hierarchical clustering produced very different re-sults. While all clustering methods are producing a greater change be-tween time points 13-15, k226means, however, shows an extreme change inthe same time periods. In these results, VI shows exaggerated differences994.4. TESTING THE PROPOSED METHODbetween time points. However, FM and Jaccard results display the dif-ference between time points more than AUC and Rand. AUC and Randresults might re003ect the reality of the changes but the changes becomeunnoticeable due to the small scaling.
050a051 K226means Clustering
050b051 PAM Clustering
050c051 C226means Clustering
050d051 Hierarchical ClusteringFigure 4.5: Results of various clustering methods using the previoustime point as reference of rehavior to calculate the amount of changeswhich happen to the groups of items in consequent time points in thetest dataset.The Friedman test is used to validate Hypothesis 1 on the proposed methodfor measuring changes over time using acquired results from the syn-thetic dataset. The p.value of the four samples for measuring changes100CHAPTER 4. MEASURING ITEMS' BEHA VIOURAL CHANGEof time points against the original dataset is 4.947325e-14 and p.valuefor measuring changes of current time points against the previous timepoint is 1.895672e-14. This means, in both cases, we can not reject thenull hypothesis and hence, the samples are different. However, a closerlook at the results by comparing every two samples of different clusteringmethods using Wilcoxon tests reveals 050see Table 4.1051 that all p.values arehigher than 0.05 for the samples used the 002rst time point as the referenceof rehavior. For those samples which using previous time point as thereference of rehavior, only hierarchical clustering produced p.values lessthan 0.05 when compared with other samples. This means all three clus-tering methods are producing the same results for measuring changesover time. Given that, we can consider Hypothesis 1 to hold true espe-cially given all clustering methods are con002rming that the items insidethe groups are changing gradually over time. The difference is only inthe sensitivity to the change , an aspect of the clustering method.
Clustering1	Clustering2	p-V alue First	p-V alue Consequent
k226means	c226means	0.9778971	0.6262925k226means	PAM	0.7868127	0.8050843k226means	hierarchical	0.5369699	0.000704285c226means	PAM	0.7555338	0.7776328c226means	hierarchical	0.4877342	3.17E-05PAM	hierarchical	0.6903287	4.68E-05
Table 4.1: P-values of Wilcoxon-test for each pair of clusters.To validate Hypothesis 2, the similarity of result samples produced bydifferent external cluster validity indices have to be measured. We usedthe Friedman test to check if all the results are similar to the null hy-pothesis that assumes similarity for the produced results in measuringthe amount of change for all time points using different external cluster1014.4. TESTING THE PROPOSED METHODvalidity indices or AUC. Two p-values are produced. The 002rst p-value =5.232651e-44 for the samples which are produced by measuring the be-haviour of each time point compared to the 002rst time point. The sec-ond p-value = 1.416841e-53 for the results which are produced by com-paring each time point with its successor. In both cases, p-values aresmaller than 0.05. The null hypotheses should, therefore, be rejected asthe samples are different. Moreover, we conducted a Wilcoxon test on thesamples to take a closer look at the results of every pair of two samplesproduced with different measures. As shown in Table 4.2, the p-values050except for the AUC and Rand pair051 are smaller than 0.05 which indicatethat these pairs are different from each other. This means that differentmeasures are producing signi002cantly different results, Hence, Hypothe-sis 2 can not be true. So, further examination of the results is requiredto check whether the proposed method can be used to measure changesover time or not.However, despite the measures producing different results, as provedby using different statistical tests, we can see from 002gures 4.4 and 4.5that all measures indicate the gradual change in the data with differentsensitivities to the amount of change. As the data is synthesised andnew time points are created by mutating the current time point, we can,thus, con002rm that the results re003ect the gradual change which alreadyexists in the data. Therefore, the difference between samples might bea direct result of the different sensitivities which each measure is createdfor, and included in its method of calculating differences in group paritiesbetween predicted results and true labels of the items.Measures with different sensitivities proved to be a positive aspect of theproposed method for measuring changes over time in various situationsas it enables us to control the amount of sensitivity needed for a speci002csituation or application. For example in Figure 4.4, Rand and AUC mea-sures re003ect the amount of change well, while in Figure 4.5 Jaccard and102CHAPTER 4. MEASURING ITEMS' BEHA VIOURAL CHANGEFM can highlight changes which can not be detected by the previous twomeasures.
Clustering1	Clustering2	p-V alue First	p-V alue Consequent
Rand	Jaccard	1.947533e-17	2.182083e-13Rand	FM	1.857682e-11	4.051658e-07Rand	VI	4.131331e-13	9.372113e-24Rand	AUC	0.9251302	0.5177034Jaccard	FM	3.865308e-08	3.565382e-06Jaccard	VI	1.977779e-18	1.242547e-22Jaccard	AUC	1.103106e-17	2.012194e-13FM	VI	1.956715e-15	3.196178e-23FM	AUC	2.114171e-11	1.110287e-06VI	AUC	3.718286e-13	1.051501e-23
Table 4.2: P-values of Wilcoxon-test for each pair of external cluster va-lidity indices and AUC.To be able to use the proposed method for measuring changes over timein temporal data, it should, at least, be proven that each measure inde-pendently from other measures can produce consistent results for differ-ent clustering methods. Another test is conducted to check if a measurecan produce consistent results across multiple clustering methods. Theresults for each measure produced by different clustering algorithms arecompared and the p-value for the Wilcoxon test is produced as shown inTable 4.3. P-values of each pair of the produced samples are higher than0.05 except for hierarchical clustering when using previous time point asa reference of rehavior 050consequent test051. This means, we can not rejectthe null hypothesis because the results of measures are consistent acrossmultiple clustering methods. That the p-value is not smaller than 0.05 in1034.4. TESTING THE PROPOSED METHODhierarchical clustering might be due to the fact that hierarchical cluster-ing itself produces different groups than other clustering methods as hasbeen previously proven in this section.
Cluster1	Cluster2	Rand	Jaccard	FM	VI	AUC
Firstk226means	c226means	0.930085	0.930085	0.930085	1	0.941807k226means	PAM	0.883816	0.906934	0.906934	0.906934	0.165448k226means	hierar	0.704262	0.704262	0.682708	0.704262	0.085021c226means	PAM	0.965026	0.988339	0.988339	0.91851	0.188877c226means	hierar	0.579058	0.579058	0.579058	0.682708	0.08502PAM	hierar	0.579058	0.579058	0.579058	0.682708	0.539772Consequentk226means	c226means	0.558817	0.558817	0.558817	0.619407	0.609161k226means	PAM	0.529826	0.539462	0.539462	0.640234	0.578892k226means	hierar	0.00319	0.003505	0.003504	0.018246	9.14E-05c226means	PAM	0.976681	0.98834	0.98834	0.98834	0.214412c226means	hierar	6.34E-05	6.34E-05	6.34E-05	0.000787	8.05E-07PAM	hierar	4.94E-05	4.94E-05	4.94E-05	0.001192	6.92E-06
Table 4.3: P-values of Wilcoxon-test for each pair of external cluster va-lidity indices or AUC.In this section, we demonstrated and proved that using different cluster-ing techniques will produce similar results for measuring changes overtime. We also proved that using the same measure 050that is external clus-ter validity indices or AUC of ROC051 produces consistent results across allclustering methods. This is an indication that the proposed method canbe used to measure changes over time and produce a single value which104CHAPTER 4. MEASURING ITEMS' BEHA VIOURAL CHANGEindicates the amount of change that happens to items' membership in theavailable groups at different time points.4.5 Measuring Players' Strategy Change over TimeThe main objective of this experiment is to quantify how players' changein strategy in the public goods game can contribute to the understandingof the players' behaviour and present a tool for economists to measurethe amount of change for different set-ups of their experiment. Anotherobjective of this experiment is to demonstrate the ability of the proposedmethod to produce quanti002able measures for changes in items. in thetemporal data and provide interpretable results. We compare the resultsand 002ndings of our method with the MONIC method which is originallyused to measure cluster changes in a data stream [52].In section 3.7.2 of chapter three, two datasets of PGG are introduced. Forthis experiment, both datasets are used to measure players behaviour andstrategy change during the consequent rounds of the game. The attributeof players own contribution and their expectation of other players' con-tribution at each time point are used by this method to 002nd the magni-tude of the change. These two datasets have different groups of playersand different lengths as the 002rst dataset is 10 rounds length and the sec-ond is 27. Therefore, these two datasets are used separately and treatedas different datasets in this experiment. Based on the previous discus-sion in section 4.3.3, we used four clusters to cluster players in each timepoint using k226means, PAM, c226means and hierarchical clustering meth-ods.These methods were selected based on our discussion in section 4.3.2.As both datasets of PGG share the same experiment settings and setup,it can be hypothesised that the results of the behaviour change should beconsistent with regards to the length of the experiment which, in turn,might affect the behaviour of players [135]. While we use all previously1054.5. MEASURING PLA YERS' STRATEGY CHANGE OVER TIMEselected external cluster validity indices as in section 4.3.4 and AUC ofROC, we will, however, depend on AUC and Rand results to compare thebehaviour of players in these two different datasets as we demonstratedthat these two measures produce more consistent results than the rest ofthe measures.4.5.1 Using Proposed MethodPrior to the analysis of the players' behaviour, we checked both Hypothe-sis 1 and 2 using real datasets. Using p-value, as described in the previoussection, similarities between results of different clustering and externalcluster validity indices are tested. P-value results are shown in AppendixA. While slightly different results are produced especially for 27 perioddataset, the results are consistent with the results of synthetic data. Thiscan be considered as extra evidence that the presented method for mea-suring changes over time can be used with real datasets.Different types of reference point reveal different aspects of players' strat-egy change. By using the 002rst time point as the reference of rehavior,we can detect drift of players' behaviour from the initial expectation andcontribution. As shown in Figure 4.6 for 10 rounds dataset and Figure 4.8for 27 rounds, players in both datasets are gradually drifting away fromtheir initial game plan and expectation. This trend can be seen with allfour clustering methods with the different measurement methods of ex-ternal cluster validity indices and AUC. Because the results of AUC andRand are consistent across all clustering methods, we used AUC to cal-culate the linear regression of the results. The negative results of linearregression is an indication that players increase their behaviour of drift-ing away from their original gameplay .By using the previous time point as the reference of rehavior we can mea-sure the amount of change between any two consecutive time points.106CHAPTER 4. MEASURING ITEMS' BEHA VIOURAL CHANGEThis allows detection of players' behaviour transition from one time pointto another. Figure 4.7 of the 10 rounds dataset shows that players strat-egy change from one time point to another is constant. This is indicatedby the linear regression of AUC and Rand measures. In contrast Figure4.9 of 27 rounds shows that the change between time points is decreasingthroughout the progress of the game.At 002rst glance, the results of 10 and 27 rounds datasets are not consistent.However, after taking a closer look at the results, we can detect that theplayers' behaviour change in 27 rounds dataset is stable without any de-crease until round 10 of the game. As shown in Figure 3.16 this decreasemight be due to the fact that most of the players dropped their contribu-tion to zero when they reached round 10. This means there is no roomfor further change left in the game except some players randomly startto increase their contribution again but the rise is not constant, so afterround 10 we detect less change than expected.As we hypothesised in the previous section, player behaviour has to beconsistent in both datasets. The results for measuring changes using the002rst time point as the reference of rehavior are compatible as players' con-tribution drops gradually in both cases. The results of using the previoustime point as the reference of rehavior show that players strategy changeis constant until round 10. In 27 rounds dataset, most players' contribu-tion after round 10 dropped to zero meaning there is no room for fur-ther change in their strategy . Hence, the amount of change in their strat-egy decreases and their game pattern starts to become similar betweenany two consequent time points. These results show that the proposedhypothesis holds true. This is yet another indication that the proposedmethod produces consistent results for similar situations.The results of the proposed method for both datasets are compatible withthe 002ndings of economists [119, 136, 137]. However, this method pro-vides a tool which enables them to quantify changes in players behaviour.1074.5. MEASURING PLA YERS' STRATEGY CHANGE OVER TIME
050a051 K226means Clustering
050b051 PAM Clustering
050c051 C226means Clustering
050d051 Hirarchical ClusteringFigure 4.6: Results of various clustering methods using the 002rst timepoint as reference of rehavior to calculate the amount of changes whichhappen to the groups of items in consequent time points in the 10 roundsPGG dataset.Quantifying behaviour change is important so they can measure the nu-anced differences between various gameplay setups like the length of therounds, the percentage of the rewards from the public project, and know-ing the identity of other players.108CHAPTER 4. MEASURING ITEMS' BEHA VIOURAL CHANGE
050a051 K226means Clustering
050b051 PAM Clustering
050c051 C226means Clustering
050d051 Hirarchical ClusteringFigure 4.7: Results of various clustering methods using the previous timepoint as reference of rehavior to calculate the amount of changes whichhappen to the groups of items in consequent time points in the 10 roundsPGG dataset.4.5.2 Using MONICWe used MONIC1to gain more insight into the public goods games dataand to compare our results with the existing methods of measuring clus-ter changes in different time points. The data for each time period wereclustered separately using k226means with four clusters. The clusteringwas carried out on the main temporal attributes of the data, namely be-
1Available at http://infolab.cs.unipi.gr/people/ntoutsi/monic.html1094.5. MEASURING PLA YERS' STRATEGY CHANGE OVER TIME
050a051 K226means Clustering
050b051 PAM Clustering
050c051 C226means Clustering
050d051 Hirarchical ClusteringFigure 4.8: Results of various clustering methods using the 002rst timepoint as reference of rehavior to calculate the amount of changes whichhappen to the groups of items in consequent time points in the 27 roundsPGG dataset.lief and contribution. Then the data and cluster labels of items in eachconsequent pair of time points was fed to the MONIC algorithm to cal-culate changes to clusters from one time point to another. The methodcalculated the number of survived, appeared and disappeared clusters,as shown in 002gures 4.10 and 4.11, for the ten rounds of the game.In the 10 rounds dataset, the number of survived clusters reduced fromfour clusters between the 002rst and second time points until it reached110CHAPTER 4. MEASURING ITEMS' BEHA VIOURAL CHANGE
050a051 K226means Clustering
050b051 PAM Clustering
050c051 C226means Clustering
050d051 Hirarchical ClusteringFigure 4.9: Results of various clustering methods using the previous timepoint as reference of rehavior to calculate the amount of changes whichhappen to the groups of items in consequent time points in the 27 roundsPGG dataset.zero, while new clusters appeared in the middle of the 002fth and sixthgame rounds. Then the number rose again until the end of the game.This might be due to the fact that players are changing their strategies andexploring new options until they ultimately settle on a certain strategicpattern. This change is consistent with our 002ndings, as the measuresslightly increase between the 002fth and seventh time points, which mightbe an indication of players changing their strategy back to their original1114.5. MEASURING PLA YERS' STRATEGY CHANGE OVER TIMEone. As Keser and Winden [138] suggest, this change might be due to theplayers responding to the average contribution of other players in theprevious round.
Figure 4.10: Number of survival, appearance and disappearance of clus-ters between every tow consequent time points for ten rounds publicgoods game as measured by MONIC.The results for the 27 rounds dataset is not straightforward as the num-bers of cluster survivals, appearances and disappearances change morefrequently . However, the cyclic pattern of increasing and decreasing num-ber of survived clusters might be an effect of changing players' strategiesor due to the underlying algorithm, as it provides an ageing factor to theitems.
Figure 4.11: Number of survival, appearance and disappearance of clus-ters between every tow consequent time points for 27 rounds publicgoods game as measured by MONIC.112CHAPTER 4. MEASURING ITEMS' BEHA VIOURAL CHANGEAs the MONIC algorithm was originally introduced to detect cluster changesin data streams, it uses an ageing factor which reduces the effect of olderitems in the cluster and removes items older than two time points [52].This ageing factor is essential for the algorithm to keep up-to-date withthe 003owing data stream and provide the right results for the current sta-tus of the clusters. However, this might not be useful for public goodsgames data, as there is a 002xed number of players. This might result in theremoval of players who stay in the same cluster for long time points. Theeffect of the ageing might not be obvious in the 10 rounds game due tothe limited number of time points, but it might still undermine players'strategies.While the proposed method assumes a 002xed number of clusters to cal-culate the change in items membership, the MONIC algorithm is an ef-fective method for gaining insights into the available clusters and theirstability by measuring the number of survived clusters between two timepoints. However, it does not measure the amount of items drifting fromone cluster into another, which can be detected by the proposed method,as it introduces a speci002c ratio between each consequent time point, in-dicating the amount of change happening to the items in the clusters bycalculating their membership change among clusters.MONIC can be compared with the proposed method especially the caseof previous time point as reference of rehavior as both of these meth-ods compare the current clusters with the previous time point. The re-gression result for the average of cluster moves 050appear, disappear andsurvive051 is near to zero, which is compatible with the proposed methodresults using the previous time point as reference of rehavior except for27 rounds clustered by PAM and hierarchical clustering. By comparingresults from the proposed method and MONIC, we can conclude that theplayers slightly and gradually change their cluster membership. How-ever, the amount of change is stable from one time point to another. The1134.6. SUMMARYproposed method provides an exact number for the change while theMONIC presents overall clusters movement and change.4.6 SummaryThe primary purpose of this chapter is to answer two of the main ques-tions of the study . The 002rst question is: Can we use the proposed methodin chapter three to measure changes over time? The second question is:Do players of PGG behave as predicted by economists? As presentedin chapter three, the proposed method consists of two main steps. The002rst step is to cluster items at each time point, and the second step is tomeasure changes happening in the clusters of each time point using areference of rehavior. Many types of reference of rehavior for items inthe dataset can exist; in this chapter, we tested two, namely the 002rst timepoint and previous time point.To answer the 002rst question we checked the validity of hypothesis 1 and2. Laid out in the 002rst chapter, they are:017To prove that the above proposition is valid the results of differentexternal clustering indices and AUC should be consistent.017Using different clustering algorithms will not produce a signi002cantdifference in the 002nal result of quantifying the changes over time aslong as same clustering algorithm is used at both time points.These two hypotheses examine the main aspects of the proposed methodfor measuring items' changes over time in temporal data. If these twohold true, then they can be presented as evidence which proves that theproposed method is working adequately and consistently .To check the validity of these two hypotheses, we used the synthetic datawhich was introduced in chapter three. Prior to the experiment of test-ing the proposed method, the rationale for selecting certain clustering114CHAPTER 4. MEASURING ITEMS' BEHA VIOURAL CHANGEmethods and external cluster validity indices is presented. It is crucialto make sure that the appropriate range of clustering methods are usedso that items at each time point are clustered appropriately . We choseclustering methods which mainly separate items according to their dis-tance from each other; the clusterings used are k226means, c226means, PAMand hierarchical clustering for this purpose. For external cluster valid-ity indices, we have mainly used the matching based methods of JaccardCoef002cient, Rand Statistic and Fowlkes-Mallows Measure. We have alsoused the Variation of Information VI method, which is an example of astatistical-based model, and AUC of ROC with players to measure theef002ciency of classi002cation.Tests of the synthetic data using the proposed method with suggestedclustering and external cluster validity indices multiple sample sets of re-sults are produced. By using p-value for Wilcoxon-test, we demonstratedthat each pair of results is similar to each other except for some hierarchi-cal clustering cases. This similarity proves that the results of proposedmethod are consistent regardless of the clustering method used. This,therefore, veri002es the validity of hypothesis 1. While the similarity be-tween different external cluster validity indices did not hold true, eachexternal cluster validity indices result, however, proved to be similaracross different clustering algorithms meaning the results of the exter-nal cluster validity indices are consistent but with different sensitivitiesto the change of items. After conducting these tests, it can be concludedthat the proposed method can be successfully used to measure and quan-tify changes of items in temporal data.To answer the second question, we used the proposed method on bothPGG datasets introduced in chapter three. The same choice of clusteringmethods and external cluster validity indices are used in the process ofquantifying players' strategy change. Four clusters are used of playersin each time point because economists have categorised players into four1154.6. SUMMARYgroups in their studies. The four-cluster model was a viable choice aswe tested the data using the Elbow method to determine the number ofclusters in the datasets. The results showed that the players' strategychange when approaching the end of the game. However, the changeitself between any two time point is constant on average. This resultcorresponds with economists' conclusions.To gain another perspective on the players' strategy change, we usedthe MONIC method which was created to detect cluster change in datastreams. The results showed that the clusters periodically appear anddisappear through data points in the temporal data of PGG. This is anindication that the players' strategy changes as new clusters are emerg-ing and others vanishing. Moreover, the unstable number of survivedclusters is an indication that the players are not changing their strat-egy homogeneously and their reaction varies from each other. While theMONIC method provides a new perspective on the dataset, however, itis not possible to directly compare it with the results of our proposedmethod because they consider different aspects of the data. The pro-posed method quanti002es the amount of individual items exchange be-tween clusters while MONIC shows the changes which are happening tothe clusters in general.In this chapter, we made a comparison between two different referencesof behaviour for items in temporal data, namely the 002rst time point andthe previous time point of the temporal dataset. However, another ref-erence of rehavior is proposed in chapter three which is the general be-haviour across all time points. This type of reference of rehavior is possi-ble if the class of each item is known in the temporal data. In chapter 002ve,we propose a new algorithm to classify items in a temporal data by opti-mising rules for classes provided by experts or human agents. In chaptersix, we will use the produced classes of items as the reference of rehaviorto measure changes in items.116Chapter 5Optimizing T emporal Rule-BasedClassi002cation5.1 IntroductionThis chapter answers the question posed in chapter one regarding theplayers' classi002cation in the Public Goods Game data sets. The aim is tocompare the Optimizing Temporal Rule-Based Classi002cation proposed inchapter three section 3.4 against the available classi002cation method whichis used by economists [80]. This comparison is formed into a Hypothesis4 in chapter one. If this hypothesis holds true, this means our proposedmethod is performing better than the available classi002cation method.After classifying players with the proposed method, we use their newclasses to answer two more questions about players behaviour. The 002rstquestion concerns consistency of players strategy in various length of thegame. To answer this question, we will check the validity of Hypothesis5 as it states that the length of the game does not affect player strategy .The second question concerns using the overall general behaviour as Ref-erence of Behaviour as our Hypothesis 3 in chapter one states that usingoverall behaviour as reference of rehavior is more stable than the other1175.1. INTRODUCTIONtwo methods; the 002rst time point and the previous time point. If this hy-pothesis holds true, so measuring changes over time can be performedreliably regardless of the underlying clustering and external cluster va-lidity indicess.Hypothesis 4 indicates that using 003exible rules by experts and then lateroptimising and specifying these rules will generate classes which aremore representative of player's behaviour during the game. While thishypothesis is speci002c about the domain of the data set namely a publicgoods game, the proposed classi002cation method can, however, be usedon data sets with similar properties. For example, stock market pricedata, students' performance over the years and effects of drugs on pa-tients. In chapter six, we will classify stock market data using the pro-posed classi002cation method.The proposed classi002cation method has two main steps. The 002rst stepuses specialised de002nitions from 002eld experts for classes which exist foritems. These de002nitions are based on aggregated attributes of the tem-poral data. The second step is the optimisation process. In this step, thebest possible classi002er for the items will be selected. The best classi002eris a classi002er which can produce the most compacted classes of items050players051 at each time point in the temporal data. The compactness of theclasses is calculated by using a cost function which is based on the over-all dispersal of items in each class. Classes' dispersal can be measuredby using internal cluster validity indices like the Dunn Index, distancemeasures like Euclidean distance or statistical measures such as standarddeviation.In this chapter, we use brute force to 002nd the best classi002er. Brute forceis simple and can solve classi002cation in a relatively reasonable time forthe available public goods game data sets. However, it can not performoptimally with a larger amount of data. Therefore, in the next chapter, wewill replace the brute force with a heuristic method, namely differential118CHAPTER 5. OPTIMIZING TEMPORAL RULE-BASEDCLASSIFICATIONevolutionary algorithm DEA, to optimise rules of the classi002er.5.2 BackgroundMost rule-based classi002cations use the 'if..else..' form to classify under-lying data, which is conducive for easier comprehension [139]. The rulescan be learned through examples or provided by an expert [140]. Asexplained below, many different data mining and analysis methods userule-based systems for classi002cation.Rule-based classi002cations are used in fuzzy systems. For example Cor-don et al. [141] proposed a new Fussy Reasoning Method 050FRM051 withbetter optimization for the system, whereby the rules do not lose theircomprehensibility . Ishibuchi [142] compared two kind of voting schemesfor fuzzy rule-based classi002cation.Experts use common sense and vague terms to solve problems and clas-sify situations/items, while an expert system that tries to simulate humanexperts uses logic to conclude decisions instead of hard programmed so-lutions [139]. A number of expert systems that rely on rule-based logichave been introduced [143].Many other methods have been introduced that use rule-based systemsfor classi002cation, like [144], which proposed a generic classi002er construc-tion algorithm 050ICCA051. [145] proposed an algorithm for a rule-based clas-si002er that can extract rules from uncertain data, and used probability esti-mation for rule learning, inspired by the use of probabilities to constructdecision trees.To classify players in the public goods data sets, economists use players'contribution tables [80]. In this table, players state their intent for con-tribution in response to the rounded average contribution of other co-players. Thus, this table consists of players intended contribution condi-1195.2. BACKGROUNDtioned by the contribution of other players ranging from 0 to 20. Accord-ing to the players' response, economists classify them into four classeswhich are conditional co-operator, free riders, triangle contributors andothers.However, classifying players according to the contribution table whichhas been completed by the players prior to the game rounds might notrepresent players' actual behaviour during the game. This table ignoresplayers' real contribution in the game rounds, which might change dur-ing games due to the change in their strategy as a result of their experi-ence from previous game rounds.There are many well known temporal classi002cation methods which useeither dynamic time warpingDTW[62] or Euclidean distance to classifytime series data sets. Examples of temporal classi002ers such as Douzal-Chouakria et al. [68] used decision trees, Vincent S. Tseng et al. usedNaive Bayes sequence classi002er [70] and Ranganatha Sitaram et al. usedSupport V ector MachineSVMas a temporal classi002er with different ker-nels [69]. However, all these methods require training set samples whichare required to build their classi002er instead of following experts de002ni-tion to classify items in the temporal data.The available data sets for public goods games do not contain labels forplayers that re003ect their behaviour during the game because experts usecontribution tables to classify players. However, these tables are not di-rectly related to their behaviour. Using a static contribution table is eas-ier for economists to classify players as they can follow players answersmanually or using simple methods. This simpli002ed method can not bedone with the temporal data even though it better re003ects player be-haviour. In chapter two, multiple examples are presented for methodsof extracting rule-based classi002ers using genetic [25], evolutionary algo-rithms [26] and SVM [29]. However, these methods require training datasets to build the classi002er.120CHAPTER 5. OPTIMIZING TEMPORAL RULE-BASEDCLASSIFICATION5.3 ApproachThe proposed classi002cation method consists of two main steps; rule gen-eration and rule optimisation, as shown in 002gure 5.1. The optimised rulescan be reconstructed as a decision tree. As explained in chapter two, de-cision trees and rule-based classi002ers can interchangeably represent eachother. However, rule-based representation is more preferable by humansas they are more intuitive and they might also be more ef002cient than theircounterparts of decision trees.In the subsections below we will detail the process of the rule genera-tion and the methods of determining the number of classes and limitsof each class. Then, we discuss the optimisation process and the pa-rameters which are to be optimised as well as methods for measuringthe optimum classi002er such as using internal cluster validity indices andeuclidean distance among items. Finally , we will lay out a comparisonmethod between the results of the proposed classi002cation method andavailable classi002cation for players of the public goods game.
Figure 5.1: An illustration of the proposed classi002cation algorithm andits relation with temporal data and their aggregates.1215.3. APPROACH5.3.1 Choosing Initial Limits for ClassesFor a selected number of classes, every class has a limit in each of theaggregated 050non-temporal051 attributes which are used in the classi002cationrules. A limit is start and end values of a class in a certain attribute ordimension and these can be represented by [min, max] pairs. As we men-tioned in chapter three section 3.4.1, classi002cation rules are formulated ina nested if-else fashion to evaluate items' class as well as classes of priori-ties . The class limits for the attributes are represented in the if conditionsof the classi002cation rules using logical operations like6and>.A general template for class rules is shown in algorithm 5.1. The classespriority is embedded through multi if-else statements. In the practicalimplementation, for the sake of clarity and simplicity , the rule of eachclass can be represented in a method which returnstruevalue if the at-tributes of an instance satisfy the conditions of the class orf alseother-wise. The last branch of the nested statement can be one of these options:017An else statement which represents a class with extreme valueswhich can always be satis002ed after all other classes are tested017An else statement which represents 224others224 or elements which cannot be classi002ed by the given set of rules.017An elseif statement which represents one of the classes. In this case,any outlier with extreme values will be ignored and not classi002ed.To produce initial rules for classes with their range of values for eachclass limit in the aggregated attributes, the knowledge of experts in thespeci002c 002eld is required. However, experts might need speci002c types ofaggregated attributes which should be created to formulate these rules.Moreover, to visualise data as an aid for the human expert to make moreinformative decisions about the class rules, an item pro002le should be cre-ated. In later subsections, we will discuss the methods of formulatingrules through human experts, data manipulation and item pro002ling.122CHAPTER 5. OPTIMIZING TEMPORAL RULE-BASEDCLASSIFICATION
Algorithm 5.1:Simple Multi if-else statements to priorities classes
1ifConditions for Class Athen
2Item is class A;3end4else ifConditions for Class Bthen
5Item is class B;6end7else ifConditions for Class Cthen
8Item is class C;9end10else
11Item is Class Others;12end
Data ManipulationThe 002nal classi002cation rules are expressed in the form of aggregated at-tributes or any available static 050none-temporal051 attributes. These aggre-gated attributes are derived from temporal attributes of the availableitems in the data set. Each items' temporal attribute can be aggregated inmany ways as required by the classi002cation rules. Possible aggregationsfor temporal attributes can be originated from basic statistical analysessuch as:017T otal:Returns the summation of all available time points' values.017Mean:Returns the total of a temporal attribute divided by the num-ber of time points.017Median:Returns the middle value of a temporal attribute after sort-ing all values of the available time points.017Mode:Returns the most frequent value from available time pointsof a temporal attribute.1235.3. APPROACH017Count:The occurrence number 050frequency051 of a value or targetedvalues. For example, the number of zero contribution in all roundsfor each player in public goods games or the number of resit sub-jects for each student in the entirety of their study .017Minimum:Returns the lowest value of a temporal attribute amongall values of the available time points.017Maximum:Returns the highest value of a temporal attribute amongall values of the available time points.
Player ID	Time	Belief	Contribution
Belief
ContributionjZeroj
1	1	4	0	3	5	11	2	1	9	3	5	12	1	3	2	6	7	02	2	9	12	6	7	03	1	5	0	8	0	23	2	10	0	8	0	2
Table 5.1: Sample of the public goods game data with three aggregatedattributes which are derived from temporal attributes. The aggregatedattribute headers are denoted by their respective mathematical notation.According to the classes' de002nitions, the behaviour of players is deter-mined by their contribution and their beliefs on their co-players' contri-bution. Given this, the required aggregations for classifying players ofpublic goods game using the proposed classi002cation method are mean ofcontribution, mean of belief and count number of zero contributions. Ta-ble 5.1 shows a simpli002ed sample of the public goods game data set withthe three newly-created aggregated attributes.124CHAPTER 5. OPTIMIZING TEMPORAL RULE-BASEDCLASSIFICATIONVisual Pro002lingVisual pro002le for an item is its important attributes 050temporal and non-temporal051 displayed for human experts in a simple graph050s051. These items'pro002les can be used as an aid for experts to make better decisions forthe class rules, and the start and end limits of each class for the usedattributes in these rules. These pro002les can provide a visual tool for dis-playing the quality of the classes generated after the optimisation step.This allows for further enhancement of the initial limits for classes. Byexperts being able to iteratively modify these ranges, better classes canbe created for the items intended to be classi002ed.Figure 5.2 shows three samples of players pro002les. Each pro002le displaystwo graphs. The 002rst graph shows a player's contribution table with itsmean and regression, features which are used by economists as a basefor classifying players of public goods game. The second graph showsplayers actual contribution and belief in all 10 rounds with their respec-tive mean and regression. The proposed classi002cation method relies onthe data of the second graph to classify players of the public goods game.From these three samples and the rest of players' pro002les, we can noticetwo points:017Players might change their strategy from their contribution table.Given that, using a contribution table to classify players might notre003ect their actual behaviour during the game.017The regression value of most players' contribution and beliefs arenegative, which indicates their decline while progressing throughgame rounds.1255.3. APPROACH
Figure 5.2: Three samples of player's pro002les of the public goods game10 rounds data set.126CHAPTER 5. OPTIMIZING TEMPORAL RULE-BASEDCLASSIFICATIONDriving Classes from Experts' KnowledgeClassifying items using human experts' knowledge can be accomplishedby two methods. The 002rst method is directly acquiring classes' rules fromexperts of the 002eld of the data as example [146]. The second method is in-directly driving classes from existing common knowledge about the dataand the items which have to be classi002ed. Experts' de002nition for classescan be used to generate rules. In other cases, rules can be generated fromother classi002cation methods as in [147] or numerically analysing the datato generate rules as in [148]. However, in this study , we will combinethese two methods to generate initial classes. The rules are derived froma modi002ed version of the available de002nitions for classes [80]. To 002nalisethese rules we asked experts iteratively their opinion on the producedclasses for players using players' pro002les for a visual aid of their deci-sions. As a reminder for the available classes, we list them here:017Conditional Co-Operator:these players increase their contributionwhen other players' contribution increases.017Free Riders:these players do not contribute to the project regard-less of other players' contribution.017T riangle Contributors:these players' contribution will increase to apoint with the rise of other players' contribution to a certain point.Then their contribution starts to decline a while other players in-crease their amount of contribution.017Others:these players are contribute in a random and unexpectedpattern.The above experts' de002nitions for public goods game players are basedon the static data of 050contribution table051 [119].Therefore, a modi002ed ver-sion of de002nitions is used in our classi002cation with the aid of visual pro-002ling of players' behaviour across all rounds of the game. The modi002edversion of classes for players' classes in the public goods game with 201275.3. APPROACHpoints as the maximum available contribution points are:017Free Riders:players who contribute by equal or less than one pointon average for all rounds or who are not contributing in most rounds.This class corresponds to the traditional category of Free Riders.017Weak Contributors:players who contribute between 1 and 5 orthose not contributing in half of the rounds. In the old categoriza-tion, this class loosely relates to conditional contributors.017Normal Contributors:players who contribute on average around5 points. This class is strongly related to conditional contributors asit 002ts the same criteria.017Strong Contributors:players who contribute more than 10 pointson average. This class relates to conditional comparators and othersin the classical categories.However, these class de002nitions can be vague and lead to imprecise de-cisions for the 002nal limits of classes, hence generating imprecise rules forthe classes or as described by L. Zadeh [146] 224Much of the uncertaintyin the knowledge base of a typical expert system derives from the fuzzi-ness and incompleteness of data, rather than from its randomness224. Toovercome this imprecision, the [min, max] range of each class limit isproposed as described earlier.
Contribution
BeliefjZeroj
FR	WC	NC	FR	WC	NC	FR	WC
10 Rounds
Min	0	1	2	2	4	2	6	5Max	1	4	6	9	9	9	9	7
27 Rounds
Min	0	1	2	2	4	2	20	15Max	1	4	6	9	9	9	25	20
Table 5.2: The attributes' [min, max] values for classi002cation rulesFor the two public goods game data sets used in this experiment, the128CHAPTER 5. OPTIMIZING TEMPORAL RULE-BASEDCLASSIFICATION[min, max] boundaries are determined using the above de002nitions withmultiple iterations of classi002cation to enhance boundaries through do-main experts' decisions. The classi002cation rules are prioritised so thatthe Free Rider FR class has the highest priority followed by Weak Con-tributor WC, then Normal Contributor NC while Strong Contributor hasthe lowest priority . The attribute boundaries for classes are distributedso that all values from the lowest to highest values are covered. Thismeans there are no rules for SC class as players who are not classi002edwith higher priorities will be classi002ed as SC by the 'else' statement. Ta-ble 5.2 shows these range boundaries for attributes which are used toclassify players in the public goods game data sets. It can be noticed thatthe boundaries for both 10 and 27 rounds data sets are similar except forthe number of zero contributions, which is different due to the differentlengths of the games. The second step of classi002cation will reduce theseranges into scalar values by using optimisation as detailed in the nextsection.5.3.2 Selecting Best Classi002erBy selecting a single value from each proposed [min, max] range for theclassi002cation rules, we can create a classi002er with de002ned crisp edges.However, the initial classi002cation rules with the proposed range of valuesfor each attribute produce numerous slightly different crisp classi002cationrules. As mentioned in chapter three section 3.4.2, the best classi002er willproduce the most compacted classes for items at each time point. Thecompactness of classes is calculated by this equation which we use as acost function with the aim of minimising it.f050C051 =TXt=1NXn=1CM050ctn051002 jcnj0505.1051In this function T represents the number of available time points, N is the1295.3. APPROACHnumber of clusters,jcnjis the cardinality number of items in cluster n,andCM050ctn051is a compact measure for cluster n in t time point.There are many ways to measure the compactness of classes suxh as Eu-clidean distances between items, statistical measures, and internal clus-tering validity measures. To use all of these different compactness mea-sures a general cost function is created with the place holder for the com-pact measure function as shown in Algorithm 5.2.However, not all the presented compactness measures can calculate mul-tivariate data such as standard deviation. For this reason, another generalfunction is created to calculate the sum of individual attributes to ensurethat all compactness measures can operate in multivariate temporal data.In the next subsections, we will discuss each type of compactness mea-sure.
Algorithm 5.2:General cost function with a place holder for differenttypes of compact measuresCM
1Functioncost
Input:CM = Compactness functionInput:Temporal data with classi002cation informarion2foreacht in Timesdo
3foreachc in Classesdo
4costs.append050CM050c[t]051 * count050c051051;5end6end
Statistical MeasuresThere are many statistical measures which can calculate the compactnessof a single variate data [149]. There are also other variations of these mea-sures which can analyse multivariate data sets [150]. However, we pre-ferred to use the former as they are more widely used and have built-in130CHAPTER 5. OPTIMIZING TEMPORAL RULE-BASEDCLASSIFICATIONimplementations in most programming languages. For multivariate tem-poral data sets, we simply calculate the total sum of all single temporalattributes as the 002nal cost function.For the tests of statistical measures as cost functions, we used standarddeviationsdand interquartile rangeIQR. Sd calculates the dispersion ofdata around the mean [149]. This measure assumes normality of data, soit is not always possible for it to be used as a cost function. IQR is thedistance of the middle 50% of data which lies between the 002rst and lastquarter [97]. As this measure ignores the 002rst and fourth quartiles, it isinsusceptible to outlier values. On the other hand, it might ignore themall together which also might not be a desired characteristic. These twostatistical functions are not tailored speci002cally to calculate compactnessof data but they can capture the magnitude of data spread.Euclidean DistanceEuclidean distance is the shortest length between any two points [151].Euclidean distance can calculate the distance of two points n and m fromone dimension to any D dimension using this equation:len050n; m051 =vuut
DXi=1050ni000mi05120505.2051To compare results of Euclidean distance based cost function with the sta-tistical results we use the naive method in our experiments as describedby Keogh et al. [152]. In this method, the total sum of distances for eachdimension is calculated by simply looping through all dimensions sepa-rately . This loop will change the Euclidean equation to:len050n; m051 =DXi=1p
050ni000mi05120505.3051We used two cost functions based on Euclidean distance. The 002rst cost1315.3. APPROACHfunction is 'complete distance' which is the total distance of each itemin any class to all other items in the same class. The second cost func-tion is 'centroid distance' which is the total distance of items in one classto the centre of that class. This method uses a similar technique whichexists in k226means clustering to 002nd the best clusters. Therefore, it mayhave the same drawbacks of k226means clustering including its sensitivityto extreme values 050or outliers051 [153].Internal Cluster V alidity IndicesInternal cluster validity indices are a range of measures designed specif-ically to validate the results of clustering algorithms using structural in-formation of the proposed clusters by the algorithm. The structure of theclustering includes both 1051 compactness of clusters. That is, how closeitems are to each other inside one cluster and 2051 separation between clus-ters which means how far each cluster is from other clusters. A betterclustering algorithm generates closer items in each cluster and more dis-tant clusters from each other [154]. Please refer to chapter two for moredetail on Internal cluster validity indices.While most of the Internal cluster validity indices are specially designedto measure the compactness of clusters, they calculate the distances ofitems in the clusters and the distance between clusters at the same time[2] and then returns a single value to describe the status of the clusters.While this feature is proven to be important to validate the quality of clus-tering, it also creates a challenge for embedding them in our cost functionwhich requires multiplying compactness of the cluster to its size. So forour tests with Internal cluster validity indices we will use a modi002ed ver-sion of the proposed cost function which is:f050C051 =TXt=1NXn=1CM050ctn0510505.4051This modi002ed cost function does not multiply Compactness Measures132CHAPTER 5. OPTIMIZING TEMPORAL RULE-BASEDCLASSIFICATIONCM function withjcnjthis might lead the algorithm to create only one ortwo big clusters. This characteristic of the Internal cluster validity indicesmight limit their use as CM in our cost functions.There are many available Internal cluster validity indices [155]. However,for the experiments of the proposed classi002cation method, we selectedfour Internal cluster validity indices which directly calculate compact-ness of items in the clusters:017Dunn Index 050Dunn051: is calculated as a ratio of the minimum dis-tance between items of different clusters and maximum distancebetween items inside a cluster [37].017Davies.Bouldin 050DB051: is calculated as the average of all clusters'maximum variance around the mean of their cluster. [46]017SD: is calculated by using the average scattering of items in eachcluster and the total separation between clusters [40].017S
Dbw: is calculated by using intra-cluster variance and inter-clusterdensity to identify very compact clusters with the highest separa-tion between clusters [40].In the next section, we will compare our results with economists classi002-cation to determine the performance of the proposed method using newderived attributes from available attributes of the 10 round public goodsgame data set.5.4 Performance of the Proposed Classi002cationTo test the performance of the proposed classi002cation the ten rounds ofpublic goods game data set are used for comparison. We compare ourclassi002cation results with the labels of players produced by economistsusing class de002nitions provided by Fischbacher et al. [80] for players'1335.4. PERFORMANCE OF THE PROPOSED CLASSIFICATIONstrategy types. However, the data set does not provide a ground truthof player types, so it is challenging to make a direct comparison betweentwo methods. To overcome this issue, we compare both results in twoways:017By comparing players' contribution behaviour of each class in allten rounds. We can assume that this better classi002cation processwill produce more homogeneity , hence more compact contribution,at each time point.017By using 75% of the players' data to build two classi002ers for an-other classi002cation model such as SVM. The 002rst classi002er is builtby using economists' labels for players and the second using theproposed classes in this study . Then, we predict the remainingplayers' labels and classes using their respective models. The classi-002er model with a higher level accuracy to predict players' labels orclasses is an indication of a better underlying classi002cation methodwith more consistent results for players' behaviour. The choice of75% training and 25% test are decided by considering two facts.First, there are suf002cient data for the classi002cation model to be setdue to the fact there are 10 and 27 rounds of the game and then treat-ing each round as a separate dataset. Second, a suf002cient amount oftest data is required so that we can determine which classi002cationmethod performs better.5.4.1 Optimizing Classi002cation RulesTo compare the proposed rule-based classi002cation method with economists'labels for players, the rules have to be optimised so that all ranges of[min, max] discussed in detail in section 5.3.1 become a single value.All possibilities of the range combinations are enumerated using bruteforce to 002nd the best classi002er. The best classi002er is selected according134CHAPTER 5. OPTIMIZING TEMPORAL RULE-BASEDCLASSIFICATIONto the proposed cost functions in section 5.3.2 and its subsections. Thebase of the cost functions might be a statistical measure 050IQR or Stdev051,Euclidean distance 050Complete or centroid051, or internal cluster validity in-dices 050Dunn, DB, SD or S
Dbw051Table 5.3 displays the best values as selected by the optimisation processusing different cost functions. After this point, each range can be replacedwith a single value. For example, the classi002cation rules which determinewhether a player is a free rider or not is provided by the experts are asfollows:i f 050 050 meanContrib<[ 0 , 1 ] & & meanBelief<[ 2 , 9 ] 051j jzeroContrib>[ 6 , 9 ] 051item = 1After optimising this rule using one of the cost functions such as IQR itbecomes:i f 050 050 meanContrib<1 & & meanBelief<2051j jzeroContrib>6051item = 1To assess the impact of different cost functions on the classi002cation rules;the number of players in each class is calculated and listed in Table 5.3. Aswe anticipated in section 5.3.2, the cost functions which are based on in-ternal cluster validity indices produce imbalanced classes with one largeclass except for SD. This is due to the underlying equation for these Inter-nal cluster validity indices. Moreover, the Euclidean based centroid dis-tance creates an empty class, and stdev also creates imbalanced classes,despite multiplying CM with the cardinality of classes to prevent creationof a large class.These cost functions might be modi002ed to work in different situationswith different data sets. Moreover, domain speci002c cost functions can becrafted to ful002l the requirements of the provided initial rules. For thepublic goods game, we consider that the remaining three cost functions050IQR, Complete Distance and SD051 are the best-suited to be used for clas-sifying players in the data. These cost functions do not allow for big1355.4. PERFORMANCE OF THE PROPOSED CLASSIFICATION
Contribution
BeliefjZeroj
FR	WC	NC	FR	WC	NC	FR	WC
Statistics
IQR	1	3	5	2	4	2	6	5Stdev	1	1	6	2	4	2	9	6
Euclidean
Complete	1	3	6	2	4	2	7	5Centroid	1	2	2	2	4	2	6	5
ICVI
Dunn	1	3	2	7	7	2	6	6DB	1	4	2	2	5	2	5	6SD	1	4	6	7	4	2	9	6S
Dbw	1	4	4	2	4	2	8	6
Table 5.3: The attributes' best values for the ranges of the initial classi002-cation rules of 10 rounds the public goods game data set using differentcost functions.classes to form which might be a result of their mathematical equationsrather than similarity of players' behaviour. We will, therefore, only usethem for later comparisons for the public goods game data sets.5.4.2 Comparing Contribution Behaviour of the PlayersThe essence of classifying the strategy of players is to describe their con-tribution behaviour pattern [80] because the only attribute which mattersat the end of each round is how much a player will contribute and thenhow this contribution changes in the next rounds. Therefore, any classi-002cation which can create more homogeneous players with the same con-tribution behaviour at each time point is a better classi002cation method.To determine which classi002cation method performs better at classifying136CHAPTER 5. OPTIMIZING TEMPORAL RULE-BASEDCLASSIFICATION
Cost Function	Fr	Wc	Nc	Sc
Statistics
IQR	46	22	22	50Stdev	36	10	58	36
Euclidean
Complete	38	30	37	35Centroid	46	10	0	84
ICVI
Dunn	42	4	9	85DB	37	34	2	67SD	28	48	28	36S
Dbw	37	40	1	62
Table 5.4: Number of players in each class 050Cardinality number of classes051in 10 rounds of the public goods game data set using different cost func-tions.players' according to their behaviour, we compare each class's contribu-tion distribution at each time point for both our proposed classi002cationand the available classi002cation for the public goods game.We use two methods for comparing the distribution of classes' contribu-tion. The 002rst is to use the visual method of box-plots and means, andthe second involves using the average of standard deviation. We com-pare contribution behaviour of economists' labels against our classi002ca-tion method according to the three selected cost functions.Figure 5.3 shows boxplots of the public goods game players' contributionat all time points 050rounds051 for each label of players separately . Players areclassi002ed using economists method for classifying players which dependon the contribution table 050none-temporal attributes051. In this 002gure, wecan observe that:017The median of free riders is almost always zero 050except round two051.However, the 002rst 002ve rounds show a very high IQR values whichcan be interpreted as there being a large difference in players' be-haviour.1375.4. PERFORMANCE OF THE PROPOSED CLASSIFICATION
Figure 5.3: Boxplots of the players' contribution behaviour of differentplayer labels in the 10 rounds data set of the public goods game. Thelabels are generated using economists' de002nitions for various strategytypes.017The median of the players' contribution is gradually dropping asexpected. However, all rounds have a large value for IQR, whichmight be an indication that player strategy varies from contributiontable to and actual contributions.017There is no signi002cant difference between behaviours of triangularcontributors and conditional contributors except starting with lit-tle higher contribution and there is a steeper drop for it during therounds.017The others class players do not follow any pattern for their contri-bution.Figures 5.4, 5.5 and 5.6 show the public goods game players' contribu-tions boxplots for different classes using proposed classi002cation with costfunctions IQR, Complete Distance and SD respectively . In these 002gures,138CHAPTER 5. OPTIMIZING TEMPORAL RULE-BASEDCLASSIFICATION
Figure 5.4: Boxplots of the players' contribution behaviour in differentclasses which are generated using proposed classi002cation method withIQR as a CM for the cost function.
Figure 5.5: Boxplots of the players' contribution behaviour in differentclasses which are generated using proposed classi002cation method withEuclidean complete Dist. as a CM for the cost function.1395.4. PERFORMANCE OF THE PROPOSED CLASSIFICATION
Figure 5.6: Boxplots of the players' contribution behaviour in differentclasses which are generated using proposed classi002cation method withSD as a CM for the cost function.we can observe that:017Free riders' median is always zero with very low IQR values meanthat players contribution in these classes are mostly zero as expected.017Except for strong contributors the IQR values for other classes at alltime points are lower than economists classes.017There is a noticeable difference in the players' contribution medianfrom one class to the next as the contribution of the same time pointrises from free rider to weak contributor and so on.017Except for the free rider class, all other classes' contribution mediangradually drops as expected.According to these observations, we can conclude that the proposed clas-si002cation method can produce better classes for players according to theirbehaviour with more homogeneous contributions among the same class.To check these observations, we calculated the average of the standard140CHAPTER 5. OPTIMIZING TEMPORAL RULE-BASEDCLASSIFICATIONdeviation of the ten rounds for each classes' contribution.
Cost Function	FR	WC	NC	SC	Mean
IQR	4	3.3	3.3	5.5	4Complete	2.1	4.6	3.7	5.6	4SD	1.7	3.9	3.9	5.7	3.8
Economists'-	CC	FR	TC	OT	MeanClassi002cation	5.7	4.5	4.2	6.3	5.2
Table 5.5: The ten rounds' average of standard deviation for players' con-tribution of each class using various cost functions to produce players'classes which are compared with the economist labels.Table 5.5 shows that the classes of the proposed classi002cation methodwith different cost functions have smaller standard deviation on aver-age in comparison to the economists labels for players. This means lessspread of contribution at each time point. which might be an indicationof better class models for the players actual contribution behaviour.5.4.3 Using a Third Classi002er for ComparisonWe use a third classi002cation algorithm to compare the proposed classi002-cation method and the existing economists' labels. In this experiment, weselected SVM classi002cation as the third classi002er due to its proven successand wide acceptance [156]. SVM uses optimised hyperplanes to classifydata. Hyperplanes can be linear or non-linear according to the used ker-nel in training. These hyperplanes are optimised through training usingpre-classi002ed data sets.Four SVM classi002ers are created using 75% of the players' data and classlabels. Each of these classi002ers used different labels of players which areoriginally generated by using either the economists' classi002cation or ourproposed classi002cation with different cost functions 050IQR, CompleteDist1415.4. PERFORMANCE OF THE PROPOSED CLASSIFICATIONor SD051. Then, we used the remaining 25% of the players to test the accu-racy of the different SVM classi002ers. The more accurate these classi002ersare, the better reliable and consistent labels are presented to them in thetraining and testing sessions. Hence, the better classi002er has producedthe train/test labels in the 002rst place. We used each time point of thepublic goods game data set separately to avoid a temporal dimension forthe SVM classi002er, and to check how consistent the provided labels are ineach time point. Moreover, multiple new attributes are derived from ex-isting attributes and used for the classi002cation to determine the accuracyof the classi002ers with attributes which have not been used to generatetrain/test labels. The new attributes are:017Payoff: The amount of points an individual player amasses duringeach round. This can be calculated by points that they kept + publicgoods project returns. The payoff value may have a great impact onthe players' behaviour for the next rounds.017
ContribT ab: The average of 'contribution table' which is indicatedby attributes [b0-b20]. This attribute is important in estimating theoverall level of players' initial willingness to contribute.017
Contrib: The average of players' contribution in all rounds. This002eld is important to ascertain the general level of contribution dur-ing the game.017InitialDiff: Difference between actual contribution and supposedcontribution according to the players' contribution table. The im-portance of this attribute is to determine the amount of players'strategy change during the game rounds.017
initialDif f: Average ofInitialDiffduring all game rounds. Thisattribute validates player's initial claim of willingness for contribu-tion.017PredecAcc: Accuracy of players' prediction. This attribute is calcu-142CHAPTER 5. OPTIMIZING TEMPORAL RULE-BASEDCLASSIFICATIONlated as the difference between player's belief about other playerscontribution and their actual contribution.017PredecAccSD: Standard Deviation ofPredecAccfor each player in allrounds of the game. This attribute detects how much a player cor-rectly anticipates their co-players' strategy .The new attributes which are derived from existing data may raise con-cerns about the level of correlation between them as they may might af-fect the performance of the classi002cation. Table 5.6 addresses all correla-tion values among these attributes.Contrib
0.549Payoff
-0.135	-0.58
ContribT ab
0.048	0.208	-0.169
Contrib
0.263	0.684	-0.486	0.296InitialDiff
0.235	0.511	-0.285	0.251	0.361
initialDif f
0.097	0.332	-0.218	0.34	0.489	0.743
Belief	Contrib	Payoff
ContribT ab
ContribInitialDiffTable 5.6: Correlation value among created attributesThe average of AUC of ROC analysis is used to measure the accuracy ofthe SVM classi002ers. To train the classi002ers and then test their accuracies,different attribute sets are used to create these classi002ers. The 002rst set isboth contribution and belief of players, the second is original attributesof players, the third attribute set is the derived attributes above, and thelast attribute set contains all available attributes.The accuracy results of the SVM classi002er with different sets of attributesand different classes for players are shown in Table 5.7. It can be noticedthat the SVM classi002er for all proposed classes with different cost func-tions perform better than economists' labels for players in predicting thetest set except in the case of IQR cost function when original attributes areused. Moreover, the SVM classi002er is more accurate for all attribute sets1435.5. ANALYSING THE BEHA VIOUR OF PGG PLA YERSusing proposed classes with SD cost function. This result aligns with theprevious test results of the players' contribution behaviour compactnessin each time point as the SD cost function produced the most compactedbehaviours with minimum standard deviation.The results of the last two tests indicate that the proposed temporal clas-si002cation method with different cost functions can classify players betterthan the available method which means Hypothesis 4 holds true. Vari-ous cost functions and initial ranges for classi002cation rules provide more003exibility , so the best classi002er can be selected for the temporal items.We showed that, by combining human expertise and computer optimi-sation, we can create better classes than the domain speci002c classi002er, yetwith simple rules which can be understood by experts. Rule simplicityis a positive point in this classi002er as it allows experts to further adjusttheir initial rules to create better classes in a reiterated classi002cation. Sim-ple rules might be necessary in order to gain a better understanding foritems behaviour in the underlying complex temporal data.
AttributesEconomists'	Proposed Classes
labels	IQR	Complete	SD
Belief+Contrib	0.497	0.755	0.787	0.798Original	0.723	0.685	0.758	0.768Derived	0.650	0.824	0.832	0.861All	0.703	0.726	0.790	0.814
Table 5.7: Accuracy of SVM using different attribute sets to compare pro-posed classi002cation and existing labels5.5 Analysing the Behaviour of PGG PlayersAfter successfully testing and comparing the proposed classi002cation methodwith the existing method of classifying players of public goods game, we144CHAPTER 5. OPTIMIZING TEMPORAL RULE-BASEDCLASSIFICATIONwill use created classes through this method to further study players' be-haviour. In this section, we will conduct two more analyses. First, we willcompare both public goods game data sets players to determine the effectof the game's length on the players' behaviour. Second, we will use play-ers' classes as the reference of behaviour for measuring their behaviourchange over time.5.5.1 Players' Strategy in Different Lengths of the GameTo determine the effect that the duration of the game rounds may haveon the players' behaviour and to check the validity of Hypothesis 5, wecompare players' class membership from both public goods game datasets 05010 and 27 rounds051. If both data sets produce comparable class mem-berships, then the number of rounds may have no effect on the play-ers. Otherwise, players' behaviour may change due to the longer gamerounds.In this experiment, we will classify players of 27 rounds data set of publicgoods game and then compare the cardinality number of classes withplayers of 10 rounds game using Wilcoxon-test. We will compare theclass cardinality of the proposed classes of all three selected cost functions050IQR, Complete Distance and SD051. If the samples from the experimentsare considered to have the same population mean rank, then there mightbe no effect of the length of the game on the players' behaviour.Before starting the comparison, the initial rules of section 5.3.1 for 27rounds of the public goods game are optimised using the same bruteforce method as the 10 rounds game. The results of the best values forthe ranges of the rules are shown in Table 5.8. The cardinality number ofeach class is given in Table 5.9. It can be noticed that the SD cost func-tion creates imbalanced classes. This means that, despite the best resultswhich are produced by SD in the 10 rounds of the public goods game data1455.5. ANALYSING THE BEHA VIOUR OF PGG PLA YERSset, it is speci002c to that particular data. The SD result indicates that ourinitial prediction about the internal classi002cation indices was accurate asthey may produce imbalanced and empty classes. However, as SD costfunction proved its ability to perform well in speci002c situations, they can,therefore, be used for speci002c data sets if they can 002t them.
Contribution
BeliefjZeroj
FR	WC	NC	FR	WC	NC	FR	WC
IQR	1	3	3	2	4	2	20	15Complete	1	1	3	3	4	2	24	17SD	1	4	6	4	9	2	20	20
Table 5.8: The attributes' best values for the ranges of the initial classi002-cation rules of 27 rounds of the public goods game data set using selectedcost functions.We used each classes' percentage for comparison purposes between twodifferent data sets as they do not contain the same number of players.The p-value of Wilcoxon-test equals 0.4942, which suggests that the nullhypothesis is true and the two samples have the same population meanrand. This might be an indication that the duration of the game doesnot affect the players' strategy . Moreover this result is aligned with our002ndings in chapter four that the behaviour of the players in both datasets are consistent.5.5.2 New Players Classes' as Reference of BehaviourAfter players were classi002ed according to their temporal attributes whichre003ect their contribution behaviour, we can use the new players' classesas a reference of behaviour to check the validity of Hypothesis 3. In chap-ter four, we examined two different reference of rehaviors; the 002rst time146CHAPTER 5. OPTIMIZING TEMPORAL RULE-BASEDCLASSIFICATION
Cost Function	Fr	Wc	Nc	Sc
IQR	48	29	31	20Complete	67	29	14	18SD	63	1	61	3
Table 5.9: Number of players in each class 050Cardinality number of classes051in 10 rounds of the public goods game data set using different cost func-tions.point as reference of rehavior and the previous time point. In this sec-tion, we will continue with the last proposed reference of rehavior, whichis players' universal behaviour during the game. As the proposed clas-si002cation uses aggregations of temporal attributes to create classi002cationrules and then optimises them through each time point of the temporaldata, it is, therefore, suitable to be used as a general 050universal051 referenceof rehavior for players.As shown in Figures 5.7 and 5.8, there are signi002cant differences betweenplayers' classes and the their temporal behaviour. This difference canbe seen with the low value of the behavioural change measures acrossall clusterings and all different external cluster validity indices 050less than0.6051. This indicates that the players do not always employ the same strat-egy . Instead, they try and explore other strategies which contribute totheir learning process to different strategy results. However, the regres-sion of the behavioural change for all cases is small 050near zero051, which in-dicates the difference is stable throughout all time points. This is anotherindication that, despite their temporary strategy change, these changesdo not affect their general behaviour when playing.Despite the sensitivity difference between external cluster validity in-dices, all the results of different clusterings and external cluster validityindices are similar to regression slope being equal to zero. This might bean indication that using items' overall general behaviour in the temporal1475.5. ANALYSING THE BEHA VIOUR OF PGG PLA YERS
050a051 K226means Clustering
050b051 PAM Clustering
050c051 C226means Clustering
050d051 Hierarchical ClusteringFigure 5.7: Results of various clustering methods using proposed classesas reference of rehavior to calculate the amount of changes which happento the groups of items in consequent time points in the test dataset. Theamount of change is measured by using different external cluster validityindices and AUC of ROC.attributes can create more stable predictions than other two reference ofrehaviors on the items' behavioural change. However, each reference ofrehavior can be useful for certain situations. This means that Hypothesis3 holds true. Using the 002rst time point as the reference of behaviour willdemonstrate how items are deviating from their initial behaviour. Usingthe previous time point shows the stability of the items during differentstages of the temporal data. Using players' temporal classes as referenceof rehavior demonstrates items behavioural variability in various stagesrelated to their overall behaviour across all time points.148CHAPTER 5. OPTIMIZING TEMPORAL RULE-BASEDCLASSIFICATION
050a051 K226means Clustering
050b051 PAM Clustering
050c051 C226means Clustering
050d051 Hierarchical ClusteringFigure 5.8: Results of various clustering methods using proposed classesas reference of rehavior to calculate the amount of changes which happento the groups of items in consequent time points in the test dataset. Theamount of change is measured by using different external cluster validityindices and AUC of ROC.5.6 SummaryIn this chapter, we answered the three questions posed in chapter one.The 002rst question concerned the ability of classifying players of publicgoods game to use their temporal attributes during the game rounds.The other two questions were dependent on the 002rst question as tem-poral classes of the players were required to answer the remaining twoquestions regarding players' behaviour in the public goods game.To answer the 002rst question, we proposed a rule-based temporal classi002-cation method as mentioned in chapter three section 3.4. The proposed1495.6. SUMMARYclassi002cation is based on optimising rules which are provided by humanexperts. For the sake of simplicity , these rules are generated throughaggregating the temporal attributes so that domain experts can handleand understand them The provided rules contain ranges of values whichhave to be optimised to create the best compacted classes of items at eachtime point.To optimise the initial rules we used brute force to enumerate all possibil-ities and 002nd the best classi002er. The best classi002er is determined througha cost function which assures the most compacted classes in each timepoint. We tested multiple compactness measuresCMin the optimisationprocess including statistical, Euclidean distance and internal clusteringvalidity indices . The best CM were IQR and the complete Euclidean dis-tance between items. As we anticipated, all the Internal cluster validityindices except for SD in one situation 050with 10 rounds of the public goodsgame051 were proven to create imbalanced large classes, as their cost func-tion could not adjust the size of the groups. This was not a concern forthe original use of these measures.To check the validity of Hypothesis 4, we classi002ed the players of the tenrounds of public goods game data set with the new proposed classes.Then, we compared the new classes of players with the labels providedby economists in two ways. First, by comparing the contribution be-haviour of the players in each class and label for all ten rounds. Weused IQR and standard deviation 'stdev' to measure the spread of play-ers contribution in the classes in each time point. For all cases, our pro-posed classes created more similar behaviours among players of the sameclass than the economists' labels. Second, we trained SVM classi002er us-ing our classes and economists' labels with 75% of the players and testedthem to determine the rest of the players in each time point. The resultsshowed that the SVM classi002ers, which are trained with the proposedclasses, could detect the classes of the rest of players with a higher level150CHAPTER 5. OPTIMIZING TEMPORAL RULE-BASEDCLASSIFICATIONof accuracy than the classi002er which is trained and tested using existingplayers' labels. The results of both tests indicate that the proposed clas-si002cation method can produce better classes for players of PGG than theavailable method.To answer the second question, which concerns players behaviour in dif-ferent length of public goods game, and to validate Hypothesis 5 whichsuggests that there is no effect of the games' duration on players be-haviour, we classi002ed 27 rounds of the public goods games data set andcompared the percentage of players in each class with the 10 rounds ofpublic goods game. We determined that there is no signi002cant differ-ence between the two samples which proves the validity of Hypothesis5. Moreover, a closer examination for the optimised rules shows thatthese rules are not identical. However, they are close to each other andsimilar especially if we rule out the differences which are mainly causedby the duration of the game, such as the number of zero contributions.To answer the last question about the overall behaviour change of theplayers, we used the produced players' classes of both data sets as refer-ence of rehaviors. The results for both data sets indicate that the players'change over time is stable with near zero regression for all different mea-sures using different clustering methods. This proves that Hypothesis 3holds true.In the next chapter, we will classify a larger data set of stock market usingour proposed classi002cation method. To reduce the time required for theoptimisation process, we will use a heuristic method called differentialevolution.1515.6. SUMMARY152Chapter 6T esting the Stability of the StockMarket6.1 IntroductionThis chapter answerers the question of capability of being able to gener-alise the use of the temporal rule-based classi002cation which is proposedto classify players of the public goods game. In this chapter, we willcheck the validity of Hypothesis 6 regarding stock market predictabilityby classifying them into different stability classes. To be able to classify alarger data than public goods game, a heuristic algorithm has to be usedfor optimising the initial rules instead of enumerating all possible rulecombinations.In this chapter we will validate Hypothesis 6 by classifying stock mar-ket data set for two consecutive quarters of the 002nancial year and thencomparing an individual stock's stability classes. The hypothesis indi-cates that to be able to predict the stock market, at least half of the stocksshould follow the same stability class. We also use the proposed methodin chapter four for measuring changes over time to determine the stabil-ity of the stock markets using different reference of behaviours.1536.2. BACKGROUNDThe presented stock market data set of S&P 500 in chapter three is classi-002ed to validate Hypothesis 6. The stocks are classi002ed into four differentstability classes: very stable; smooth stable; rough stable; and unstable.Pro002les for each stock are created to construct the initial rules and deter-mine the [min, max] range of the rule values.For optimisation process, we use the differential evolution algorithm,which is developed by Storn et al. [93], as a heuristic function to improvethe speed of the process. To check the ef002ciency of the differential evolu-tionary algorithm, we compare the brute force results of the public goodsgames data sets with the heuristic results. Then, the classi002cation resultsof the proposed method for the public goods games will be comparedwith common classi002cation algorithms like SVM.The stability test for the stock market might be controversial. However,we have to point out that the concluded result in this chapter is not themain point of this study . Rather, the classi002cation tests are mainly aboutchecking the ability of the proposed classi002cation method to classify var-ious temporal data sets. However, the results indicate that there are sig-ni002cant difference in the stability classes between the 002rst and secondquarters of the 002nancial year for S&P 500stocks. It can, therefore, be con-cluded that according to the available data and the proposed method,stock market prices cannot be predicted by entirely relying on their his-torical data.6.2 Background6.2.1 Stock Market PredictabilityMany algorithms and methods have been developed to predict stockmarket prices [157]. However, there is a debate among economists on theaccuracy of these predictions. The 002rst group emphasises the essential154CHAPTER 6. TESTING THE STABILITY OF THE STOCK MARKETrandomness of the stock market, thus precluding any possibility of fu-ture price predictions based on historical values [83]. The second groupclaims market prices have an element of predictability [84]. In this chap-ter, we will present a method of how to determine the predictability ofthe stock market by classifying two consecutive quarters of a 002nancialyear and then counting the number of stocks which have not changed. Ifas Hypothesis 6 states that if more than half of the stocks' stability classeschange between these two quarters, then the stock market might be ran-dom and, therefore, not possible to predict their prices.6.2.2 T emporal Data MiningClassi002cation is a type of supervised machine learning concerned withpredicting one of the prede002ned 002nite classes for items subject to clas-si002cation [2]. Temporal and sequence classi002cation is an automatic sys-tem which assigns one of the prede002ned classes to the time series or se-quence input [50]. Many temporal classi002cations have been introducedthat reuse traditional classi002cation algorithms using criteria and mea-surements crafted for temporal data.Many temporal supervised and unsupervised algorithms use dynamictime warping 050DTW051 [62] to align between two sequences or time seriesand 002nd the distance between them. This method was originally used inspeech recognition to 002nd human speech patterns [63]. For complex timeseries, Euclidean distance is sensitive to the time 003uctuation; so DTW ismore preferred for use [65]. DTW can be used with KNN classi002cationto determine distance between items in temporal data. It can also beused with clustering algorithms such as hierarchical clustering to createconfusion matrix, meaning the distances between any two time serieswill be calculated according to their best match. In this chapter we usethis method to con002rm the results of the classi002cation stability betweentwo quarters of a 002nancial year.1556.3. APPROACHDouzal-Chouakria et al. [68] used classi002cation trees to classify time se-ries data by introducing new splits for the tree nodes using time seriesproximities relying on adaptive metrics considering behaviours and val-ues. Distance-based K-nearest neighbours classi002cation method 050KNN051is used with temporal and sequential data with Euclidean distance mea-sure [64]. Other methods use Support V ector Machine 050SVM051 as a tem-poral data classi002er using different kernels [69]. SVM classi002es items byseparating each class using optimal hyperplanes between them [2].Model-based classi002ers can also be used for temporal and sequential clas-si002cations such as Naive Bayes sequence classi002er [70] and Hidden MarkovModel [71]. In the training step, the parameters of the model are createdand trained depending on some assumptions, and a set of parametersdescribing probability distributions. In the classi002cation step, a new se-quence is assigned to the class with the best possible similarity [72].6.3 ApproachTo classify stock market data sets to test their stability , we use the pro-posed method for temporal rule-based classi002cation. To classify the stockmarket data set, we follow the two steps as proposed in chapter threeand tested in chapter 002ve for creating initial rules via pro002les of the dataitems. Then, the initial rules are optimised to obtain a crisp classi002cationrule. However, due to the larger size of the data 050more items and timepoints051, using brute force to optimise the initial becomes extremely timeconsuming, so we will use the heuristic function of differential evolutionfor the optimisation process. To ensure that the results of differential evo-lution are comparable to the brute force, we will compare classi002cationresults of both methods. Moreover, to test the ability of the proposedclassi002cation to operate on more general areas other than public goodsgames we will compare it with more 002rmly-established methods of clas-156CHAPTER 6. TESTING THE STABILITY OF THE STOCK MARKETsi002cation such as SVM and ctree.The stock market data set consists of two quarters of the year; we willuse the 002rst quarter to create the optimised rules for classi002cation andthen use these rules to classify both quarters. Hypothesis 6 may provevalid if more than half of the items in the data set are classi002ed as thesame class. Furthermore, we will use the proposed method for measur-ing changes over time to study the behaviour of the stocks with differentreference points, including the temporal classi002cation of the items for the002rst quarter of the year.6.3.1 Producing Initial Rules for ClassesTo create the initial rules for the classes, we aid human experts with vi-sual pro002les and create required aggregated attributes for the rules. Theprovided initial rules by the experts might contain ranges of values whichhave to be optimised at a later stage.Data ManipulationThe main objective of the data manipulation is to create aggregated at-tributes for the stock data set to create the initial rules for classi002cation.As mentioned in chapter 002ve section 5.3.1, there are multiple possibilitiesof aggregating temporal attributes such as total, mean, median, mode,count, minimum, maximum and standard deviation. The original at-tributes of the stock market as listed in chapter three are:017Date: The date of the stock price. Each date can be considered as atime point and converted to a sequence of integer numbers.017Symbol: The standard symbol which identi002es companies' stocks.017Open: The price of the stock at the opening time for that date.1576.3. APPROACH017High: The highest price reached by the stock on that date.017Low: The lowest price the stock hit on that date.017Close: The price of the stock at the close of the stock market on thatdate.017V olume: The number of shares which are traded on that date.The stock market data set is similar to the public goods games data setby having discrete time points for each entry 050working days for the stockmarket and rounds for public goods games051. Therefore, there is no needto use any windowing technique to slice data into separate, distinct timepoints. Contrary to the public goods game, the values of the stock pricesmight be decimal and have different minimum and maximum values foreach stock. Consequently , the values are standardised and coerced tointegers. For classifying the stock market data set, we focus on the closeattribute to create three attributes which are:017StdevClose: Standard deviation of the closing price for each stock.017CloseDiff: The difference of the closing price between any two con-secutive days. This attribute is not aggregated as it changes withtime. It will, however, be used to create the next attribute.017StdevCloseDiff: The standard deviation for thecloseDiff.The other attributes might be effective for predicting and analysing thenext day or short range price [158]. However, we assume that they donot have the same impact for the quarter based analysis as in our case.Moreover, there are multiple studies which rely on the closing price suchas [159]. For these reasons, our focus is only on the closing price forstability classi002cation.158CHAPTER 6. TESTING THE STABILITY OF THE STOCK MARKETStocks Pro002lingThe aim of pro002ling is to aid human experts in 002nding the initial classi-002cation rules with a range of overlapping areas separating classes fromeach other in each attribute. A pro002le for each stock's 002rst quarter data iscreated. The pro002le consists of two main parts. The left part representsthe stock's closing price, and its standard deviation and regression line.The right plot represents the stock's price difference between each con-secutive days with its standard deviation multiplied by 10. We multiplythe standard deviation by 10 to enable more accuracy for its rounded in-teger. Three samples of the pro002les are shown in Figure 6.1. From theprovided samples, it can be noticed that a rapidly-changing stock mar-ket price might create a fairly stable difference in prices between any twodays. This might be due to the consistency of the change itself, soStde-vCloseDiffmight shape the difference between the rough and smoothchanges in the prices.Driving Classes from Stock's Pro002lesTo create classes for stocks, we used the visual pro002les of the stocks tohelp experts to decide the 002nal number of classes and the limits of eachclass. The very obvious classes are dividing the stocks into stable andunstable parts. However, after carefully examining classes, we can deter-mine that the stable class can be further split into two classes: the verystable; and the rest. It is also true for the unstable class to be divided intotwo parts, the unstable and slightly stable classes. So, the 002nal number ofclasses become four. They are:017V ery stable:the price of this class of stocks experiences a relativelysmall change over time.017Smooth stable:the price 003uctuation of this class of stocks is largerthan very stable class, with a small difference in price between two1596.3. APPROACH
Figure 6.1: Three samples of stocks's pro002les of S&P 500 data set.consecutive days on average.017Rough stable:the price of this class of stocks is larger than that ofthe very stable class, with a large difference in price between twoconsecutive days on average.017Unstable:the price of this class of stocks experiences relativelylarge changes over time.While other class numbers might be possible, classifying stock marketinto four classes, however, gives it an advantage of becoming comparablewith public goods games data set as it has also four classes.The initial rules for classi002cation were produced by human experts, withranges in the forms of [min, max] values. Both aggregated attributes160CHAPTER 6. TESTING THE STABILITY OF THE STOCK MARKETgenerated in section 6.3 are used to express these rules. The rules aredesigned and prioritised so that the obvious stocks will be classi002ed 002rst050unstable and very stable051, then rough stable stocks are labelled; 002nally ,any remaining stock will be classi002ed as smooth stable. The class ruleswith their priority order are shown in Table 6.1. These rules will be op-timised, and a single value will be chosen for each range. These are asdescribed in the next subsection.
ClassRule
V ery StablestdevClose>[1100, 1300] && stdevCloseDiff>[500, 750]UnstablestdevClose<[1600, 2000] && stdevCloseDiff<[650, 1000]Rouged StablestdevCloseDiff<[550, 800]Smooth StableAll remaining instance after the above 002lters 050Others051
Table 6.1: Initial classi002cation rules of stock market data set6.3.2 Optimising Rules Using HeuristicDifferential Evolution 050DE051 is a heuristic search algorithm introduced byStorn et al. [93], who described it as simple and ef002cient. DifferentialEvolution is a type of evolutionary algorithm that uses crossover andmutation while producing the next generation. This happens accordingto the nature of DNA and derives natural evolution from creating solu-tions 050species051 that are optimised for the environment. This algorithmhas proved to be successful, and it has been used in many different ar-eas [160]. In this study , we used Differential Evolution to optimise pro-vided rules by a human classi002er. The optimisation focuses on minimis-ing the distance between items within classes according to their temporalattributes. Please see chapter three for more details about DE.1616.4. TESTING WITH PUBLIC GOODS GAME DATA SETS6.4 T esting With Public Goods Game Data SetsIn this section, we will compare the results of classifying public goodsgames using brute force and differential evolution according to their speedand similarity . Then, we compare the proposed method with well-knownclassi002cation methods such as ctree, svm and c50. The comparison will berun on the 10 rounds of public goods games data set as it contains moreplayers than the 27 rounds data set, as the number of items is more im-portant for the training and testing of classi002ers than longer time points.These two comparisons are necessary to demonstrate the ability of theproposed classi002cation method to function in more of a general scopethan only be restricted to the public goods games data sets with an ac-ceptable ef002ciency of speed and accuracy .6.4.1 Comparing Brute Force and Heuristic ResultsThe main advantage of using heuristic functions to solve the problem ofoptimisation is to reduce the required search time to 002nd an optimumsolution. However, it is important to check the heuristic function resultsto ensure that they are not radically different from the brute force results.To accomplish the comparison, we use the differential evolution package[109] of R language. The maximum iteration is set on 200 iterations with50 chromosomes in each generation. By default, the result of each itera-tion is real numbers. It can, however, be changed to produce only integernumbers. The speed and optimisation result of the algorithm is mainlydependent on the maximum-allowed number of iterations. For our tests,the average rounded speed of the results were 7 minutes compared to 48for the brute force which makes it nearly seven times faster.Table 6.2 shows the optimum classi002cation results of both brute force anddifferential evolution for different cost functions. The four player classes162CHAPTER 6. TESTING THE STABILITY OF THE STOCK MARKETare Free Rider FR, Weak Contributor WC, Normal Contributor NC andStrong Contributor SC. The optimum classi002cation rules generated by thedifferent methods are mostly similar with two exceptions:017The values for the rules of belief attribute for normal contributorsare different for all cost functions.017There are many differences between brute force generated rules anddifferential evolution ones for centroid distance cost function.Despite these differences, Table 6.3 shows that there is no difference be-tween classi002cation results of both methods of optimisation except for thetest where centroid distance is used as a cost function. From these twotables 050Table 6.2 and Table 6.3051 we can arrive at three conclusions:1636.4. TESTING WITH PUBLIC GOODS GAME DATA SETS
Brute Force	Heuristics 050DE051
Contribution
BeliefjZeroj
Contribution
BeliefjZeroj
FR	WC	NC	FR	WC	NC	FR	WC	FR	WC	NC	FR	WC	NC	FR	WC
Statistics
IQR	1	3	5	2	4	2	6	5	1	3	5	2	4	5	6	5Stdev	1	1	6	2	4	2	9	6	1	1	6	2	9	9	9	6
Euclidean
Complete	1	3	6	2	4	2	7	5	1	3	6	2	4	9	7	5Centroid	1	2	2	2	4	2	6	5	1	3	2	9	6	7	8	5
ICVI
Dunn	1	3	2	7	7	2	6	6	1	3	2	8	7	6	6	6DB	1	4	2	2	5	2	5	6	1	4	2	2	5	8	5	6SD	1	4	6	7	4	2	9	6	1	4	6	8	4	7	9	6S
Dbw	1	4	4	2	4	2	8	6	1	4	4	2	4	6	8	6
Table 6.2: Comparing of brute force and differential evolution results for optimising attributes' values for the ranges of the initialclassi002cation rules of 10 rounds public goods games data set for different cost functions.
164CHAPTER 6. TESTING THE STABILITY OF THE STOCK MARKET017The rule of the belief attribute for Normal Contributor class mightbe more 003exible than accepting only one value, or it is irrelevant,and the rule can be further simpli002ed.017For the centroid-distance cost function, the heuristic failed to reachthe most optimum value in 200 iterations as it did not generate theexact results as the brute force function. However, the result is notvery far from the most optimum value as AUC measure of ROCanalysis scored 0.94 which can be considered as an acceptable re-sult.017From the above, we can conclude that the differential evolutionfunction can optimise the rules for the proposed classi002cation at afaster rate with exact or acceptable results. Hence, we can use thisheuristic method for future tests with larger data sets con002dent thatit will produce an acceptable optimisation result.
Brute force	Heuristic 050DE051Cost Function	Fr	Wc	Nc	Sc	Fr	Wc	Nc	Sc	AUC
Statistics
IQR	46	22	22	50	46	22	22	50	1Stdev	36	10	58	36	36	10	58	36	1
Euclidean
Complete	38	30	37	35	38	30	37	35	1Centroid	46	10	0	84	30	25	6	79	0.94
ICVI
Dunn	42	4	9	85	42	4	9	85	1DB	37	34	2	67	37	34	2	67	1SD	28	48	28	36	28	48	28	36	1S
Dbw	37	40	1	62	37	40	1	62	1
Table 6.3: Comparing class membership results of the brute force anddifferential evolution in 10 rounds of public goods game data set usingdifferent cost functions.1656.4. TESTING WITH PUBLIC GOODS GAME DATA SETS6.4.2 Comparing Results with Other Classi002cation Meth-odsIn this section, we will test the proposed temporal classi002cation method'sability to operate at a comparable ef002ciency 050i.e. classifying items cor-rectly051 with general and popular classi002cation algorithms. If we demon-strate the ability of the proposed classi002er to classify items as effectiveas other classi002cation algorithms, it might be an indication that the pro-posed algorithm can be used in more general areas rather than only berestricted to the public goods game data sets.There are many classi002cation methods which can operate on temporaldata in various ways [60]. However, we chose three classi002cation meth-ods to compare the proposed method with. The 002rst classi002cation methodis Support V ector MachineSVM, which is one of the most successfulclassi002cation algorithms [156]. Besides its success, SVM is a partitionbased classi002cation method which classi002es items through creating hy-perplanes between classes. This feature is similar to the initial rule con-struction of the proposed classi002cation. The second classi002cation methodis C5.0 which is an extension of C4.5 which is, in turn, an extension ofIterative Dichotomiser 3ID3[161]. This algorithm was selected as thebest algorithm of data mining and classi002cation by [18] for 2008 and eversince, its popularity and success has grown. This algorithm with all itsvariations is considered as a decision tree and rule-based classi002cationmethod [144] which makes it a perfect candidate for comparison withthe proposed classi002cation algorithm. The 002nal classi002cation algorithmis conditional inference treesctreewhich is considered a statistical deci-sion tree classi002er. This algorithm uses tree-structured regression modelsto classify items in the data set [162].These classi002cation methods were originally designed to work with none-temporal data sets. However, it is possible to use these classi002ers with166CHAPTER 6. TESTING THE STABILITY OF THE STOCK MARKETtemporal data sets by preprocessing the temporal data before buildingthe classi002cation model [163]. There are multiple methods of extractingfeatures from the temporal data in the preprocessing stage such as Singu-lar Value Decomposition, Discrete Fourier Transform, Discrete WaveletTransform and Piecewise Aggregate Approximation [164]. In this test,we will use Discrete Wavelet Transform which was introduced by Zhanget al. [165], due to its popularity and acceptance in many areas whichrequire temporal data mining [166]. Moreover, it is also possible to usethe plain temporal data of items directly for the tests by converting eachtime point into a separate feature 050attribute051 of the items. These attributesare created by transposing a single temporal attribute 050i.e. contribution051which means for the 10 rounds data set 10 attributes are used and 27 at-tributes are created for the 27 rounds of public goods game data set.One of the advantages of the proposed classi002cation method is its abil-ity to classify items from optimised rules provided by a human expert.However, this might create a challenge when we want to assess it in com-parison with other classi002cation methods especially when these methodsrequire pre-labelled data records to train their classi002er model.To be able to test the accuracy of these classi002cation methods, we 002rst usethe existing labels which are provided by the economists. Although theselabels are not based on the temporal data of the players, it might still offera valuable insight into how well these labels are related to their tempo-ral behaviour. The second types of labels are driven from the [min, max]attribute limits which are provided as initial rules by experts. Instead ofusing optimisation for [min, max] pairs, we use the rounded average ofeach pair 050i.e. the middle051 as it might represent the best guess if the ex-perts manually labelled the players. We use the average of the [min, max]spectrum because normal distribution is assumed for the players' contri-bution in the public goods games [167, 168]. Hence the natural dividingline between two classes might be in the middle of the spectrum.1676.4. TESTING WITH PUBLIC GOODS GAME DATA SETS
Classi002cation	Labels	Classes
MethodTemporalattributesDWTattributesTemporalattributesDWTattributes
SVM	0.602	0.504	0.877	0.797Ctree	0.704	0.583	0.841	0.848C5.0	0.735	0.654	0.858	0.892
Proposed	IQR	Complet Dist	SD0.959	0.965	0.972
Table 6.4: AUC of ROC analysis for different classes and the proposedclassi002cation method of 10 rounds of public goods games.We use 10 fold cross validation [169] to create 10 different classi002er mod-els for each classi002cation algorithm by using 90% of the players' data.Then we tested the models with the remaining 10% of the data to detectthe accuracy of the classi002ers. These 05090/10051 portions of the players arerandomly selected for each fold, and the 10% of the test players are al-ways different from one fold to another. We use this method as the num-ber of players for both data sets are limited. In this way , we can repeatthe test multiple times using the same data sets.For the proposed classi002cation method, we used the optimised rules whichare generated by using all the data set without splitting them into train-ing/test portions. These classes are used as the reference for compar-ing the accuracy of the classi002ers, which are optimised by using only thetraining portion of the data, 90% to classify the remaining 10%. For thesecomparisons, we selected three cost functions: IQR, Complete Distanceand SD.The AUC of the ROC analysis of all classi002cation methods for both datasets are shown in Table 6.4 and Table 6.5. The AUC results of classi002ca-tion models which are created based on the economists' labels score verylow, especially with SVM and ctree. These results came as no surprise be-168CHAPTER 6. TESTING THE STABILITY OF THE STOCK MARKET
Classi002cation	Labels	Classes
MethodTemporalattributesDWTattributesTemporalattributesDWTattributes
SVM	0.658	0.495	0.819	0.725Ctree	0.665	0.5	0.781	0.864C5.0	0.597	0.671	0.852	0.818
Proposed	IQR	Complet Dist	SD0.957	0.921	0.914
Table 6.5: AUC of ROC analysis for different classes and the proposedclassi002cation method of 27 rounds of public goods games.cause the labels are not intended to represent the temporal behaviour ofthe players. The importance of these results is to present yet further evi-dence that the players change their strategy during the game and do notfollowing the static contribution table. This creates the need to directlyclassify players using their temporal contribution attributes.We also used both data sets to create classi002er models for the generatedclasses by using the experts' initial rules. It can be noticed that the av-erage of AUC of the 10 fold cross-validation for each classi002cation algo-rithm 050SVM, ctree and C5.0051 is less than 0500.1051. These results might bean indication that the different data sets 050i.e. transposed and wavelettransformed for the temporal attribute051 do not affect the accuracy of theclassi002er signi002cantly for the public goods games data sets.The results from the proposed classi002cation method using different costfunctions produced a higher average of AUCs than the traditional clas-si002cation methods. This result came as no surprise as these classi002ca-tion algorithms used classes which are produced by the average of theprovided [min, max] while the proposed classi002cation used the optimumvalue for each class limits. This means that the available classi002ers are notnecessarily performing worse than the proposed classi002cation method.1696.5. TESTING STOCK MARKET STABILITYHowever, it might be an indication that optimising initial ranges for classrules provided by experts can perform better than when using crisp rulesdirectly for classes.The results indicate that the proposed method can perform better thanavailable common classi002cation algorithms without sacri002cing the un-derstandability of the rules. As these algorithms might create complexmodels possibly incomprehensible for humans especially for temporaldata sets, data transformation from time domain to frequency domainmay be necessary . The clarity of the rules might lead to better under-standing of the underlying data. This understanding might enable ex-perts to provide even more accurate initial rules through multiple iter-ations of rule generation and optimisation as described in chapter 002ve.On the other hand for complex data sets with the availability of well-established training data sets and accurate classes for the items 050for ex-ample, classifying cancer cases using protein biomarkers [170]051, it mightbe dif002cult for the experts to construct an ef002cient initial classi002er by fol-lowing the effects of hundreds of proteins.6.5 T esting Stock Market StabilityTo test the stability of the stock market and check the validity of Hy-pothesis 6, we use the introduced data set in chapter three of Standard& Poor's 500 050S&P 500051 stock market. The whole data set contains stockrecords between 1-1-2015 to 1-7-2017. Two kinds of experiments are runon the data: In the 002rst experiment, we measure stock changes over timefor the 002rst quarter using different references of behaviour to obtain anunderstanding of how stocks' stability changes over time. In the secondexperiment, we split the data into two parts; each part represents onequarter of the 002nancial year. We used the 002rst part to optimise a classi002erbased on the provided initial rules by the experts, and then we used this170CHAPTER 6. TESTING THE STABILITY OF THE STOCK MARKETclassi002er to classify both quarters of the 002scal year to compare the classmembership of each stock between these quarters and test the validity ofHypothesis 6.6.5.1 Analysing Stocks' BehaviourTo gain a better understanding of the presented stock market data set inchapter three and analyse the behaviour of the stocks between differenttime points, we measure changes over time for the entire stock marketdata using the proposed method in chapter three. Three different refer-ences of behaviour are used in the experiments: the 002rst time point, theprevious time point and the stocks' overall behaviour in the data set.Each reference of behaviour can highlight different aspects of the stocks.By using the 002rst time point as the reference of behaviour, we might beable to determine the level accuracy in predicting any future time pointof the stock market by using the last available time point. Using the pre-vious time point as the reference of behaviour, we can determine the sta-bility of the stocks for the next day and hence, the ability to predict thestock market only for the next day . Using stocks' stability classes as thereference of behaviour, we can determine the overall stability of the stockmarket and its predictability in general.Using the 002rst and previous time points as references of behaviour arestraight forward as these time points can be clustered alongside withother time points using one of the selected clustering algorithms 050k226means,c226means, PAM and hierarchical051. They can then be compared with othertime points using external cluster validity indices as has been imple-mented in chapter four. However, to use the general behaviour of thestocks in the overall time points, they have to be classi002ed according totheir stability using their temporal attributes 050closing price051. To classifystocks in the data sets, we use the proposed rule-based temporal clas-1716.5. TESTING STOCK MARKET STABILITYsi002cation method. As explained beforehand, the proposed classi002cationconsists of two steps: initial rule generation and rule optimisation. Weoptimise the initial rules which are provided in section 6.3.1, Table 6.1, byusing Differential Evolution algorithm to accelerate the process of ruleoptimisation. For this experiment we, used IQR as the cost function. The002nal rules are shown in Table 6.6 after optimisation.
ClassRule
V ery StablestdevClose>1246 && stdevCloseDiff>584UnstablestdevClose<1996 && stdevCloseDiff<797Rouged StablestdevCloseDiff<759Smooth StableAll remains
Table 6.6: Optimised classi002cation rules of stock market data set, usingIQR as cost function for optimisation process.Figure 6.2 shows the results of the change in the stocks over time com-pared with the 002rst time point. The stocks are clustered in each time pointusing different clustering algorithms 050k226means, c226means, PAM, hierar-chical051 and then compared with the 002rst time point by various externalcluster validity criteria 050Rand, Jaccard, FM, VI and AUC051. It can be no-ticed that the results for all clustering algorithms show a rapid changeof stocks' clusters between the 002rst time point and other consecutivetime points until it nearly reaches the 20th time point. It then starts tostraighten with some minor changes. This is an indication that furtherthe distance from the current time point will produce less accurate pre-dictions as the changes over time become more signi002cant until the sat-uration point is reached near the 20th time point. At that point 05020th051,changes in the stock market cancel each other out. We can, therefore, seethis stability in much lower rates of similarity .Figure 6.3 shows the results of the change between in stocks every cur-172CHAPTER 6. TESTING THE STABILITY OF THE STOCK MARKET
050a051 K226means Clustering
050b051 PAM Clustering
050c051 C226means Clustering
050d051 Hierarchical ClusteringFigure 6.2: Using the 002rst time point as reference of behaviour.rent and next time points. The similarity between every consequent timepoint is high as indicated by the high regression line for the AUC mea-sure. It can be noticed that, despite the high regression line, there is asharp transition between any time point. This might be an indicationthat the overall stability classes do not change signi002cantly between anytwo time points. However, individual stocks might change their classesmore rapidly . This means that the overall status of the stock market canbe predictable for the next day . However, individual stocks might notfollow the trend of their class.Figure 6.3 shows the results of the change in stocks over time compared1736.5. TESTING STOCK MARKET STABILITY
050a051 K226means Clustering
050b051 PAM Clustering
050c051 C226means Clustering
050d051 Hierarchical ClusteringFigure 6.3: Using the previous time point as the reference of behaviour.with their overall stability classes. From the results, we can determinethat there is a consistent difference between stocks' classes and their tem-poral behaviour. However, the difference is rather large. For example, theregression line for AUC is near 0.5 for all clustering methods, although itis 003at. That is, its slope is close to zero. This might be an indication thatit is dif002cult to predict stocks by only using their overall past behaviour.The three results achieved by comparing stock market behaviour by us-ing different reference of behaviours lead us to conclude that it might bepossible to predict stock market prices for the next day reasonably accu-rately . However, the accuracy of the prediction is rapidly become lower174CHAPTER 6. TESTING THE STABILITY OF THE STOCK MARKET
050a051 K226means Clustering
050b051 PAM Clustering
050c051 C226means Clustering
050d051 Hierarchical ClusteringFigure 6.4: Using the proposed classes as reference of behaviour.for each other next day until it gets to a point where it might be equiv-alent to a random guess. This 002nding is aligned with the random walkhypothesis in stock market predictability which is supported by a groupof economists [83]. This hypothesis states that the further walking awayfrom a known stock price there is, the more inaccurate the prediction willbecome.1756.5. TESTING STOCK MARKET STABILITY6.5.2 Comparing Stocks' Class MembershipsTo verify Hypothesis 6 and further check the ability to predict stock priceby solely using historical prices of the stocks, we conduct an experi-ment to comparing stocks' membership to one of the proposed stabilityclasses 050very-stable VS, smooth-stable SS, rough-stable RS, and unstableUS051 in two consequent quarters of the 002scal year. If more than 50% ofthe stocks are classi002ed as the same class for both quarters, Hypothesisrefhypo:pridictabilityOfStocks is valid. This then might be an indicationthat the 002rst quarter's price can be used to predict the second quarter. Inthis experiment, we only test the ability of any prediction system to pre-dict the market price for the next quarter, and not for the price the nextday . Moreover, the test is solely concerned about predictors which useprevious price data for their predictions, and not any other factors [171].The 002rst quarter's closing price of stocks is used to optimise the initialrules which are derived from pro002les of stocks in section 6.3.1. Differ-ent cost functions are used in the optimisation process 050Stdev , IQR, andComplete Distance051 so that various classi002ers are produced. The opti-mised classi002ers are used to classify both quarters separately . Then theclass membership of stocks in both quarters is compared to calculate thepercentage of the stocks with identical classes in both quarters. Table 6.7shows the percentage with the number of stocks in each class in bothquarters. The three results indicate that the majority of the stocks do notnecessarily follow the same stability class in both quarters.To compare the results of the stock classi002cation in both quarters andcon002rm the results, we used various clustering algorithms to cluster eachquarter separately . We then calculated the percentage of the stocks in thesame cluster in both 002scal years' quarters. However, the percentage ofagreement between clusters might not be suf002cient for clustering meth-ods due to the risk of instability of cluster labels. So, two external clustervalidity indices 050Jaccard index and Folkes-Mallows FM-index051 are also176CHAPTER 6. TESTING THE STABILITY OF THE STOCK MARKET
CompactnessMeasuresQuartersItems in Classes/Clusters	QuartersAgreement
VS	US	RS	SS
StdevQt1	42	172	99	18434%Qt2	112	59	79	247
IQRQt1	87	245	30	13537%Qt2	197 119	19	162
Complete DistQt1	120 123 128	12634%Qt2	242	43	83	129
Table 6.7: Number of stocks in each class and percentage of compatibleresults between two quarters of the 002scal year using different cost func-tionsused to measure the similarities between clusterings of the two quartersof the 002scal year. Three methods of clustering are used for this experi-ment and they are:017K226means for aggregated attributes: In this method, we used k226means with two aggregated attributes which are derived from 'close'attribute. The attributes are 'StdevClose' which is the standard de-viation of the close attribute for each item and StdevCloseDiff whichis the standard deviation of closinf price differences every two days.Please refer to section 6.3for more information.017K226means for temporal attributes: In this method, we used the trans-posed close attribute with k226means clustering. By transposing theclose attribute, each time point of the temporal data become a sep-arate attribute and contributes in the computation of choosing theoptimum cluster for the stocks.017Hierarchical for temporal attributes: In this method, we use hier-archical clustering with the 'close' temporal attribute directly byusing Dynamic Time Wrapping DTW [62] distance. This methodis more advantageous then Euclidean distance and for time series1776.5. TESTING STOCK MARKET STABILITYdata sets, it is less subject to time distortion.The results in Table 6.8 shows that the stocks in similar clusters for bothquarters of the 002nancial year are less than 50%. This can be also seenin the results of the Jaccard and FM indices. It can be noticed that thehierarchical clustering using dynamic time wrapping is noticeably high05047%051. This may be the effect of the DTW. However, this high percentge of similarity result between two clusters might not be a representative002gure as the dynamic time wrapping method shifts the time of items to002nd the smallest possible distance between two stocks' prices. However,this shift distorts the actual time of price change, which is crucial in thestock market data set.
Clustering Methods	Cl1 Cl2 Cl3 Cl4 Jaccard	FM	%
k226meansAggregatedQt1	89	81	176 1510.17	0.30 27Qt2 175	34	182 106
k226meansTemporalQt1 141 155	83	1180.28	0.43 16Qt2	53	138 164 142
HierarchicalTemporal050DTW051Qt1 103 134 191	690.31	0.48 47Qt2 102 251 113	31
Table 6.8: Number of stocks in each cluster and the percentage of com-patible results between two quarters using different clustering methods.The results of both classi002cation and clustering methods show the stabil-ity of stock price between the 002rst and second quarters of the 002scal yearare less than 50. This might suggest different stability behaviour for eachstock price. This is an indication that Hypothesis 6 has not been proven,which means it might not be possible to use one quarter's stock pricesto predict the next quarter's prices. This conclusion does not includepredicting the next day prices either using other factors to enhance theaccuracy of the prediction.178CHAPTER 6. TESTING THE STABILITY OF THE STOCK MARKET6.6 SummaryIn this chapter, we answered the question of stock market predictabilityonly using prices of stocks by verifying the validity of Hypothesis 6. Ac-cording to this hypothesis, 50% of stock market prices do follow the sameclassi002cation of their stability . To validate this hypothesis, we had to clas-sify stocks according to their stability . However, the harvested data forthis purpose have no pre-classi002ed labels according to their stability .To classify the stock market data set, we used the proposed rule-basedtemporal classi002cation. However, this method had only been used toclassify public goods games data set beforehand. To be able to use thisclassi002cation method, we had to adjust its speed so that it can classifylarger data sets, that is, more items in the data set and longer time points.We replaced the brute force optimisation with differential evolution, whichmight shorten the required time for the optimisation process. Moreover,to be able to use the proposed method in more general areas than solelypublic goods games, we had to demonstrate that the produced classi002erafter the optimisation process is comparable to the brute force methodand with other more general classi002cation methods such as SVM, ctree,and C5.0.We used the 10-round public goods games data set to compare results ofboth the brute force and differential evolution algorithm. The optimisedclassi002ers had limited differences which ultimately did not affect the 002-nal result of classifying players, except slightly in the case of using theEuclidean distance of items from classes centroid as a cost function.We then used both data sets of public goods games to compare resultsbetween three popular classi002ers and the proposed method. We usedtwo different sets of data attributes: 1none-temporal, contribution tableattributes and 2temporal contribution and belief attributes. Furthermore,we used different labels to train the classi002er models for each set of at-1796.6. SUMMARYtributes as we used the economist's labels with non-temporal attributesand the midpoint between every [min, max] rule of the initial rules pre-sented by the experts using player pro002les. In all cases, the proposed clas-si002cation method performed better than other classi002ers; this might bemainly due to the advantage of optimising the rules which are presentedby the experts instead of directly using labels to train classi002ers. How-ever, as we have argued before, for a data set with complex attributes anda suf002cient training data set, the proposed classi002cation method mightnot be so advantageous when used.By using pro002les of the stocks for their price behaviour, four classes arecreated: 1051 stable, 2051 smooth stable, 3051 rough stable and 4051 unstable. Initialrules for each class are created using aggregated attributes derived fromthe close price of the stocks. These rules contained a range of [min, max]values which had to be later optimised by using differential evolution to002nd the best classi002er according to one of the available cost functions.Before validating Hypothesis 6, we studied stock market behaviour inthe data set using the proposed method for measuring changes over timein temporal data sets. Three different references of behaviour were usedfor this purpose: 1002rst time point, 2previous time point, and 3temporalclass of the stocks. The 002rst two references of behaviours were clusteredalongside other time points for the comparison, while for the last one theproposed classi002cation method is used to classify the stocks according totheir price.Different clustering methods were used to cluster stocks in each timepoint. Moreover, external cluster validity indices were used to measurethe differences between each time point and its reference of behaviour. Itmight be concluded from the results that the stock price similarity dropsfrom each next day until it gets to a point before then starting to level out.To validate Hypothesis 6, three different cost functions were used the002rst part of the data set, which represents one quarter, to optimise initial180CHAPTER 6. TESTING THE STABILITY OF THE STOCK MARKETclassi002cation rules. Then, we classi002ed both quarters with the optimisedclassi002ers to produce class labels for each stock according to their stabilityin each quarter separately . Thereafter, we computed the percentage ofstocks with the identical classes in both quarters. The results suggestedthat under 50% of the stocks have similar classes in both quarters. Thismight be an indication that Hypothesis 6 has not been proven and it is notpossible to predict stocks behaviour in one quarter based on the previousquarter's price. This result was con002rmed by using different clusteringmethods to cluster stocks in both quarters of the 002scal year as the resultsalso suggested that less than 50% of the stocks follow the same group inboth cases.1816.6. SUMMARY182Chapter 7Conclusion and Future Work7.1 Thesis SummaryChapter 1 presented the main motivation behind which this thesis de-rives and the main questions to arise during the implementation of thisresearch. The motivation to undertake this study was to 002nd a methodto measure and study the change in item behaviour change in temporaldata sets. This motivation led to the discovery of the need for a methodto classify items in temporal data using relatively simple rules providedby domain experts.Chapter 2 started to cover background materials used in this thesis suchas classi002cation, clustering, cluster validity indices and classi002cation per-formance measures. Thereafter, a more detailed review was presented forthe temporal classi002cation and clustering methods. Moreover, domainspeci002c materials of the used data sets were covered. These areas includethe public goods game and its players' behaviour, as well as stock mar-ket classi002cation, prediction and predictability . This chapter presenteda variety of existing methods for measuring changes and concept driftin data streams and a spatiotemporal data sets alongside their uses andlimitations.1837.1. THESIS SUMMARYChapter 3 consisted of four parts. The 002rst part formalised the problemby specifying the intended behaviour changes of items in the temporaldata which we were interested in measuring, and the way we classifythese items to produce a reference of behaviour for them. The secondpart proposed a method to measure change over time using existing clus-tering methods and cluster validity indices. The third part proposed amethod to obtain generalised classi002cation rules from experts, and sug-gested methods of how to optimise them using different compactnessmeasures for minimising the distance between items at each time point.The last part introduced the domain speci002c data sets which are used inthis thesis as case studies. It also presented the method of collecting thesedata sets.Chapter 4was dedicated to implementing and testing the proposed methodof how to measure behavioural change.Various clustering methods wereused to cluster items at each time point 050k226means, c226means, PAM andctree051. Moreover, multiple clustering indices were used to measure dif-ferences of item membership in these clusters. These differences repre-sented the change over time. In this chapter, two references of behaviourwere used for the 002rst time point and the previous time point.Chapter 5 implemented the proposed method for rule-based temporalclassi002cation. It presented multiple compactness factors which can beused to minimise the distance between items of each time point. A de-tailed explanation of the optimisation process was presented as how toselect the optimum classi002er among all provided ranges of classi002ers bydomain experts. Then the implemented method was tested with the syn-thetic data for validation purposes. After validation, we used the methodto measure players' behaviour change during rounds of the game.Chapter 6 used a heuristic method 050Differential Evolution051 to optimisethe provided rules instead of brute force which had been used in Chapter5. It was important to increase its performance so that the classi002cation184CHAPTER 7. CONCLUSION AND FUTURE WORKmethod can be generalised and used with larger data sets. The resultsof the heuristic were validated by using previous results from the bruteforce method on public goods games. Then, the new classi002er was usedto classify the stock market data set to show the method's viability ofworking in more general areas rather than restricting it to public goodsgames players.7.2 Main ResultsThe primary motivation behind this study is to answer the question224How can we measure items' behaviour change over time in temporaldata?224. To answer this question it is required to determine the referencepoint 050called reference of behaviour051 by which we can compare items be-haviour with it at each time point. So, multiple references of behaviourare introduced including the classes of the items generated using items'overall behaviour through all time points of the temporal data. To clas-sify items in the temporal data with no training set, we proposed therule-based temporal classi002cation method. The main question and theproposed classi002cation method led to multiple sub-questions which arelisted in Chapter One. The questions, their related hypotheses and ourconclusions are listed below:017How to 002nd patterns of behaviour at a single time point?To answer this question, we propose clustering each time points'items independently from the effects of the time factor. To ensurethe clusters can detect behaviour patterns of the items, we usedmultiple clustering algorithms and hypothesised in Hypothesis 1that224 Using different clustering algorithms will not produce a sig-ni002cant difference in the 002nal result of quantifying the changes overtime as long as same clustering algorithm is used in both time points.224.In Chapter 4, we conducted experiments to answer the question1857.2. MAIN RESULTSabove and its related hypothesis. We used clustering k226means, fuzzyc226means, PAM, and hierarchical clustering algorithms to addressthat issue. . The results indicated that the hypothesis was correct,which means that we can use clustering algorithms to detect items'behaviour at each time point. This step is important when it cometo answering the main researchers' question as detecting items' be-haviour at individual time points will prepare them for the laterstage of detecting changes in their behaviour.017How to measure the difference between the produced clusters inthese time points?To answer this question, we proposed using cluster validity indicesand area under the curve of ROC analysis as these measures areoriginally designed to compare the true labels of items and theirguessed clusters and classes. To examine the ability of the pro-posed measures to detect the difference of behaviour between anytime point and a reference of behaviour, we proposed Hypothesis 2which states224 the results of different external clustering indices andAUC for the same data set and using the same clustering algorithmto determine the patterns of items' behaviour are consistent.224.We answered the question above and tested its related hypothesis inChapter 4. Different external clustering validity indices were usedfor the tests as well as AUC of ROC. According to the statisticalanalysis that we conducted, it was discovered that the hypothesisis not correct. However, the results of the single measure provedto be consistent with all the different clustering methods. So, weconcluded that different measures have different levels of sensitiv-ity for the changes of time point. Supported by evidence from thepublic goods games and synthesis data, we concluded that despitedifferent results of the measures due to the various sensitivity levelsthey possess, they produce consistent results but in various magni-tude. When using this proposed method, understanding the char-186CHAPTER 7. CONCLUSION AND FUTURE WORKacteristics of the measures might prevent any confusion or misin-terpretation of the results.017What should be the reference point of behaviour to measure thechanges between time points of the temporal data?In this study , three various references of behaviours were used toanswer this question, and each reveals different aspects of the be-havioural change of items in the temporal data. The 002rst referenceof behaviour was the 002rst time point of the temporal data. The sec-ond reference of behaviour was the previous time point for the cur-rent time point. The last was the overall behaviour of the itemsthroughout all time points. To answer the question above, we pro-posed Hypothesis 3 in Chapter One which states that 224Using over-all behaviour of a subject in a temporal data produces more stableresults than comparing each time point with the 002rst time point.224.In Chapter 4, we tested the 002rst two references of the behaviour us-ing synthetic data. The results of both cases re003ected the changeswhich are embedded in the items of the data and demonstrated dif-ferent aspects of the items change over time. For the last referenceof behaviour, we used items' classes in the temporal data. These areimplemented in Chapter 5 as general items behaviour. We used thepublic goods games data sets to compare all three proposed refer-ences. The results indicated that the related hypothesis to the abovequestion is correct.017How to classify public goods games' players according to theircontribution behaviour?To answer this question, we proposed a temporal rule-based classi-002cation method by optimising rules which are provided by expertsin Chapter Three. The original motivation behind this question wasto create a reference of behaviour. However, the proposed classi002erproved to be a viable method of classi002cation for temporal data. To1877.2. MAIN RESULTSanswer the question, we proposed Hypothesis 4 which states that224The proposed classi002cation method presents better classes that canrepresent players' behaviour than applying 002xed rules to determineplayers' classes.224We implemented the proposed classi002cation method in Chapter Six.The results of the classi002cation of public goods games data setswere compared with the labels provided by economists. The com-parison showed that the classes of the proposed classi002cation methodare more representative for players' behaviour during game roundsthan the labels provided by economists. This proved the related hy-pothesis to the question to be correct.017Does the length of the public goods game affects players strategy?To answer this question, we used the proposed classi002cation methodto classify players of two different games with various lengths 05010and 27 rounds051. To establish a test for this question, we hypothe-sised in Chapter One Hypothesis 5 224The length of the public goodsgame does not affect the overall players' strategy .224.In Chapter 5, after validating the proposed classi002cation method,we classi002ed both public goods game data sets. Then, we comparedthe results of both data sets; we did not 002nd any signi002cant differ-ence between players' classi002cation. Therefore, we concluded thatit might be an indication that the length of the game does not affectplayer behaviour.017Can the proposed temporal classi002cation method for players' ofpublic goods game be generalised and used in different areas?To answer this question, we used stock market data of S&P 500 forthe period between 1-1-2015 and 1-7-2015. The data set was clas-si002ed according to stability of the stocks' closing price. We usedproduced classes to participate in debate of the ability to predictfuture prices of stocks from existing trends of stock prices. We ar-188CHAPTER 7. CONCLUSION AND FUTURE WORKgued that to be able to predict future values of stocks, the major-ity of stock prices should follow the same stability class in at leasttwo consecutive time periods. Thus, we presented Hypothesis 6which states 224At least 50% of the stocks follow the same stabilityclass for two consecutive quarters so that their future behaviour ispredictable.224. This does not mean that we used the proposed clas-si002cation method to predict future prices. Instead, we used it toparticipate in the argument of price predictability .In Chapter 6, classi002ed the stocks of S&P 500 into four classes: sta-ble, smooth stable, rough stable and unstable. To validate the hy-pothesis of this question, the data was split into two parts, and eachpart was classi002ed separately from each other. Then, we comparedthe classes of stocks in both parts to determine whether they hadchanged their classes or not. We used multiple compactness mea-sures to classify both parts of the data set 050Euclidean distance, IQR,and Internal cluster validity indices051 and calculated the percentageof the stocks with the same classes in both parts. Moreover, weused the different clustering methods to support our 002nding in theclassi002cation. Both classi002cation and clustering methods showedthat 50% of the stocks change their classes between these two parts.We, therefore, concluded that Hypothesis 6 was not correct. Thisconclusion might indicate that it is not possible to predict stockprices only by using their historic price. However, this experimentanswered the main question which is the ability of the proposedclassi002er to operate in additional areas other than classifying publicgoods game players. Therefore, the proposed method can be gen-eralised.1897.3. CONTRIBUTIONS7.3 ContributionsTo summarise, this thesis has presented two main contributions in the002eld data of mining and analysis and four contributions in the applied002elds of the used data:017Temporal rule-based classi002cation: We have proposed this classi002-cation method and tested its ability with three data sets. We com-pared the results of this classi002cation with other well-known clas-si002cation methods 050C5.0, SVM and ctree051. The proposed methodproved to be better at determining items classes for the used tem-poral data sets.017Measuring items' behaviour change: We have proposed a new methodthat uses existing clustering and external cluster validity methodsto measure the magnitude of the change. We tested the validityof the proposed method and compared its results with the MONICmethod. The proposed method has proved to determine the magni-tude direction of the behaviour change for the items in the temporaldata sets.017Classifying players of public goods game: We have presented a newclassi002cation for the players of the public goods game using theirtemporal data rather than the existing method which used theircontribution table. We have proved that the new method re003ectsplayers' behaviour during game rounds better than than the exist-ing classi002cation method used by economists.017Determining players' behaviour change during public goods games:We have used the proposed method to measure player behaviourduring game rounds. The results indicated that their behaviourgradually changes. Moreover, we also proved that length of thegame 050number of rounds051 has a little or no impact on player be-haviour.190CHAPTER 7. CONCLUSION AND FUTURE WORK017Classifying stocks of the stock market: We have used the proposedclassi002cation method to classify stocks according to their stability .This may help with subsequent analysis of the stock market predic-tions as most stable stocks might be able to be better predicted thanthe rest, and the prediction for this particular group might be betterthan the random walk.017Contribution in stock price predictability debate: Using the pro-posed methods measuring items behaviour change and classifyingtemporal data set, we have presented a tool for economists to helpthem in determining the predictability of the stock market.It can be seen from the proposed classi002cation method that the producedresults from collaboration between human experts and machine learningsystems can outperform both whilst operating individually . As was seenfrom the classi002cation results of specially-tailored classi002er methods de-vised by human experts for public goods games players and classi002cationresults from fully automated classi002cation systems, classes could not begenerated to represent players' behaviour as the proposed method. Thisunderstanding might open an opportunity for entirely new methods ofdata mining. These could be regarded as a form of merging betweenexperts' knowledge and machines fast calculation and optimisation byallowing the experts to have more access to the created models so thatthey can adjust them in some ways 050such as changing initial boundariesof classes in our case studies051.7.4 LimitationsThe proposed methods of this study have limitations which we may t beable to address in the future. These limitations are:017The stock market data set were larger than public goods game data1917.5. FUTURE WORKsets. However, none of the used datasets for tests can be consideredas large datasets.017Due to the speed limitation of the proposed classi002cation algorithm,it might not be possible to function in reasonable time frame withbig data.017While it is possible to use multi-dimensional temporal data setswith the proposed classi002cation algorithm, we only used one or twotemporal attributes due to the limitations of the data sets.017The proposed classi002cation has been only tested with the integernumbers.7.5 Future WorkWhilst conducting this research, this study , it became obvious that thereare multiple areas that could be further pursued an investigated in future.These areas focus might vary from being an extension of this work or afurther separate study in the 002eld. The suggestions for future works are:017Develop a special criterion to measure items' behavioural change:in this study , we used the area under the curve of the receiver oper-ating characteristic analysis and multiple external validity indiceslike VI, Jaccard and Rand to determine the amount of behaviourchange of items in temporal data sets. However, these criteria werenot especially tailored for this purpose. Consequently , each of themreacted differently 050different sensitivities051 to the same amount ofchange. It might, therefore, be bene002cial if we could create criteriawhich are specially designed to quantify differences between anytwo time points. Another solution to the sensitivity problem mightbe to appoint one of the existing criteria which can be proved to beless affected by the outliers and noise.192CHAPTER 7. CONCLUSION AND FUTURE WORK017Create a con002dent degree for the change in measuring behaviourwhile creating a measure for items' behaviour change using exter-nal cluster validity , it might be possible to produce a con002dencedegree for that measure using internal cluster validity indices. Theinternal validity indices calculate the dispersion of the clusters sothat the further-dispersed clusters in each time point might be anindication of the irregularity of the groups' behaviour which mightthen lead to a decrease in the con002dence of the change measure.017Introduce a single criterion to describe items' behaviour in the dataset: in this study , we used regression to describe the general be-haviour movement for items at all time points of the temporal dataset. However, more investigations are needed to compare it withother criteria that may be available and ones that can be both bemore expressive, and also better represent the movements of thebehaviour of items at all time points.017Creating a specialised cost function for the proposed rule-basedtemporal classi002cation: In this study , different compactness mea-sures were tested to create a cost function to minimise the distanceamong the same group of items at each time point. However, theused methods might not be the ideal way to measure the compact-ness of the group items to show the homogeneity of their behaviour.For example, IQR completely ignores the outliers, Euclidean dis-tance is affected by the outliers, and internal cluster validity indiceslead to empty cluster creation. It might be possible to create a costfunction by amending the internal cluster validity equations to dis-courage the creation of empty or low population groups of items.017Increase the speed of the temporal classi002cation: In this study , weused differential evolution to optimise the classi002cation rules. Dif-ferential evolution was used to replace the brute force method of002nding an optimum solution in a reasonable time. However, it1937.5. FUTURE WORKmight be possible to further increase the speed of the optimisationprocess by using an enhanced cost function to evaluate classi002ersfaster, and calculating the dispersion of items in groups at all timepoints with one operation instead of looping through time pointsand evaluating each of them individually . It may also be possibleto use multidimensional matrices to model the data and matrix op-erations to 002nd the cost of all time points at once and, therefore,increasing the speed of the classi002er.017Creating a framework: In this study , we used R programming lan-guage to implement the proposed methods of the study . However,each method was implemented as a stand-alone solution separately .However, while this point can be considered a technical detail, , tomake the proposed methods accessible for further researches anddevelopment, it is important to create a framework which com-bines both proposed methods 050the rule-based temporal classi002erand measuring items behaviour051. The framework can be imple-mented in a single package in different programming languageslike R, SAS and Python as they are leading languages in data sci-ence [172].017Using more data sets: In this study , two data sets were used for thepublic goods games tests and one data set was used for the stockmarkets tests. While these data sets were suf002cient for this study ,further data sets might, however, be used to support the 002ndings.Different game setups for public goods games can be used to com-pare player behaviour with different rules and environments. Theresults of the stock market 050its instability051 can be con002rmed by usingdata sets from various stocks other than S&P 500 and using pricesin different years.194Bibliography[1] S. B. Kotsiantis, 223Supervised machine learning: A review ofclassi002cation techniques,224Informatica, vol. 31, pp. 249226268, 2007.[2] M. J. Zaki and M. J. Meira,Data Mining and Analysis: FundamentalConcepts and Algorithms.	New York: Cambridge University Press,2014.[3] I. H. Witten, E. Frank, and M. a. Hall,Data Mining: PracticalMachine Learning T ools and T echniques, Third Edition.	MorganKaufmann, 2011.[4] K.-R. Muller, S. Mika, G. Ratsch, K. Tsuda, and B. Scholkopf,223An introduction to kernel-based algorithms,224IEEE T ransactionson Neural Networks, vol. 12, no. 2, pp. 181227-202, 2001.[5] E. Alpaydin,Introduction to Machine Learning.	London, England:The MIT Press, 2010.[6] A. K. Jain, M. N. Murty , and P . J. Flynn, 223Data clustering: areview,224ACM computing surveys 050CSUR051, vol. 31, no. 3, pp.264227-323, 1999.[7] E. Keogh and C. A. Ratanamahatana, 223Exact indexing of dynamictime warping,224Knowledge and Information Systems, vol. 7, pp. 358226386, 2005.[8] M. Regan, 223K-Nearest Neighbors with Dynamic Time Warp-ing,224 2014. [Online]. Available: https://github.com/markdregan/195BIBLIOGRAPHYK-Nearest-Neighbors-with-Dynamic-Time-Warping[9] A. E. Eiben and J. E. Smith,Introduction to Evolutionary Computing,2nd ed., T. B250ack, A. Eiben, J. Kok, and H. Spaink, Eds.	Springer,2015.[10] T. Kirkman, 223Statistics to use,224 1996. [Online]. Available: http://www.physics.csbsju.edu/stats/[11] U. Fischbacher, S. Gachter, S. Quercia, and S. G250achter, 223Thebehavioral validity of the strategy method in public goodexperiments,224Journal of Economic Psychology, vol. 33, no. 4, pp.897226913, aug 2012.[12] S. Chakrabarti, M. Ester, U. Fayyad, and J. Gehrke, 223Datamining curriculum: a proposal,224 inACM SIGKDD, 2006, pp.122610. [Online]. Available: http://pdf.aminer.org/000/303/279/decisionf
gtreef
gconstructionf
gfromf
gmultidimensionalf
gstructuredf
gdata.pdff%g5Cnhttp://scholar.google.com/scholar?hl=enf&gbtnG=Searchf&gq=intitle:Data+mining+curriculum:+A+proposal+050V ersion+1.0051f#g4f%g5Cnhttp://scholar.google.com/scholar[13] T. Palfrey and J. Prisbrey , 223Anomalous behavior in public goodsexperiments: How much and why?224The American EconomicReview, vol. 87, no. 5, pp. 829226846, 1997.[14] M. Dufwenberg, S. G250achter, and H. Hennig-Schmidt, 223The framingof games and the psychology of play,224Games and EconomicBehavior, vol. 73, no. 2, pp. 459226478, 2011.[15] M. Halkidi, Y . Batistakis, and M. Vazirgiannis, 223Cluster validitymethods: part I,224ACM Sigmod Record, vol. 31, no. 2, pp. 4022645,2002.196BIBLIOGRAPHY[16] C. M. Bishop,Pattern Recognition and Machine Learning, M. Jordan,J. Kleinberg, and B. Scholkopf, Eds. Singapore: Springer, 2006.[17] A. Samuel, 223Some studies in machine learning using the game ofcheckers,224IBM Journal of research and development, vol. 3, no. 3, pp.210226229, 1959.[18] X. Wu, V . Kumar, Q. J. Ross, J. Ghosh, Q. Yang, H. Motoda, G. J.McLachlan, A. Ng, B. Liu, P . S. Yu, Z. H. Zhou, M. Steinbach,D. J. Hand, and D. Steinberg, 223Top 10 algorithms in data mining,224Knowledge and Information Systems, vol. 14, no. 1, pp. 122637, 2008.[19] J. R. Quinlan,C4.5: programs for machine learning. Elsevier, 2014.[20] L. Breiman, 223Random forest,224Machine learning, vol. 45, no. 1, pp.5227-32, 2001.[21] T. Hothorn, K. Hornik, and A. Zeileis, 223Unbiased RecursivePartitioning: A Conditional Inference Framework,224Journal ofComputational and Graphical Statistics, vol. 15, no. 3, pp. 651226674,sep 2006.[22] A. Rodriguez, J. A. Aguado, F. Martin, J. J. Lopez, F. Munoz, andJ. E. Ruiz, 223Rule-based classi002cation of power quality disturbancesusing S-transform,224Electric Power Systems Research, vol. 86, pp. 113226121, 2012.[23] C. S. Chen, 223Statistical analysis of space-varying morphologicalopenings with 003at structuring elements,224IEEE T ransactions onSignal Processing, vol. 44, no. 4, pp. 9982261001, 1996.[24] J. Chung, E. J. Powers, W. M. Grady , and S. C. Bhatt, 223Power dis-turbance classi002er using a rule-based method and wavelet packet-based hidden Markov model,224IEEE T ransactions on Power Delivery,vol. 17, no. 1, pp. 233226241, 2002.197BIBLIOGRAPHY[25] A. D. McAulay and J. C. Oh, 223Improving Learning of Genetic Rule-Based Classi002er,224IEEE T ransactions on Systems, Man, and Cybernet-ics, vol. 24, pp. 152227-159, 1994.[26] A. Orriols-Puig and E. Bernad264o-Mansilla, 223Evolutionary rule-based systems for imbalanced data sets,224Soft Computing, vol. 13,no. 3, pp. 213226225, 2009.[27] K. Nozaki, H. Ishibuchi, and H. Tanaka, 223Adaptive fuzzy rule-based classi002cation systems,224IEEE T ransactions on Fuzzy Systems,vol. 4, no. 3, pp. 238226250, 1996.[28] H. Ishibuchi, K. Nozaki, and H. Tanaka, 223Distributed representa-tion of fuzzy rules and its application to pattern classi002cation,224Fuzzy Sets and Systems, vol. 52, no. 1, pp. 2122632, 1992.[29] H. N264u230nez, C. Angulo, and A. Catal036a, 223Rule-based learning systemsfor support vector machines,224Neural Processing Letters, vol. 24,no. 1, pp. 122618, 2006.[30] D. Wettschereck, D. W. Aha, and T. Mohri, 223A Review andEmpirical Evaluation of Feature Weighting Methods for a Class ofLazy Learning Algorithms,224Arti002cial Intelligence Review, vol. 11,no. 12265, pp. 273227-314, 1997.[31] T. Fawcett, 223An introduction to ROC analysis,224Pattern RecognitionLetters, vol. 27, no. 8, pp. 861226874, jun 2006.[32] A. P . Bradley , 223The use of the area under the ROC curve in theevaluation of machine learning algorithms,224Pattern Recognition,vol. 30, no. 7, pp. 11452261159, jul 1997.[33] D. D. J. Hand and R. J. R. Till, 223A simple generalisation of the areaunder the ROC curve for multiple class classi002cation problems,224Machine Learning, pp. 171226186, 2001.198BIBLIOGRAPHY[34] L. Kaufman and P . J. Rousseeuw, 223Partitioning Around Medoids050Program PAM051,224Finding Groups in Data: An Introduction to Clus-tering Analysis, pp. 68226125, 1990.[35] R. T. Ng and J. Han, 223CLARANS: A method for clustering objectsfor spatial data mining,224IEEE T ransactions on Knowledge and DataEngineering, vol. 14, no. 5, pp. 10032261016, 2002.[36] X. Y . Wang, 223Fuzzy Clustering in the Analysis of FourierTransform Infrared Spectra for Cancer Diagnosis,224 Ph.D. dis-sertation, The University of Nottingham, 2006. [Online]. Avail-able:	http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.192.9931f&grep=rep1f&gtype=pdf[37] J. C. Dunn, 223A Fuzzy Relative of the ISODATA Process and ItsUse in Detecting Compact Well-Separated Clusters,224Journal ofCybernetics, vol. 3, no. 3, pp. 3222657, jan 1974.[38] J. C. Bezdek,Pattern Recognition with Fuzzy Objective FunctionAlgorithms. New York: Plenum Press, 1981, vol. 25, no. 3.[39] U. V on Luxburg, 223Clustering stability: an overview,224Foundationsand T rends in Machine Learning, vol. 2, no. 3, pp. 235227-274, 2010.[40] M. Halkidi, Y . Batistakis, and M. Vazirgiannis, 223Clustering validitychecking methods Part II,224ACM SIGMOD Record, vol. 31, no. 3,p. 19, sep 2002.[41] E. Rend264on and I. Abundez, 223Internal versus External clus-ter validation indexes,224International Journal of computers andcommunications, vol. 5, no. 1, pp. 2722634, 2011.[42] L. V endramin, R. J. Campello, and E. R. Hruschka, 223Relativeclustering validity criteria: A comparative overview,224StatisticalAnalysis and Data Mining, vol. 4, no. 3, pp. 209226235, 2010.199BIBLIOGRAPHY[43] E. Fowlkes and C. Mallows, 223A method for comparing twohierarchical clusterings,224Journal of the American . . ., vol. 78, no.383, pp. 553226569, 1983.[44] M. Meil, 223Comparing clusteringsan information based distance,224Journal of Multivariate Analysis, vol. 98, no. 5, pp. 873226895, may2007.[45] J. C. Dunn, 223A Fuzzy Relative of the ISODATA Process and ItsUse in Detecting Compact Well-Separated Clusters,224Journal ofCybernetics, vol. 3, no. 3, pp. 3222657, jan 1973.[46] D. L. Davies and D. W. Bouldin, 223A cluster separation measure,224IEEE transactions on pattern analysis and machine intelligence, vol. 1,no. 2, pp. 224226227, 1979.[47] M. Halkidi, M. Vazirgiannis, and Y . Batistakis, 223Quality schemeassessment in the clustering process,224Principles of Data Mining andKnowledge Discovery, pp. 265226276, 2000.[48] M. Halkidi and M. Vazirgiannis, 223Clustering validity assessment:002nding the optimal partitioning of a data set,224Proceedings 2001IEEE International Conference on Data Mining, no. FEBRUARY , pp.187226194, 2001.[49] A. K. Jain and R. C. Dubes,Algorithms for clustering data, ser.Prentice-Hall Advanced Reference Series. Englewood Cliffs, NewJersey: Prentice Hall PTR, 1988.[50] S. Laxman and P . P . Sastry , 223A survey of temporal data mining,224Sadhana, vol. 31, no. April, pp. 173226198, 2006.[51] J. Han and M. Kamber,Data Mining Concepter and T echniques,2nd ed. San Francisco, CA, USA: Morgan Kaufmann, 2006.[52] M. Spiliopoulou, I. Ntoutsi, Y . Theodoridis, and R. Schult, 223Monic:modeling and monitoring cluster transitions,224Proceedings of the200BIBLIOGRAPHY12th ACM SIGKDD international conference on Knowledge discoveryand data mining, pp. 706226711, 2006.[53] S. G250unnemann, H. Kremer, C. Laufkotter, and T. Seidl, 223Tracingevolving clusters by subspace and value similarity,224Advances inKnowledge Discovery and Data Mining, vol. 6635, pp. 444226456, 2011.[54] B. Hawwash and O. O. Nasraoui, 223Stream-dashboard:	aframework for mining, tracking and validating clusters in a datastream,224Proceedings of the 1st International Workshop on Big Data,Streams and Heterogeneous Source Mining:	Algorithms, Systems,Programming Models and Applications, pp. 109226117, 2012.[55] P . Kalnis, N. Mamoulis, and S. Bakiras, 223On discovering movingclusters in spatio-temporal data,224Advances in Spatial and T emporalDatabases, vol. 3633, pp. 364226381, 2005.[56] I. Ntoutsi, M. Spiliopoulou, and Y . Theodoridis, 223SummarizingCluster Evolution in Dynamic Environments,224 inComputational Sci-ence and Its Applications - ICCSA 2011. Springer Berlin Heidelberg,2011, vol. 6783, pp. 562226577.[57] M. B250ottcher, F. H250oppner, and M. Spiliopoulou, 223On exploitingthe power of time in data mining,224ACM SIGKDD ExplorationsNewsletter, vol. 10, no. 2, pp. 322611, dec 2008.[58] I. Ntoutsi, M. Spiliopoulou, and Y . Theodoridis, 223Tracing clustertransitions for different cluster types.224Control and Cybernetics,vol. 38, no. 1, pp. 239226259, 2009.[59] C. C. Aggarwal, 223On change diagnosis in evolving data streams,224Knowledge and Data Engineering, IEEE T ransactions on, vol. 17, no. 5,pp. 587226600, 2005.[60] T. Amr, 223Survey on Time-Series Data Classi002cation,224TSDM, pp.122610, 2012.201BIBLIOGRAPHY[61] J. Wang and G. Karypis, 223HARMONY: Ef002ciently Mining the BestRules for Classi002cation,224Proceedings of the 2005 SIAM InternationalConference on Data Mining, pp. 205227-216, 2005.[62] D. Berndt and J. Clifford, 223Using dynamic time warping to 002ndpatterns in time series,224AAAI-94 Workshop on Knowledge KnowledgeDiscovery in Databases, vol. 10, no. 16, pp. 359226370, 1994.[63] L. Rabiner and B.-H. Juang,Fundamentals of speech recognition. PTRPrentice Hall, 1993.[64] L. Wei and E. Keogh, 223Semi-supervised time series classi002cation,224Proceedings of the 12th ACM SIGKDD international conference onKnowledge discovery and data mining - KDD '06, p. 748, 2006.[65] L. Kajfn'agn, A. Kertfn'egsz-Farkas, D. Franklin, N. Ivanova,A. Kocsor, and S. Pongor, 223Application of a simple likelihood ra-tio approximant to protein sequence classi002cation,224Bioinformatics,vol. 22, no. 23, pp. 28652262869, 2006.[66] R. Agrawal, C. Faloutsos, and A. Swami, 223Effcient Similarity SearchIn Sequence Databases,224Foundations of data organization and algo-rithms, pp. 69227-84, 1993.[67] K.-p. Chan and A. W.-c. Fu, 223Ef002cient Time Series Matching byWavelets,224Data Engineering, 1999. Proceedings., 15th InternationalConference, pp. 126227-133, 1999.[68] A. Douzal-Chouakria and C. Amblard, 223Classi002cation trees fortime series,224Pattern Recognition, vol. 45, pp. 10762261091, 2012.[69] R. Sitaram, H. Zhang, C. Guan, M. Thulasidas, Y . Hoshi,A. Ishikawa, K. Shimizu, and N. Birbaumer, 223Temporal classi002ca-tion of multichannel near-infrared spectroscopy signals of motorimagery for developing a brain-computer interface,224NeuroImage,vol. 34, no. 4, pp. 14162261427, 2007.202BIBLIOGRAPHY[70] V . S. Tseng and C. H. Lee, 223Effective temporal data classi002cation byintegrating sequential pattern mining and probabilistic induction,224Expert Systems with Applications, vol. 36, no. 5, pp. 95242269532, 2009.[71] T. Oates, L. Firoiu, and P . Cohen, 223Clustering time series withhidden Markov models and dynamic time warping,224Proceedings ofthe IJCAI-99 workshop on neural, symbolic and reinforcement learningmethods for sequence learning, pp. 1722621, 1999.[72] Z. Xing, J. Pei, and E. Keogh, 223A brief survey on sequence classi002-cation,224ACM SIGKDD Explorations Newsletter, vol. 12, no. 1, p. 40,2010.[73] P . Esling and C. Agon, 223Time-series data mining,224ACM ComputingSurveys 050CSUR051, vol. 45, no. 1, pp. 122634, 2012.[74] T. Jebara, Y . Song, and K. Thadani, 223Spectral Clustering and Em-bedding with Hidden Markov Models,22418th European Conferenceon Machine Learning, ECML 2007, Proceedings of, vol. 4701, pp. 164226175, 2007.[75] P . P . Rodrigues, J. Gama, and J. P . Pedroso, 223Hierarchical cluster-ing of time-series data streams,224IEEE T ransactions on Knowledge andData Engineering, vol. 20, no. 5, pp. 615226627, 2008.[76] T. Warren Liao, 223Clustering of time series data - A survey,224PatternRecognition, vol. 38, no. 11, pp. 18572261874, 2005.[77] E. J. Keogh and M. J. Pazzani, 223Scaling up dynamic time warpingfor datamining applications,224Knowledge discovery and data mining,vol. 10, pp. 285226289, 2000.[78] S. Soheily-Khah, A. Douzal-Chouakria, and E. Gaussier, 223General-ized k-means-based clustering for temporal data under weightedand kernel time warp,224Pattern Recognition Letters, vol. 75, pp.6322669, 2016.203BIBLIOGRAPHY[79] I. Kaul, I. Grungberg, and M. Stern, 223Global public goods,224Globalpublic goods, 1999.[80] U. Fischbacher, S. G250achter, and E. Fehr, 223Are people conditionallycooperative?	Evidence from a public goods experiment,224Economics Letters, vol. 71, pp. 397226404, 2001.[81] R. Burlando and F. Guala, 223Heterogeneous agents in public goodsexperiments,224Experimental Economics, pp. 122641, 2005.[82] D. Rustagi, S. Engel, and M. Kosfeld, 223Conditional Cooperationand Costly Monitoring Explain Success in Forest Commons Man-agement,224Science, vol. 330, pp. 961226965, 2010.[83] E. F. Fama, 223The Behavior of Stock-Market Prices,224 p. 34, 1965.[84] A. W. Lo and A. C. MacKinlay , 223Stock Market Prices Do Not FollowRandom Walks: Evidence from a Simple Speci002cation Test,224Reviewof 002nancial studies, vol. 1, no. 1, pp. 4122666, 1988.[85] M. V . Subha and S. T. Nambi, 223Classi002cation of stock indexmovement using k-nearest neighbours 050k-NN051 algorithm,224WSEAST ransactions on Information Science and Applications, vol. 9, no. 9, pp.261226270, 2012.[86] D. Ra002ei and A. Mendelzon, 223Similarity-Based Queries for TimeSeries Data,224SIGMOD Conference, vol. 26, no. 2, pp. 1322624, 1998.[87] M. Vlachos, M. Hadjieleftheriou, D. Gunopulos, and E. J.Keogh, 223Indexing multi-dimensional time-series with support formultiple distance measures,224Proceedings of the ninth ACM SIGKDDinternational conference on Knowledge discovery and data mining -KDD '03, p. 216, 2003.[88] V . Estivill-Castro, 223Why so many clustering algorithms: a positionpaper,224ACM SIGKDD Explorations Newsletter, vol. 4, no. 1, pp.6522675, 2002.204BIBLIOGRAPHY[89] S. G250unnemann, H. Kremer, C. Laufk250otter, and T. Seidl, 223TracingEvolving Subspace Clusters in Temporal Climate Data,224DataMining and Knowledge Discovery, vol. 24, no. 2, pp. 387226410, sep2011.[90] K. S. Xu, M. Kliger, and A. O. Hero III, 223Adaptive evolutionaryclustering,224Data Mining and Knowledge Discovery, no. December2012, jan 2013.[91] T. Back, U. Hammel, and C. State, 223An Introduction to Evolution-ary Computation,224 in224Evolutionary Computation: Comments on theHistory and Current State, 1997, vol. 5, pp. 322617.[92] J. J. Grefenstette, 223Optimization offControlg fParametersgforfGeneticg fAlgorithmsg,224IEEE T ransactions on Systems, Man andCybernetics, vol. 16, no. 1, pp. 122226128, 1986.[93] R. Storn and K. Price, 223Differential evolution a simple and ef002cientheuristic for global optimization over continuous spaces,224Journalof global optimization, vol. 11, pp. 341226359, 1997.[94] S. Das, P . Nagaratnam Suganthan, and S. Member, 223DifferentialEvolution: A Survey of the State-of-the-Art,224IEEE TRANSAC-TIONS ON EVOLUTIONARY COMPUTATION, vol. 15, no. 1,2011.[95] T. Tusar and B. Filipic, 223Differential evolution versus genetic algo-rithms in multiobjective optimization,224 inInternational Conferenceon Evolutionary Multi-Criterion Optimization.	Berlin Heidelberg:Springer-V erlag, 2007, pp. 257226271.[96] J. F. Kenney ,Mathematics of Statistics, Part I, 2nd ed. New York: D.Van Nostrand Company , Inc., 1947.[97] D. M. Lane, D. Scott, M. Hebl, R. Guerra, D. Osherson, andH. Zimmer, 223Introduction to Statistics,224Introductory Statistics, p.205BIBLIOGRAPHY694, 2011.[98] J. H. MCDONALD,HANDBOOK OF BIOLOGICAL STATISTICS,1st ed. Baltimore, Maryland: Sparky House Publishing, 2008.[99] M. Friedman, 223A Comparison of alternative tests of signi002cance forthe problem of m rankings,224The Annals of Mathematical Statistics,vol. 11, no. 1, pp. 8622692, 1940.[100] J. Dem020sar, 223Statistical Comparisons of Classi002ers over MultipleData Sets,224Journal of Machine Learning Research, vol. 7, pp. 122630,2006.[101] P . M. Gonc 270alves, S. G. T. De Carvalho Santos, R. S. M. Barros, andD. C. L. Vieira, 223A comparative study on concept drift detectors,224Expert Systems with Applications, vol. 41, no. 18, pp. 81442268156,2014.[102] F. Leisch and E. Dimitriadou, 223mlbench: Machine Learning Bench-mark Problems,224 2010.[103] B. P . Goings, 223The New , New 050 Index 051 Math : 500 Now Equals502,224 Radford Aon Corporation, Tech. Rep. September, 2014.[Online]. Available: https://www.radford.com/home/insights/articles/2014/expertf
ginsightf
g500f
gnowf
gequalsf
g502.asp[104] The Editors of Encyclop346dia Britannica, 223S&P 500 STOCKMARKET.224 [Online]. Available:	https://www.britannica.com/topic/SandP-500[105] T. E. o. E. Britannica, 223Composite Index, Standard & Poor'sComposite Index, Standard and Poor's 500,224 2015. [Online].Available: https://www.britannica.com/topic/SandP-500[106] I. Editors, 223Standard & Poor ' s 500 Index - S & P 500,2242016. [Online]. Available: http://www.investopedia.com/terms/s/sp500.asp206BIBLIOGRAPHY[107] EditorsInvestopedia, 223Adjusted Closing Price Adjusting Prices forStock Splits,224 2016. [Online]. Available: http://www.investopedia.com/terms/a/adjustedf
gclosingf
gprice.asp[108] L. Nieweglowski, 223clv: Cluster Validation Techniques,224 2013.[Online]. Available: https://cran.r-project.org/package=clv[109] D. Ardia, K. M. Mullen, B. G. Peterson, and J. Ulrich,223fDEoptimg:	Differential Evolution infRg,224 2015. [Online].Available: http://cran.r-project.org/package=DEoptim[110] H. Wickham and R. Francois, 223dplyr:	A Grammar of DataManipulation,224 2015. [Online]. Available: https://cran.r-project.org/package=dplyr[111] T. Giorgino, 223Computing and Visualizing Dynamic Time WarpingAlignments infRg: ThefdtwgPackage,224Journal of StatisticalSoftware, vol. 31, no. 7, pp. 122624, 2009.[112] G. R. Warnes, B. Bolker, L. Bonebakker, R. Gentleman, W. H. A.Liaw, T. Lumley , M. Maechler, A. Magnusson, S. Moeller,M. Schwartz, and B. V enables, 223gplots: Various R ProgrammingTools for Plotting Data,224 2016. [Online]. Available:	https://cran.r-project.org/package=gplots[113] F. E. H. Jr, with contributions from Charles Dupont, andM. others., 223Hmisc:	Harrell Miscellaneous,224 2016. [Online].Available: https://cran.r-project.org/package=Hmisc[114] A. Fritsch, 223mcclust: Process an MCMC Sample of Clusterings,2242012. [Online]. Available:	https://cran.r-project.org/package=mcclust[115] X. Robin, N. Turck, A. Hainard, N. Tiberti, F. Lisacek, C. Sanchez,M. M250uller, J.-C. Sanchez, and M. M250uller, 223pROC: an open-source207BIBLIOGRAPHYpackage for R and S+ to analyze and compare ROC curves,224BMCBioinformatics, vol. 12, p. 77, 2014.[116] M. Hlavac, 223stargazer: Well-Formatted Regression and SummaryStatistics Tables,224 Cambridge, USA, 2015. [Online]. Available:http://cran.r-project.org/package=stargazer[117] A. Chaudhuri, 223Sustaining cooperation in laboratory public goodsexperiments: a selective survey of the literature,224ExperimentalEconomics, vol. 14, no. 1, pp. 4722683, sep 2010.[118] U. Fischbacher and S. Gachter, 223The behavioral validity of thestrategy method in public good experiments,224CeDEx, pp. 1227-21,2009.[119] U. Fischbacher and S. G250achter, 223Social Preferences, Beliefs, and theDynamics of Free Riding in Public Goods Experiments,224AmericanEconomic Review, vol. 100, no. 1, pp. 541226556, mar 2010.[120] R. Elwell and R. Polikar, 223Incremental Learning of Concept Driftin Nonstationary Environments,224IEEE T ransactions on Neural Net-works, vol. 22, no. 10, pp. 15172261531, 2011.[121] R. Garnett and S. J. Roberts, 223Learning from Data Streams withConcept Drift,224T echnical Report P ARG-08-01, Dept. of EngineeringScience, University of Oxford, 2008.[122] L. Xiaofeng and G. Weiwei, 223Study on a Classi002cation Model ofData Stream based on Concept Drift,224International Journal of Multi-media and Ubiquitous Engineering, vol. 9, no. 5, pp. 363226372, 2014.[123] M. Baena-Garcia, J. del Campo-Avila, R. Fidalgo, A. Bifet,R. Gavalda, and R. Morales-Bueno, 223Early Drift DetectionMethod,2244th ECML PKDD International Workshop on Knowledge Dis-covery from Data Streams, pp. 7722686, 2006.208BIBLIOGRAPHY[124] M. Harel, S. Mannor, R. El-Yaniv , and K. Crammer, 223Concept DriftDetection Through Resampling,224Proceedings of the 31st InternationalConference on Machine Learning 050ICML-14051, pp. 10092261017, 2014.[125] M. Spiliopoulou, E. Ntoutsi, Y . Theodoridis, and R. Schult,223MONIC and Followups on Modeling and Monitoring ClusterTransitions,224Machine Learning and Knowledge Discovery in Databases,vol. 8190, no. 2013, pp. 622226626, 2013.[126] D. Yang, Z. Guo, E. A. Rundensteiner, and M. O. Ward, 223CLUES: auni002ed framework supporting interactive exploration of density-based clusters in streams,224Proceedings of the 20th ACM internationalconference on Information and knowledge management, pp. 815226824,2011.[127] M. Meila, 223Comparing clusterings by the variation of information,224Learning theory and Kernel machines: 16th Annual Conference onLearning Theory and 7th Kernel Workshop, COLT/Kernel 2003,Washington, DC, USA, August 24-27, 2003: proceedings, p. 173, 2003.[128] M. Halkidi, Y . Batistakis, and M. Vazirgiannis, 223On clusteringvalidation techniques,224Journal of Intelligent Information . . ., vol. 17,no. 2-3, pp. 107226145, 2001.[129] A. K. Jain, 223Data Clustering 50 Years Beyond K-Means,224Patternrecognition letters, vol. 31, no. 8, pp. 651226666, 2010.[130] G. W. Milligan and M. C. Cooper, 223An examination of proceduresfor determining the number of clusters in a data set,224Psychometrika,vol. 50, no. 2, pp. 159226179, jun 1985.[131] H. Yu, Z. Liu, and G. Wang, 223An automatic method to determinethe number of clusters using decision-theoretic rough set,224International Journal of Approximate Reasoning, vol. 55, no. 1, pp.101226115, jan 2014.209BIBLIOGRAPHY[132] D. J. Ketchen and C. L. Shook, 223THE APPLICATION OF CLUS-TER ANALYSIS IN STRATEGIC MANAGEMENT RESEARCH:AN ANALYSIS AND CRITIQUE,224Strategic Management Journal,vol. 17, pp. 441226458, 1996.[133] O. Arbelaitz, I. Gurrutxaga, J. Muguerza, J. M. P264e rez, and I. igo Per-ona, 223An extensive comparative study of cluster validity indices,224Pattern Recognition, vol. 46, pp. 243226256, 2012.[134] M. Rezaei and P . Franti, 223Set matching measures for external clustervalidity,224IEEE T ransactions on Knowledge and Data Engineering,vol. 28, no. 8, pp. 21732262186, aug 2016.[135] C. Figui036eres, D. Masclet, and M. Willinger, 223Weak moral motivationleads to the decline of voluntary contributions,224Journal of PublicEconomic Theory, vol. 15, no. 5, pp. 745226772, 2013.[136] U. Fischbacher, S. G250achter, and K. Whitehead, 223HeterogeneousSocial Preferences and the Dynamics of Free Riding in Public GoodExperiments about the Centre or contact,224The American economicreview, vol. 100, no. 1, pp. 541227-556, 2010.[137] A. Chaudhuri and T. Paichayontvijit, 223Conditional cooperationand voluntary contributions to a public good,224Economics Bulletin,vol. 3, no. 8, pp. 122615, 2006.[138] C. Keser and F. van Winden, 223Conditional Cooperation andV oluntary Contributions to Public Goods,224The ScandinavianJournal of Economics, vol. 102, pp. 2322639, 2000.[139] M. Negnevitsky ,Arti002cial Intelligence, 2nd ed.	Edinburgh GateHarlow, England: Pearson Education Limited, 2005.[140] L. X. Wang and J. M. Mendel, 223Generating fuzzy rules by learningfrom examples,224IEEE T ransactions on Systems, Man and Cybernetics,vol. 22, pp. 14142261427, 1992.210BIBLIOGRAPHY[141] O. Cordon, M. J. del Jesus, and F. Herrera, 223A proposal on rea-soning methods in fuzzy rule-based classi002cation systems,224Inter-national Journal of Approximate Reasoning, vol. 20, no. 1, pp. 2122645,1999.[142] H. Ishibuchi, T. Nakashima, and T. Morisawa, 223V oting in fuzzyrule-based systems for pattern classi002cation problems,224Fuzzy Setsand Systems, vol. 103, no. 2, pp. 223226238, 1999.[143] E. Styvaktakis, M. H. J. Bollen, and I. Y . H. Gu, 223Expert system forclassi002cation and analysis of power system events,224IEEE T ransac-tions on Power Delivery, vol. 17, no. 2, pp. 423226428, 2002.[144] A. Giacometti, E. Miyaneh, P . Marcel, and A. Soulet, 223A genericframework for rule-based classi002cation,224Proceedings of LeGo, pp.3722654, 2008.[145] B. Qin, Y . Xia, S. Prabhakar, and Y . Tu, 223A rule-based classi002cationalgorithm for uncertain data,224Proceedings - International Conferenceon Data Engineering, pp. 16332261640, 2009.[146] L. A. Zadeh, 223Making computers think like people,224IEEE Spec-trum, vol. 21, no. August, pp. 2622632, 1984.[147] R. L. Lawrence and A. Wrlght, 223Rule-Based Classi002cation SystemsUsing Classi002cation and Regression Tree 050CART051 Analysis,224Pho-togrammetric Engineering & Remote Sensing, vol. 67, no. 10, pp. 11372261142, 2001.[148] M. Sugeno and T. Yasukawa, 223A Fuzzy-Logic-Based Approach toQualitative Modeling,224IEEE T ransactions on Fuzzy Systems, vol. 1,no. 1, pp. 722631, 1993.[149] J. H. Watt and S. van den Berg, 223Describing Data: Measures of Cen-tral Tendency and Dispersion,224 inBasic T ools of Research: Sampling,211BIBLIOGRAPHYMeasurement, Distributions, and Descriptive Statistics2, 2002, pp. 100226119.[150] A. Harvey , E. Ruiz, and N. Shephard, 223Multivariate stochastic vari-ance models,224The Review of Economic Studies, vol. 61, no. 2, pp.247227-264, 1994.[151] M. M. Deza and E. Deza,Encyclopedia of distances. Springer, 2009.[152] E. Keogh and S. Kasetty , 223On the Need for Time Series Data MiningBenchmarks: A Survey and Empirical Demonstration,224Data Min-ing and Knowledge Discovery, vol. 7, no. 4, pp. 349226371, 2003.[153] K.-L. Wu and M.-S. Yang, 223Alternative c-means clusteringalgorithms,224Pattern Recognition, vol. 35, no. 10, pp. 22672262278,2002.[154] Y . Liu, Z. Li, H. Xiong, X. Gao, and J. Wu, 223Understanding ofInternal Clustering Validation Measures,2242010 IEEE InternationalConference on Data Mining, pp. 911226916, 2010.[155] L. Jegatha Deborah, R. Baskaran, and A. Kannan, 223A Surveyon Internal Validity Measure for Cluster Validation,224InternationalJournal of Computer Science & Engineering Survey, vol. 1, no. 2, pp.85226102, nov 2010.[156] Y . Bazi and F. Melgani, 223Toward an optimal SVM classi002cation sys-tem for hyperspectral remote sensing images,224IEEE T ransactions onGeoscience and Remote Sensing, vol. 44, no. 11, pp. 33742263385, 2006.[157] G. Atsalakis and Valavanis K., 223Surveying stock market forecastingtechniques - Part I: Conventional methods,224Zopounidis C., Compu-tation Optimization in Economics and Finance Research Compendium,,no. August, pp. 49226104, 2013.[158] J. I. Larsen, B. Publishing, M. K. Brunnermeier, and L. H. Pedersen,223Predicting Stock Prices Using Technical Analysis and Machine212BIBLIOGRAPHYLearning,224Review of Financial Studies, vol. 22, no. June, pp. 693226709,2010.[159] J. Wolfers and E. Zitzewitz, 223Prediction Markets,224The Journal of Eco-nomic Perspectives, vol. 18, no. 2, pp. 107226126, 2004.[160] D. Ardia, K. Boudt, P . Carl, K. M. Mullen, and B. G. Peterson,223Differential Evolution with DEoptim,224The R Journal, vol. 3, no. 1,pp. 2722634, 2011.[161] B. Letham, C. Rudin, T. H. Mccormick, and D. Madigan, 223An Inter-pretable Stroke Prediction Model Using Rules and Bayesian Anal-ysis,224 University of Washington, Tech. Rep., 2013.[162] T. Hothorn, K. Hornik, and A. Zeileis, 223ctree: Conditional InferenceTrees,224Cran.At.R-Project.Org, 2006.[163] P . Revesz and T. Triplet, 223Temporal data classi002cation using linearclassi002ers,224Information Systems, vol. 36, no. 1, pp. 3022641, 2011.[164] Y . Zhao, 223R and Data Mining: Examples and Case Studies,224Academic Press, no. December 2012, pp. 1226160, 2014.[165] H. Zhang, T. B. Ho, and M. S. Lin, 223A Non-parametric Wavelet Fea-ture Extractor for Time Series Classi002cation,224Advances in KnowledgeDiscovery and Data Mining, vol. 3056, pp. 595226603, 2004.[166] T. C. Fu, 223A review on time series data mining,224EngineeringApplications of Arti002cial Intelligence, vol. 24, no. 1, pp. 164226181, 2011.[167] J.-i. Itaya, D. de Meza, and G. D. Myles, 223The PrivateProvision of Public Goods,224 2010. [Online]. Available:	https://fee.org/articles/the-private-provision-of-public-goods/[168] S. P . Anderson, J. K. Goeree, and C. A. Holt, 223A theoretical analysisof altruism and decision error in public goods games,224Journal ofPublic Economics, vol. 70, no. 2, pp. 297226323, 1998.213BIBLIOGRAPHY[169] R. H. Kirschen, E. A. O&apos;Higgins, and R. T. Lee, 223TheRoyal London Space Planning: An integration of space analysisand treatment planning Part I: Assessing the space required tomeet treatment objectives,224American Journal of Orthodontics andDentofacial Orthopedics, vol. 118, no. 4, pp. 448226455, 2000.[170] Y . Liu, U. Aickelin, J. Feyereisl, and L. G. Durrant, 223BiomarkerCD46 Detection in Colorectal Cancer Data based on Wavelet Fea-ture Extraction and Genetic Algorithm,224Knowledge-Based Systems,vol. 37, pp. 502226514, 2013.[171] J. G. Agrawal, V . S. Chourasia, and a. K. Mittra, 223State-of-the-Artin Stock Prediction Techniques,224Advanced Research in Electrical andInstrumental Engineering, vol. 2, no. 4, pp. 13602261366, 2013.[172] G.	Piatetsky ,	223Four	main	languages	for	Analyt-ics	,	Data	Mining	,	Data	Science,224	2014.	[On-line].	Available:	http://www.kdnuggets.com/2014/08/four-main-languages-analytics-data-mining-data-science.html214Appendices215Appendix AP-V alues for Public Goods GameA.1 Public Goods Game 10
Clustering1 Clustering2	p-Value First	p-Value Consequent
kmeans	cmeans	0.9232418	0.7602488kmeans	pam	0.862259	0.4645937kmeans	hierarchical	0.8221081	0.2435835cmeans	pam	0.9615768	0.624153cmeans	hierarchical	0.9168674	0.1469612pam	hierarchical	0.9935938	0.06095961
Friedman0.7819042	0.1059157
Table A.1: P-value results for testing the effect of using different cluster-ing methods for grouping each time point as preparation for measuringtheir behaviour using 002rst and previous 050consecutive051 time point as refer-ence of behaviour on 10 rounds PGG data set. P-values for Wilcoxon-testare presented for each pair of clusters for one to one comparison and thep-value for Friedman-test is presented as comparison for entire samples.217A.1. PUBLIC GOODS GAME 10
Referance Point Clustering1 Clustering2	Rand	Jaccard	FM	VI	AUC
Firstkmeans	cmeans	0.4362814 0.340107	0.2973262	0.2224188	0.4362814kmeans	pam	0.232989	0.0027561	0.0027561	0.0503085	1kmeans	hierarchical 0.093912	0.0004936	8.23E-05	4.11E-05	0.5457014cmeans	pam	0.5457014 0.03146853 0.0314685	0.2224188	0.4894282cmeans	hierarchical 0.0314685 0.00123406 0.0004936	8.23E-05	0.8633073pam	hierarchical 0.0244344 4.11E-05	4.11E-05	4.11E-05	0.6048128Friedman0.0003104 2.13E-05	2.13E-05	8.69E-05	0.769034Consequentkmeans	cmeans	1	0.2224188	0.2224188	0.3865076	0.6664747kmeans	pam	0.8633073 0.00123406 0.00185109 0.003990128 0.02443439kmeans	hierarchical 0.8251941 8.23E-05	8.23E-05	4.11E-05	0.6664747cmeans	pam	0.9314274 0.03998355 0.03146853 0.1614973	0.1614973cmeans	hierarchical 1	4.11E-05	4.11E-05	4.11E-05	0.7961744pam	hierarchical 1	4.11E-05	4.11E-05	4.11E-05	0.2224188Friedman0.7370632 8.69E-05	0.0001448	0.0001448	0.1818249
Table A.2: P-value results for testing the effect of using different ECVI and AUC methods for measuring changes over timeusing 002rst and previous 050consecutive051 time point as reference of behaviour on 10 rounds PGG data set. P-values for Wilcoxon-test are presented for each pair of ECVI and AUC for one to one comparison and the p-value for Friedman-test is presented ascomparison for entire samples.
218APPENDIX A. P-V ALUES FOR PUBLIC GOODS GAMEA.2 Public Goods Game 27
Clustering1 Clustering2	p-Value First	p-Value Consequent
kmeans	cmeans	0.9244413	0.9362404kmeans	pam	0.7766422	0.767808kmeans	hierarchical	0.4931374	0.0057171cmeans	pam	0.8813398	0.792489cmeans	hierarchical	0.5959155	0.007159pam	hierarchical	0.6952552	0.0036869
Friedman0.9089858	0.005215256
Table A.3: P-value results for testing the effect of using different cluster-ing methods for grouping each time point as preparation for measuringtheir behaviour using 002rst and previous 050consecutive051 time point as refer-ence of behaviour on 27 rounds PGG data set. P-values for Wilcoxon-testare presented for each pair of clusters for one to one comparison and thep-value for Friedman-test is presented as comparison for entire samples.219A.2. PUBLIC GOODS GAME 27
220APPENDIX A. P-V ALUES FOR PUBLIC GOODS GAME
Referance Point Clustering1 Clustering2	Rand	Jaccard	FM	VI	AUC
Firstkmeans	cmeans	0.436667	0.1519604	0.22568	0.4729701	0.4957342kmeans	pam	0.02111068 8.24E-07	1.68E-06	0.000380741 0.071227kmeans	hierarchical 1.94E-05	4.03E-15	1.81E-13	2.70E-13	0.1416689cmeans	pam	0.03068753 7.03E-06	6.33E-06	0.0006021	0.2707101cmeans	hierarchical 6.85E-08	4.03E-15	8.07E-15	8.07E-15	0.05298507pam	hierarchical 2.32E-11	4.03E-15	4.03E-15	4.03E-15	0.00261Friedman6.58E-13	5.83E-15	5.83E-15	2.02E-13	0.05246Consequentkmeans	cmeans	0.2119101	0.723425	0.6565234	0.3489321	0.5550633kmeans	pam	0.0403862	0.01040974 0.008312094 0.007849577 0.3214264kmeans	hierarchical 0.03299582 7.81E-06	3.69E-06	2.66E-07	1cmeans	pam	0.2953524	0.03372976 0.03534339	0.1017556	0.09061cmeans	hierarchical 0.1906824	5.70E-07	3.91E-07	9.07E-08	0.9638254pam	hierarchical 0.425963	4.84E-10	3.98E-10	3.26E-10	0.2052534Friedman0.2315811	2.57E-12	1.22E-12	1.79E-12	0.1447436
Table A.4: P-value results for testing the effect of using different ECVI and AUC methods for measuring changes over timeusing 002rst and previous 050consecutive051 time point as reference of behaviour on 27 rounds PGG data set. P-values for Wilcoxon-test are presented for each pair of ECVI and AUC for one to one comparison and the p-value for Friedman-test is presented ascomparison for entire samples.
221A.2. PUBLIC GOODS GAME 27222Appendix BPro002les of PGG Players
223224APPENDIX B. PROFILES OF PGG PLA YERS
225226APPENDIX B. PROFILES OF PGG PLA YERS
227228Appendix CPro002les of S&P 500 Stocks
229230APPENDIX C. PROFILES OF S&P 500 STOCKS
231232APPENDIX C. PROFILES OF S&P 500 STOCKS
233234